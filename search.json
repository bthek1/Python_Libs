[
  {
    "objectID": "sqlalchemy.html",
    "href": "sqlalchemy.html",
    "title": "SQLAlchemy",
    "section": "",
    "text": "Two layers\n\nCore: SQL expression language + dialects + connection/transaction APIs.\nORM: Maps Python classes ↔︎ tables, manages identity map & unit-of-work via Session.\n\nBatteries for SQL, not a DB: You still pick Postgres/MySQL/SQLite/etc. SQLAlchemy gives you portable SQL and well-designed state management.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#what-sqlalchemy-is-and-isnt",
    "href": "sqlalchemy.html#what-sqlalchemy-is-and-isnt",
    "title": "SQLAlchemy",
    "section": "",
    "text": "Two layers\n\nCore: SQL expression language + dialects + connection/transaction APIs.\nORM: Maps Python classes ↔︎ tables, manages identity map & unit-of-work via Session.\n\nBatteries for SQL, not a DB: You still pick Postgres/MySQL/SQLite/etc. SQLAlchemy gives you portable SQL and well-designed state management.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#core-vs-orm-when-to-use-which",
    "href": "sqlalchemy.html#core-vs-orm-when-to-use-which",
    "title": "SQLAlchemy",
    "section": "Core vs ORM (when to use which)",
    "text": "Core vs ORM (when to use which)\n\n\n\n\n\n\n\nUse case\nPrefer\n\n\n\n\nHand-tuned SQL, ETL, admin scripts, DDL\nCore\n\n\nApp domain models, relations, change tracking, identity map\nORM\n\n\nHybrid: complex read SQL + mapped writes\nBoth (Core selects, ORM for stateful writes)",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#quickstart-the-modern-2.x-style",
    "href": "sqlalchemy.html#quickstart-the-modern-2.x-style",
    "title": "SQLAlchemy",
    "section": "Quickstart – the modern (2.x) style",
    "text": "Quickstart – the modern (2.x) style\n\n1) Define tables & models (Declarative)\nfrom sqlalchemy import String, ForeignKey\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship\n\nclass Base(DeclarativeBase): pass\n\nclass User(Base):\n    __tablename__ = \"user\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    email: Mapped[str] = mapped_column(String(256), unique=True, index=True)\n    posts: Mapped[list[\"Post\"]] = relationship(back_populates=\"author\", cascade=\"all, delete-orphan\")\n\nclass Post(Base):\n    __tablename__ = \"post\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    title: Mapped[str] = mapped_column(String(200))\n    user_id: Mapped[int] = mapped_column(ForeignKey(\"user.id\"), index=True)\n    author: Mapped[User] = relationship(back_populates=\"posts\")\n\n\n2) Engine & schema\nfrom sqlalchemy import create_engine\nengine = create_engine(\"postgresql+psycopg://user:pass@localhost/dbname\", echo=False)\n\n# Create tables (dev/test use; prod uses Alembic)\nBase.metadata.create_all(engine)\n\n\n3) Sessions & basic CRUD\nfrom sqlalchemy.orm import Session\n\nwith Session(engine, expire_on_commit=False) as session:\n    alice = User(email=\"alice@example.com\")\n    alice.posts.append(Post(title=\"Hello!\"))\n    session.add(alice)\n    session.commit()\n\n    # Query (2.x style)\n    from sqlalchemy import select\n    q = select(User).where(User.email == \"alice@example.com\")\n    row = session.execute(q).scalar_one()",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#querying-2.x-patterns",
    "href": "sqlalchemy.html#querying-2.x-patterns",
    "title": "SQLAlchemy",
    "section": "Querying (2.x patterns)",
    "text": "Querying (2.x patterns)\nfrom sqlalchemy import select, func\n\n# Filter + order + limit\nstmt = (\n    select(Post.title, func.count(Post.id).label(\"n\"))\n    .group_by(Post.title)\n    .order_by(func.count(Post.id).desc())\n    .limit(10)\n)\nrows = session.execute(stmt).all()\n\n# Join + load related efficiently\nfrom sqlalchemy.orm import joinedload, selectinload\nstmt = select(User).options(selectinload(User.posts))  # great for 1-to-many\nusers = session.execute(stmt).scalars().all()\nLoading strategies\n\nselectinload: many small SELECTs; excellent for 1-to-many fan-out (avoids big cartesian explosions).\njoinedload: single JOIN; good for 1-to-1 or small 1-to-many.\nDefault lazy loading can cause N+1; prefer explicit .options(...).",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#transactions-do-them-right",
    "href": "sqlalchemy.html#transactions-do-them-right",
    "title": "SQLAlchemy",
    "section": "Transactions: do them right",
    "text": "Transactions: do them right\nwith engine.begin() as conn:           # Core transaction\n    conn.execute(...)\n\nwith Session(engine) as session:       # ORM unit-of-work\n    with session.begin():              # commit/rollback handled\n        session.add(obj)\n        # multiple operations…\n\nPrefer with session.begin() blocks for atomic writes.\nexpire_on_commit=False keeps objects usable after commit (common web pattern).",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#asyncio-support",
    "href": "sqlalchemy.html#asyncio-support",
    "title": "SQLAlchemy",
    "section": "AsyncIO support",
    "text": "AsyncIO support\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker\n\nasync_engine = create_async_engine(\"postgresql+asyncpg://user:pass@/dbname\")\nAsyncSession = async_sessionmaker(async_engine, expire_on_commit=False)\n\nasync def run():\n    async with AsyncSession() as s:\n        from sqlalchemy import select\n        res = await s.execute(select(User).where(User.email.like(\"%@example.com\")))\n        users = res.scalars().all()\n\nasyncio.run(run())\n\nAsync is great for high-latency I/O workloads (APIs, microservices).\nORM patterns are nearly identical, just await connection/session ops.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#migrations-with-alembic-the-standard",
    "href": "sqlalchemy.html#migrations-with-alembic-the-standard",
    "title": "SQLAlchemy",
    "section": "Migrations with Alembic (the standard)",
    "text": "Migrations with Alembic (the standard)\n\nalembic init migrations\nSet sqlalchemy.url in alembic.ini.\nalembic revision --autogenerate -m \"add post table\"\nalembic upgrade head\n\nTips\n\nKeep metadata import in env.py pointing to your Base.metadata.\nReview autogen diffs (types, constraints, server defaults) before applying.\nFor multi-DB setups, create envs or programmatic configs.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#relationships-cascades-cheat-sheet",
    "href": "sqlalchemy.html#relationships-cascades-cheat-sheet",
    "title": "SQLAlchemy",
    "section": "Relationships & Cascades (cheat sheet)",
    "text": "Relationships & Cascades (cheat sheet)\nrelationship(\n    back_populates=\"...\",\n    cascade=\"save-update, merge, delete, delete-orphan\",\n    passive_deletes=True,        # pair with ON DELETE in FK for DB-side deletes\n    lazy=\"selectin\"               # sane default for 1-to-many\n)\n\ndelete-orphan only on the parent side of a one-to-many.\nSet nullable=False on FKs when the child must always have a parent.\nAdd index=True to FKs used in joins.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#performance-playbook",
    "href": "sqlalchemy.html#performance-playbook",
    "title": "SQLAlchemy",
    "section": "Performance Playbook",
    "text": "Performance Playbook\n\nPick the right loader (selectinload vs joinedload).\nBatch writes with session.bulk_save_objects (ORM) or Core execute(many=True); measure correctness vs speed (bulk APIs skip some ORM events).\nPagination: use keyset (a.k.a. “seek”) pagination with WHERE (created_at, id) &gt; (...) ORDER BY created_at, id LIMIT n for large tables.\nProfiling: set echo=True in dev; or use sqlalchemy.engine logging + EXPLAIN ANALYZE in Postgres.\nAvoid N+1: always declare loader options for list views.\nConnection pool: tune pool_size, max_overflow, pool_recycle for your DB and workload.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#typing-dataclasses-and-pydantic",
    "href": "sqlalchemy.html#typing-dataclasses-and-pydantic",
    "title": "SQLAlchemy",
    "section": "Typing, Dataclasses, and Pydantic",
    "text": "Typing, Dataclasses, and Pydantic\n\nUse PEP-484 typed mappings (Mapped[T], mapped_column) for editor help & safety.\nFor API schemas, prefer Pydantic models at the boundary; map ORM ↔︎ DTOs explicitly (don’t bleed ORM into transport).\nWith FastAPI, return Pydantic models; load ORM entities inside request handlers.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#patterns-for-web-apps",
    "href": "sqlalchemy.html#patterns-for-web-apps",
    "title": "SQLAlchemy",
    "section": "Patterns for Web Apps",
    "text": "Patterns for Web Apps\n\nSession scoping\n\nFastAPI: provide a session per request (dependency) and close it.\nDjango (DRF) alongside SQLAlchemy: keep SQLAlchemy session separate from Django ORM; use middleware or per-view dependency.\n\n\n\nRepositories (optional)\n\nWrap DB access in small “repo” classes to decouple domain from ORM. Good for large codebases/testing.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#testing",
    "href": "sqlalchemy.html#testing",
    "title": "SQLAlchemy",
    "section": "Testing",
    "text": "Testing\n\nUse SQLite :memory: for fast unit tests (be careful with PostgreSQL-specific features).\nFor integration tests, spin up a temp Postgres (Docker) + transactional rollbacks.\nUse session.begin_nested() and savepoint rollbacks per test to avoid re-creating schema.\nFactory libraries (e.g., factory_boy) help generate related graphs.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#advanced-sql-with-core-portable-power",
    "href": "sqlalchemy.html#advanced-sql-with-core-portable-power",
    "title": "SQLAlchemy",
    "section": "Advanced SQL with Core (portable power)",
    "text": "Advanced SQL with Core (portable power)\nfrom sqlalchemy import Table, Column, Integer, String, MetaData, select, text\nmeta = MetaData()\nt = Table(\"thing\", meta,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"name\", String(50), index=True),\n)\nwith engine.connect() as conn:\n    conn.execute(text(\"SET LOCAL statement_timeout = 2000\"))       # Postgres hint\n    rows = conn.execute(select(t.c.id, t.c.name).where(t.c.name.ilike(\"%foo%\"))).all()\n\nWindow functions (func.row_number().over(...)), CTEs (stmt.cte()), UNION/INTERSECT, array/json types via dialects.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#postgres-specific-goodies",
    "href": "sqlalchemy.html#postgres-specific-goodies",
    "title": "SQLAlchemy",
    "section": "Postgres-specific goodies",
    "text": "Postgres-specific goodies\nfrom sqlalchemy.dialects.postgresql import JSONB, ARRAY\nclass Event(Base):\n    __tablename__ = \"event\"\n    id: Mapped[int] = mapped_column(primary_key=True)\n    tags: Mapped[list[str]] = mapped_column(ARRAY(String))\n    payload: Mapped[dict] = mapped_column(JSONB)\n\n# Indexes / constraints\nfrom sqlalchemy import Index, func\nIndex(\"ix_event_gin_payload\", Event.payload, postgresql_using=\"gin\")\n\n# Upserts\nfrom sqlalchemy.dialects.postgresql import insert\nstmt = insert(User).values(email=\"x@x.com\").on_conflict_do_nothing(index_elements=[User.email])\nsession.execute(stmt)",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#concurrency-locks-pragmatic-notes",
    "href": "sqlalchemy.html#concurrency-locks-pragmatic-notes",
    "title": "SQLAlchemy",
    "section": "Concurrency & Locks (pragmatic notes)",
    "text": "Concurrency & Locks (pragmatic notes)\n\nUse SELECT ... FOR UPDATE with ORM:\nfrom sqlalchemy import select\nu = session.execute(\n    select(User).where(User.id==uid).with_for_update()\n).scalar_one()\nPrefer app-level idempotency (unique keys) to avoid duplicate writes.\nUse advisory locks (Postgres) for coarse critical sections.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#common-pitfalls-and-fixes",
    "href": "sqlalchemy.html#common-pitfalls-and-fixes",
    "title": "SQLAlchemy",
    "section": "Common Pitfalls (and fixes)",
    "text": "Common Pitfalls (and fixes)\n\nN+1 queries → always set loader options for list endpoints.\nStale objects after commit → expire_on_commit=False (but remember to refresh when needed).\nImplicit flush surprises → autoflush=True is default; call session.flush() where order matters, or disable via context manager temporarily.\nLeaking sessions → always with Session(...) as s: or ensure FastAPI dependency closes sessions.\nOver-eager cascades → review cascade= rules; be explicit with deletes.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#alembic-gotchas",
    "href": "sqlalchemy.html#alembic-gotchas",
    "title": "SQLAlchemy",
    "section": "Alembic Gotchas",
    "text": "Alembic Gotchas\n\nColumn type changes may need server_default adjustments & data migrations.\nEnum changes in Postgres require ALTER TYPE (write revision manually).\nRenames: use op.alter_column(..., new_column_name=...), and keep ORM property name aligned.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#choosing-the-right-abstraction",
    "href": "sqlalchemy.html#choosing-the-right-abstraction",
    "title": "SQLAlchemy",
    "section": "Choosing the right abstraction",
    "text": "Choosing the right abstraction\n\nSmall service, API-only, heavy I/O → ORM + async session, or Core if you prefer SQL control.\nLarge domain model, rich relations → ORM with explicit loader strategies and clear aggregate boundaries.\nAnalytics/ETL → Core for READs + bulk COPY; ORM optional for simple stateful writes.",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "sqlalchemy.html#mini-starter-template-sync",
    "href": "sqlalchemy.html#mini-starter-template-sync",
    "title": "SQLAlchemy",
    "section": "Mini “starter template” (sync)",
    "text": "Mini “starter template” (sync)\nyourapp/\n  db.py          # engine, SessionLocal, Base\n  models.py      # declarative models\n  schema.py      # Pydantic DTOs (if using FastAPI)\n  repo/          # optional repositories\n  services/      # business logic (or “use cases”)\n  api/           # FastAPI/Django views\n  migrations/    # Alembic\ntests/\ndb.py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, DeclarativeBase\n\nclass Base(DeclarativeBase): pass\n\nengine = create_engine(\"postgresql+psycopg://user:pass@localhost/app\", future=True)\nSessionLocal = sessionmaker(engine, expire_on_commit=False)\n\ndef get_session():\n    with SessionLocal() as s:\n        yield s\n\n\n# db_async_nb.py  (just paste in a notebook cell)\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\n\nDATABASE_URL = \"postgresql+asyncpg://ben:secret@localhost:5433/mydb\"\n\nengine = create_async_engine(\n    DATABASE_URL,\n    pool_size=10,\n    max_overflow=20,\n    pool_pre_ping=True,\n    connect_args={\"server_settings\": {\"search_path\": \"api,public\"}},\n)\n\nasync def get_table_info(schema: str = \"api\"):\n    async with engine.begin() as conn:\n        result = await conn.execute(text(\"\"\"\n            SELECT \n                table_name,\n                column_name,\n                ordinal_position,\n                data_type,\n                is_nullable,\n                column_default\n            FROM information_schema.columns\n            WHERE table_schema = :schema\n            ORDER BY table_name, ordinal_position\n        \"\"\"), {\"schema\": schema})\n        return [dict(r) for r in result.mappings().all()]\n\n\nimport pandas as pd\n\nrows = await get_table_info(\"api\")   # &lt;-- key change: use await, not asyncio.run\ndf = pd.DataFrame(rows)\ndf\n\n\n\n\n\n\n\n\ntable_name\ncolumn_name\nordinal_position\ndata_type\nis_nullable\ncolumn_default\n\n\n\n\n0\niotawatt\ntimestamp\n1\ntimestamp with time zone\nNO\nNone\n\n\n1\niotawatt\ndevice\n2\ntext\nNO\nNone\n\n\n2\niotawatt\nsensor\n3\ntext\nNO\nNone\n\n\n3\niotawatt\npower\n4\ndouble precision\nYES\nNone\n\n\n4\niotawatt\npf\n5\ndouble precision\nYES\nNone\n\n\n5\niotawatt\ncurrent\n6\ndouble precision\nYES\nNone\n\n\n6\niotawatt\nv\n7\ndouble precision\nYES\nNone\n\n\n\n\n\n\n\n\nfrom sqlalchemy import text\n\nasync def get_constraints(schema: str = \"api\"):\n    async with engine.begin() as conn:\n        res = await conn.execute(text(\"\"\"\n            SELECT\n              tc.table_name,\n              tc.constraint_type,\n              kcu.column_name,\n              ccu.table_name AS foreign_table,\n              ccu.column_name AS foreign_column\n            FROM information_schema.table_constraints AS tc\n            JOIN information_schema.key_column_usage AS kcu\n              ON tc.constraint_name = kcu.constraint_name\n             AND tc.table_schema = kcu.table_schema\n            LEFT JOIN information_schema.constraint_column_usage AS ccu\n              ON ccu.constraint_name = tc.constraint_name\n             AND ccu.table_schema = tc.table_schema\n            WHERE tc.table_schema = :schema\n            ORDER BY tc.table_name, tc.constraint_type\n        \"\"\"), {\"schema\": schema})\n        return [dict(r) for r in res.mappings().all()]\n\nconstraints_df = pd.DataFrame(await get_constraints(\"api\"))\nconstraints_df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nasync def get_index_ddl(schema: str = \"api\"):\n    async with engine.begin() as conn:\n        res = await conn.execute(text(\"\"\"\n            SELECT n.nspname  AS schema,\n                   c.relname  AS table,\n                   i.relname  AS index,\n                   pg_get_indexdef(ix.indexrelid) AS definition,\n                   ix.indisunique AS is_unique\n            FROM pg_index ix\n            JOIN pg_class i  ON i.oid = ix.indexrelid\n            JOIN pg_class c  ON c.oid = ix.indrelid\n            JOIN pg_namespace n ON n.oid = c.relnamespace\n            WHERE n.nspname = :schema\n            ORDER BY c.relname, i.relname\n        \"\"\"), {\"schema\": schema})\n        return [dict(r) for r in res.mappings().all()]\n\nindexes_df = pd.DataFrame(await get_index_ddl(\"api\"))\nindexes_df\n\n\n\n\n\n\n\n\nschema\ntable\nindex\ndefinition\nis_unique\n\n\n\n\n0\napi\niotawatt\niotawatt_timestamp_idx\nCREATE INDEX iotawatt_timestamp_idx ON api.iot...\nFalse",
    "crumbs": [
      "Blog",
      "SQLAlchemy"
    ]
  },
  {
    "objectID": "Python/python_args.html",
    "href": "Python/python_args.html",
    "title": "Python args",
    "section": "",
    "text": "import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"square\", type=int,\n                    help=\"display a square of a given number\")\nparser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                    help=\"increase output verbosity\")\nargs = parser.parse_args()\nanswer = args.square**2\nif args.verbose:\n    print(f\"the square of {args.square} equals {answer}\")\nelse:\n    print(answer)\n&gt;&gt; python prog.py\nusage: prog.py [-h] [-v] square\nprog.py: error: the following arguments are required: square\n\n&gt;&gt; python prog.py 4\n16\n\n&gt;&gt; python prog.py 4 --verbose\nthe square of 4 equals 16\n\n&gt;&gt; python prog.py --verbose 4\nthe square of 4 equals 16\n\n!cat 9_argparse_example.py\n\nimport argparse\nfrom datetime import datetime\n\ndef reformat_date(date_string):\n    date_object = datetime.strptime(date_string, '%d/%m/%Y')\n    return date_object.strftime('%Y-%m-%dT%H:%M:%SZ')\n\ndef main(start, end):\n    if start != None:\n        print(\"Argument 1:\", reformat_date(start))\n    if end != None:\n        print(\"Argument 2:\", reformat_date(end))\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"\"\"Create models for users\n    Ex. python test.py -s 19/03/2024 -e 19/07/2024\"\"\")\n    parser.add_argument(\"-s\", \"--start_date\", type=str, help=\"Start Date ex. '19/03/2024'\")\n    parser.add_argument(\"-e\", \"--end_date\", type=str, help=\"End Date ex. '19/07/2024'\")\n    args = parser.parse_args()\n    main(args.start_date, args.end_date)\n\n\n\n!python 9_argparse_example.py -h\n\nusage: 9_argparse_example.py [-h] [-s START_DATE] [-e END_DATE]\n\nCreate models for users Ex. python test.py -s 19/03/2024 -e 19/07/2024\n\noptions:\n  -h, --help            show this help message and exit\n  -s START_DATE, --start_date START_DATE\n                        Start Date ex. '19/03/2024'\n  -e END_DATE, --end_date END_DATE\n                        End Date ex. '19/07/2024'\n\n\n\n!python 9_argparse_example.py -s 01/01/2023 -e 01/01/2024\n\nArgument 1: 2023-01-01T00:00:00Z\nArgument 2: 2024-01-01T00:00:00Z\n\n\n\n!cat 9_sys_example.py\n\nimport sys\n \n# total arguments\nn = len(sys.argv)\nprint(\"Total arguments passed:\", n)\n \n# Arguments passed\nprint(\"\\nName of Python script:\", sys.argv[0])\n \nprint(\"\\nArguments passed:\", end = \" \")\nfor i in range(1, n):\n    print(sys.argv[i], end = \" \")\n     \n# Addition of numbers\nSum = 0\n# Using argparse module\nfor i in range(1, n):\n    Sum += int(sys.argv[i])\n     \nprint(\"\\n\\nResult:\", Sum)\n\n\n\n!python 9_sys_example.py 1 2\n\nTotal arguments passed: 3\n\nName of Python script: 9_sys_example.py\n\nArguments passed: 1 2 \n\nResult: 3\n\n\n\na = []\n\n\na[1] = 1\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[1], line 1\n----&gt; 1 a[1] = 1\n\nNameError: name 'a' is not defined\n\n\n\n\na\n\n[1, 1, 3]\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Python",
      "Python args"
    ]
  },
  {
    "objectID": "Python/python_class.html",
    "href": "Python/python_class.html",
    "title": "Python Class",
    "section": "",
    "text": "def scope_test():\n    def do_local():\n        spam = \"local spam\"\n\n    def do_nonlocal():\n        nonlocal spam\n        spam = \"nonlocal spam\"\n\n    def do_global():\n        global spam\n        spam = \"global spam\"\n\n    spam = \"test spam\"\n    do_local()\n    print(\"After local assignment:\", spam)\n    do_nonlocal()\n    print(\"After nonlocal assignment:\", spam)\n    do_global()\n    print(\"After global assignment:\", spam)\n\nscope_test()\nprint(\"In global scope:\", spam)\n\nAfter local assignment: test spam\nAfter nonlocal assignment: nonlocal spam\nAfter global assignment: nonlocal spam\nIn global scope: global spam",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#scopes-and-namespaces-example",
    "href": "Python/python_class.html#scopes-and-namespaces-example",
    "title": "Python Class",
    "section": "",
    "text": "def scope_test():\n    def do_local():\n        spam = \"local spam\"\n\n    def do_nonlocal():\n        nonlocal spam\n        spam = \"nonlocal spam\"\n\n    def do_global():\n        global spam\n        spam = \"global spam\"\n\n    spam = \"test spam\"\n    do_local()\n    print(\"After local assignment:\", spam)\n    do_nonlocal()\n    print(\"After nonlocal assignment:\", spam)\n    do_global()\n    print(\"After global assignment:\", spam)\n\nscope_test()\nprint(\"In global scope:\", spam)\n\nAfter local assignment: test spam\nAfter nonlocal assignment: nonlocal spam\nAfter global assignment: nonlocal spam\nIn global scope: global spam",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#class-syntax",
    "href": "Python/python_class.html#class-syntax",
    "title": "Python Class",
    "section": "Class Syntax",
    "text": "Class Syntax\nclass ClassName:\n    &lt;statement-1&gt;\n    .\n    .\n    .\n    &lt;statement-N&gt;",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#the-self-parameter",
    "href": "Python/python_class.html#the-self-parameter",
    "title": "Python Class",
    "section": "The self Parameter",
    "text": "The self Parameter\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def myfunc(self):\n        print(\"Hello my name is \" + self.name)\n\np1 = Person(\"John\", 36)\np1.myfunc()\n\nHello my name is John\n\n\n\nclass Person:\n    def __init__(mysillyobject, name, age):\n        mysillyobject.name = name\n        mysillyobject.age = age\n\n    def myfunc(abc):\n        print(\"Hello my name is \" + abc.name)\n\np1 = Person(\"John\", 36)\np1.myfunc()\n\nHello my name is John\n\n\n\nThe pass Statement\nclass definitions cannot be empty, but if you for some reason have a class definition with no content, put in the pass statement to avoid getting an error.\n\nclass Person:\n    pass",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#init__",
    "href": "Python/python_class.html#init__",
    "title": "Python Class",
    "section": "__init__",
    "text": "__init__\nThe instantiation operation (“calling” a class object) creates an empty object. Many classes like to create objects with instances customized to a specific initial state. Therefore a class may define a special method named init(), like this:\n\ndef __init__(self):\n    self.data = []\n\n\nclass Complex:\n    def __init__(self, realpart, imagpart):\n        self.r = realpart\n        self.i = imagpart\n\nx = Complex(3.0, -4.5)\n\nx.r, x.i\n\n(3.0, -4.5)",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#new__",
    "href": "Python/python_class.html#new__",
    "title": "Python Class",
    "section": "__new__",
    "text": "__new__\nWhen you create a new object by calling the class, Python calls the new() method to create the object first and then calls the init() method to initialize the object’s attributes.\n\nclass Person:\n    def __new__(cls, name):\n        print(f'Creating a new {cls.__name__} object...')\n        obj = object.__new__(cls)\n        return obj\n\n    def __init__(self, name):\n        print(f'Initializing the person object...')\n        self.name = name\n\n\nperson = Person('John')\n\nCreating a new Person object...\nInitializing the person object...\n\n\n\nx.counter = 1\nwhile x.counter &lt; 10:\n    x.counter = x.counter * 2\nprint(x.counter)\ndel x.counter\n\n16\n\n\n\nclass Dog:\n\n    tricks = []             # mistaken use of a class variable\n\n    def __init__(self, name):\n        self.name = name\n\n    def add_trick(self, trick):\n        self.tricks.append(trick)\n\nd = Dog('Fido')\ne = Dog('Buddy')\nd.add_trick('roll over')\ne.add_trick('play dead')\nd.tricks                # unexpectedly shared by all dogs\n\n['roll over', 'play dead']\n\n\n\nclass Dog:\n\n    def __init__(self, name):\n        self.name = name\n        self.tricks = []    # creates a new empty list for each dog\n\n    def add_trick(self, trick):\n        self.tricks.append(trick)\n\nd = Dog('Fido')\ne = Dog('Buddy')\nd.add_trick('roll over')\ne.add_trick('play dead')\nd.tricks\n\n['roll over']\n\n\n\ne.tricks\n\n['play dead']\n\n\nMethods may call other methods by using method attributes of the self argument:\n\nclass Bag:\n    def __init__(self):\n        self.data = []\n\n    def add(self, x):\n        self.data.append(x)\n\n    def addtwice(self, x):\n        self.add(x)\n        self.add(x)",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#iter__-__next__",
    "href": "Python/python_class.html#iter__-__next__",
    "title": "Python Class",
    "section": "__iter__ & __next__",
    "text": "__iter__ & __next__\n\nclass Reverse:\n    \"\"\"Iterator for looping over a sequence backwards.\"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.index = len(self.data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index == 0:\n            self.index = len(self.data)\n            raise StopIteration\n        self.index = self.index - 1\n        return self.data[self.index]\n\n\nrev = Reverse('spam')\n\niter(rev)\n\n&lt;__main__.Reverse&gt;\n\n\n\nfor char in rev:\n    print(char)\n\nm\na\np\ns\n\n\n\ns = 'abc'\n\nit = iter(s)\n\nit\n\n&lt;str_ascii_iterator&gt;\n\n\n\ndef reverse(data):\n    for index in range(len(data)-1, -1, -1):\n        yield data[index]\n        \n\nfor char in reverse('golf'):\n    print(char)\n\nf\nl\no\ng\n\n\nAnything that can be done with generators can also be done with class-based iterators as described in the previous section. What makes generators so compact is that the iter() and next() methods are created automatically.",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#str__",
    "href": "Python/python_class.html#str__",
    "title": "Python Class",
    "section": "__str__",
    "text": "__str__\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\np1 = Person(\"John\", 36)\n\nprint(p1)\n\n&lt;__main__.Person object&gt;\n\n\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __str__(self):\n        return f\"{self.name}({self.age})\"\n\np1 = Person(\"John\", 36)\n\nprint(p1)\n\nJohn(36)",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#repr__",
    "href": "Python/python_class.html#repr__",
    "title": "Python Class",
    "section": "__repr__",
    "text": "__repr__\n\nclass Person:\n    def __init__(self, first_name, last_name, age):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.age = age\n\n\nperson = Person('John', 'Doe', 25)\nprint(repr(person))\n\n&lt;__main__.Person object&gt;\n\n\n\nclass Person:\n    def __init__(self, first_name, last_name, age):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.age = age\n        \n    def __str__(self):\n        return f'str: {self.first_name}\",\"{self.last_name}\",{self.age}'\n\n    def __repr__(self):\n        return f'repr: (\"{self.first_name}\",\"{self.last_name}\",{self.age})'\n    \n    def __call__(self):\n        return f\"call: {self.__dict__}\"\n\n\nperson = Person(\"John\", \"Doe\", 25)\nprint(person)\n\nstr: John\",\"Doe\",25\n\n\n\nprint(repr(person))\n\nrepr: (\"John\",\"Doe\",25)\n\n\n\nperson\n\nrepr: (\"John\",\"Doe\",25)\n\n\n\nperson()\n\n\"call: {'first_name': 'John', 'last_name': 'Doe', 'age': 25}\"\n\n\n\nstr vs repr\nThe main difference between str and repr method is intended audiences.\nThe str method returns a string representation of an object that is human-readable while the repr method returns a string representation of an object that is machine-readable.\n\n\nSummary\n\nImplement the repr method to customize the string representation of an object when repr() is called on it.\nThe str calls repr internally by default.",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#call__",
    "href": "Python/python_class.html#call__",
    "title": "Python Class",
    "section": "__call__",
    "text": "__call__\n\nclass Counter:\n    def __init__(self):\n        self.count = 0\n\n    def increment(self):\n        self.count += 1\n\n    def __call__(self):\n        self.increment()\n        return self.count\n\n\ncount = Counter()\n\n\ncount()\n\n1\n\n\n\ncount.__dict__\n\n{'count': 1}",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#setattr__-__getattr__",
    "href": "Python/python_class.html#setattr__-__getattr__",
    "title": "Python Class",
    "section": "__setattr__ & __getattr__",
    "text": "__setattr__ & __getattr__\n\nclass Person:\n    def __init__(self, first_name, last_name, age):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.set_age(age)\n        \n    def __str__(self):\n        return f'str: {self.first_name}\",\"{self.last_name}\",{self.age}'\n\n    def __repr__(self):\n        return f'repr: (\"{self.first_name}\",\"{self.last_name}\",{self.age})'\n    \n    def __call__(self):\n        return f\"call: {self.__dict__}\"\n    \n    def __getattr__(self, attr):\n        print(\"getting attr\")\n        try:\n            return self.__dict__[attr] \n        except KeyError:\n            print(f\"Attribute doesn't exist\")\n    \n    \n    def __setattr__(self, attr, value):\n        print(f\"setting attr: class.{attr} = {value}\")\n        self.__dict__[attr] = value\n        \n    def set_age(self, age):\n        if age &lt;= 0:\n            #raise ValueError('The age must be positive')\n            print('The age must be positive')\n            return\n        self._age = age\n\n    def get_age(self):\n        return self._age\n\n\njohn = Person('John', 'Doe', 23)\njohn.set_age(12)\n\nsetting attr: class.first_name = John\nsetting attr: class.last_name = Doe\nsetting attr: class._age = 23\nsetting attr: class._age = 12\n\n\n\njohn.a = 1\n\nsetting attr: class.a = 1\n\n\n\njohn.b\n\ngetting attr\nAttribute doesn't exist\n\n\n\njohn.__dict__\n\n{'first_name': 'John', 'last_name': 'Doe', '_age': 12, 'a': 1}\n\n\n\ngetattr(john, 'b')\n\ngetting attr\nAttribute doesn't exist",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#setitem__-__getitem__",
    "href": "Python/python_class.html#setitem__-__getitem__",
    "title": "Python Class",
    "section": "__setitem__ & __getitem__",
    "text": "__setitem__ & __getitem__\n\n# Code to demonstrate use \n# of __getitem__() in python \nclass Test(object): \n      \n    # This function prints the type \n    # of the object passed as well  \n    # as the object item \n    def __getitem__(self, items): \n        print (type(items), items) \n  \n    # Driver code \ntest = Test() \ntest[5] \ntest[5:65:5] \ntest['GeeksforGeeks'] \ntest[1, 'x', 10.0] \ntest['a':'z':2] \ntest[object()]\n\n&lt;class 'int'&gt; 5\n&lt;class 'slice'&gt; slice(5, 65, 5)\n&lt;class 'str'&gt; GeeksforGeeks\n&lt;class 'tuple'&gt; (1, 'x', 10.0)\n&lt;class 'slice'&gt; slice('a', 'z', 2)\n&lt;class 'object'&gt; &lt;object object&gt;\n\n\n\nclass Building(object):\n    def __init__(self, floors):\n        self._floors = [None]*floors\n    def __setitem__(self, floor_number, data):\n        self._floors[floor_number] = data\n    def __getitem__(self, floor_number):\n        return self._floors[floor_number]\n\nbuilding1 = Building(4) # Construct a building with 4 floors\nbuilding1[0] = 'Reception'\nbuilding1[1] = 'ABC Corp'\nbuilding1[2] = 'DEF Inc'\nprint(building1[1])\n\nABC Corp\n\n\n\nclass PDFreader:\n    ''' Function for reading and displaying pdf files\n        ex. path = './Data/&lt;file&gt;.pdf' \n            pdf = PDFreader(path, size = (10, 8))\n            pdf[0:5]\n    '''\n    def __init__(self, path, size = (6, 4)):\n        self.filepath = path\n        self.images = self.display_pdf_slides()\n        self.index = 0\n        self.size = size   \n        \n        \n    def __str__(self):\n        return f'--string--: path:\"{self.filepath}\"   index:{self.index}   size:{self.size}   len:{len(self.images)}'\n\n    def __repr__(self):\n        return f'--Representation-- \\r\\npath:\"{self.filepath}\" \\r\\nindex:{self.index} \\r\\nsize:{self.size} \\r\\nlen:{len(self.images)}'\n    \n    def __getitem__(self, slide):\n        'get slides like indexing a array'\n        if isinstance(slide, int):\n            self.slides(slice(slide, slide + 1))   \n        elif isinstance(slide, slice):\n            self.slides(slide)  \n            \n    \n    def slides(self, slide):\n        'display the slide as plt.imshow(image)'\n        import matplotlib.pyplot as plt\n\n        for i, image in enumerate(self.images[slide]):\n            plt.figure(figsize=self.size)\n            plt.imshow(image)\n            if slide.step == None:\n                plt.title(f'Slide {slide.start + i}')\n            else:\n                plt.title(f'Slide {slide.start + slide.step}')\n            plt.axis('off')\n        plt.show()",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#enter__-__exit__",
    "href": "Python/python_class.html#enter__-__exit__",
    "title": "Python Class",
    "section": "__enter__ & __exit__",
    "text": "__enter__ & __exit__\n\nclass MySecretConnection:\n    def __init__(self, url):\n        self.url = url\n\n    def __enter__(self):\n        print('entering:', self.url)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print('exit:', self.url)\n\n\nwith MySecretConnection('(test)') as finxter:\n    # Called finxter.__enter__()\n    pass\n    # Called finxter.__exit__()\n\nentering: (test)\nexit: (test)\n\n\n\nclass Open_File():\n    def __init__(self, filename, mode):\n        self.filename = filename\n        self.mode = mode\n        \n    def __enter__(self):\n        self.file = open(self.filename, self.mode)\n        print('file opened')\n        return self.file\n\n    def __exit__(self, exc_type, exc_val, traceback):\n        self.file.close()\n        print('file closed')\n        \nwith Open_File('Data/sample.txt', 'a') as f:\n    f.write('Testing\\n\\r')\n        \nprint(f.closed)\n\nfile opened\nfile closed\nTrue\n\n\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef open_file(file, mode):\n    # __enter__ start\n    f = open(file, mode)  \n    print('file opened')\n    # __enter__ end\n    yield f\n    # __exit__ start\n    f.close()\n    print('file closed')\n    # __exit__ end\n    \nwith open_file('Data/sample.txt', 'a') as f:\n    f.write('test text\\n\\r')\n    \nprint(f.closed)\n\nfile opened\nfile closed\nTrue",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#eq__",
    "href": "Python/python_class.html#eq__",
    "title": "Python Class",
    "section": "__eq__",
    "text": "__eq__\n\nclass Person:\n    def __init__(self, first_name, last_name, age):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.age = age\n\n\njohn = Person('John', 'Doe', 25)\njane = Person('Jane', 'Doe', 25)\n\n\nprint(john is jane); print(john == jane); john == jane # False\n\nFalse\nFalse\n\n\nFalse\n\n\n\nclass Person:\n    def __init__(self, first_name, last_name, age):\n        self.first_name = first_name\n        self.last_name = last_name\n        self.age = age\n\n    def __eq__(self, other):\n        if isinstance(other, Person):\n            return self.age == other.age\n\n        return False\n\n\njohn = Person('John', 'Doe', 25)\njane = Person('Jane', 'Doe', 25)\nprint(john is jane); print(john == jane); john == jane # False\n\nFalse\nTrue\n\n\nTrue\n\n\n\njohn = Person('John', 'Doe', 25)\nmary = Person('Mary', 'Doe', 27)\nprint(john is mary); print(john == mary); john == mary # False\n\nFalse\nFalse\n\n\nFalse\n\n\n\njohn = Person('John', 'Doe', 25)\nprint(john == 20)\n\nFalse",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#bool__",
    "href": "Python/python_class.html#bool__",
    "title": "Python Class",
    "section": "__bool__",
    "text": "__bool__\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __bool__(self):\n        if self.age &lt; 18 or self.age &gt; 65:\n            return False\n        return True\n\n\n\njane = Person('Jane', 19)\nbool(jane)\n\nTrue\n\n\n\nbool(jane) is True\n\nTrue",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#len__",
    "href": "Python/python_class.html#len__",
    "title": "Python Class",
    "section": "__len__",
    "text": "__len__\n\na = 'aasd'\nlen(a)\n\n4\n\n\n\nclass Person:\n    def __init__(self, name):\n        self.name = name\n\n    def __len__(self):\n        print('len was called...')\n        return len(self.name)\n\n\nben = Person('ben')\nprint(bool(ben))  # False\n\nben.name = ''\nprint(bool(ben))  # True\n\nlen was called...\nTrue\nlen was called...\nFalse\n\n\n\nSummary\n\nAll objects of custom classes return True by default.\nImplement the bool method to override the default. The bool method must return either True or False.\nIf a class doesn’t implement the bool method, Python will use the result of the len method. If the class doesn’t implement both methods, the objects will be True by default.",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#del__",
    "href": "Python/python_class.html#del__",
    "title": "Python Class",
    "section": "__del__",
    "text": "__del__\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __del__(self):\n        print('__del__ was called')\n\n\nperson = Person('John Doe', 23)\ndel person\n\n__del__ was called\n\n\n\nperson = Person('John Doe', 23)\nperson = None\n\n__del__ was called",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#dict__",
    "href": "Python/python_class.html#dict__",
    "title": "Python Class",
    "section": "__dict__",
    "text": "__dict__\n\nPerson.__dict__\n\nmappingproxy({'__module__': '__main__',\n              '__init__': &lt;function __main__.Person.__init__(self, name, age)&gt;,\n              '__del__': &lt;function __main__.Person.__del__(self)&gt;,\n              '__dict__': &lt;attribute '__dict__' of 'Person' objects&gt;,\n              '__weakref__': &lt;attribute '__weakref__' of 'Person' objects&gt;,\n              '__doc__': None})",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#python-operator-overloading",
    "href": "Python/python_class.html#python-operator-overloading",
    "title": "Python Class",
    "section": "Python Operator Overloading",
    "text": "Python Operator Overloading\n\nclass Point2D:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __repr__(self):\n        return f'({self.x},{self.y})'\n\n    def __add__(self, point):\n        if not isinstance(point, Point2D):\n            raise ValueError('The other must be an instance of the Point2D')\n\n        return Point2D(self.x + point.x, self.y + point.y)\n\n    def __sub__(self, point):\n        if not isinstance(point, Point2D):\n            raise ValueError('The other must be an instance of the Point2D')\n\n        return Point2D(self.x - point.x, self.y - point.y)\n    def __mul__(self, point):\n        if not isinstance(point, Point2D):\n            raise ValueError('The other must be an instance of the Point2D')\n\n        return Point2D(self.x * point.x, self.y * point.y)\n\n    def __and__(self, point):\n        return self.__add__(point)\n\n\na = Point2D(10, 20)\nb = Point2D(15, 25)\nc = b - a\nb-a, b + a, b * a, b & a\n\n((5,5), (25,45), (150,500), (25,45))",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#inheritance",
    "href": "Python/python_class.html#inheritance",
    "title": "Python Class",
    "section": "Inheritance",
    "text": "Inheritance\nclass DerivedClassName(Base1, Base2, Base3):\n    &lt;statement-1&gt;\n    .\n    .\n    .\n    &lt;statement-N&gt;\n\nExample\n\nclass Person:\n    def __init__(self, fname, lname):\n        self.firstname = fname\n        self.lastname = lname\n        \n    def __str__(self):\n        return f\"str:{self.lastname}, {self.firstname}\"\n    \n    def __repr__(self):\n        return f'Repr: {self.firstname},{self.lastname}'\n\n    def printname(self):\n        print(self.firstname, self.lastname)\n\n#Use the Person class to create an object, and then execute the printname method:\n\n\nx = Person(\"John\", \"Doe\")\nprint(x)\n\nstr:Doe, John\n\n\n\nx\n\nRepr: John,Doe\n\n\n\nclass Student(Person):\n    pass \n\nx = Student(\"Mike\", \"Olsen\")\nx.printname()\n\nMike Olsen\n\n\nThe child’s init() function overrides the inheritance of the parent’s init() function.\n\nclass Student(Person):\n    def __init__(self, fname, lname):\n        Person.__init__(self, fname, lname)\n\nNow we have successfully added the init() function, and kept the inheritance of the parent class, and we are ready to add functionality in the init() function.\nPython also has a super() function that will make the child class inherit all the methods and properties from its parent:\n\nclass Student(Person):\n    def __init__(self, fname, lname, year):\n        super().__init__(fname, lname)\n        self.graduationyear = year\n\n    def welcome(self):\n        print(\"Welcome\", self.firstname, self.lastname, \"to the class of\", self.graduationyear)\n\n\nx = Student(\"Mike\", \"Olsen\", 2019) \nx.welcome()\n\nWelcome Mike Olsen to the class of 2019",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#property",
    "href": "Python/python_class.html#property",
    "title": "Python Class",
    "section": "Property",
    "text": "Property\n\nGetter and setter\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.set_age(age)\n\n    def set_age(self, age):\n        if age &lt;= 0:\n            #raise ValueError('The age must be positive')\n            print('The age must be positive')\n            return\n        self._age = age\n\n    def get_age(self):\n        return self._age\n\njohn = Person('John', 18)\n\n\njohn.set_age(-19)\nprint(john.get_age())\n\nThe age must be positive\n18\n\n\n\njohn.__dict__\n\n{'name': 'John', '_age': 18}\n\n\n\nPerson.__dict__\n\nmappingproxy({'__module__': '__main__',\n              '__init__': &lt;function __main__.Person.__init__(self, name, age)&gt;,\n              'set_age': &lt;function __main__.Person.set_age(self, age)&gt;,\n              'get_age': &lt;function __main__.Person.get_age(self)&gt;,\n              '__dict__': &lt;attribute '__dict__' of 'Person' objects&gt;,\n              '__weakref__': &lt;attribute '__weakref__' of 'Person' objects&gt;,\n              '__doc__': None})\n\n\nThe property() has the following parameters:\n\nfget is a function to get the value of the attribute, or the getter method.\nfset is a function to set the value of the attribute, or the setter method.\nfdel is a function to delete the attribute.\ndoc is a docstring i.e., a comment.\n\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.set_age(age)\n\n    def set_age(self, age):\n        if age &lt;= 0:\n            #raise ValueError('The age must be positive')\n            print('The age must be positive')\n            return\n        self._age = age\n\n    def get_age(self):\n        return self._age\n    \n    age = property(fget=get_age, fset=set_age)\n\njohn = Person('John', 18)\n\n\njohn.age = -19\n\nThe age must be positive\n\n\n\njohn.age\n\n18\n\n\n\n\nProperty Decorator\nHere’s the syntax of the property class:\nclass property(fget=None, fset=None, fdel=None, doc=None)\nThe property() accepts a callable (age) and returns a callable. Therefore, it is a decorator. Therefore, you can use the @property decorator to decorate the age() method as follows:\nTo assign the set_age to the fset of the age property object, you call the setter() method of the age property object like the following:\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self._age = age\n\n    @property\n    def age(self):\n        return self._age\n\n    @age.setter\n    def set_age(self, value):\n        if value &lt;= 0:\n            raise ValueError('The age must be positive')\n        self._age = value\n\n\n\nReadonly Property\nTo define a readonly property, you need to create a property with only the getter. However, it is not truly read-only because you can always access the underlying attribute and change it.\n\nimport math\n\n\nclass Circle:\n    def __init__(self, radius):\n        self.radius = radius\n\n    @property\n    def area(self):\n        return math.pi * self.radius ** 2\n\n\nc = Circle(10)\nprint(c.area)\n\n314.1592653589793\n\n\n\n\nDelete Property\n\nfrom pprint import pprint\n\n\nclass Person:\n    def __init__(self, name):\n        self._name = name\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        if value.strip() == '':\n            raise ValueError('name cannot be empty')\n        self._name = value\n\n    @name.deleter\n    def name(self):\n        del self._name\n\n\npprint(Person.__dict__)\n\nmappingproxy({'__dict__': &lt;attribute '__dict__' of 'Person' objects&gt;,\n              '__doc__': None,\n              '__init__': &lt;function Person.__init__&gt;,\n              '__module__': '__main__',\n              '__weakref__': &lt;attribute '__weakref__' of 'Person' objects&gt;,\n              'name': &lt;property object&gt;})\n\n\n\nperson = Person('John')\n\n\nperson.__class__.__name__\n\n'Person'\n\n\n\npprint(person.__dict__)\n\n{'_name': 'John'}\n\n\n\ndel person.name\n\n\npprint(person.__dict__)\n\n{}",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#decorators",
    "href": "Python/python_class.html#decorators",
    "title": "Python Class",
    "section": "Decorators",
    "text": "Decorators\n\nPassing the function as an argument\n\n# can be passed as arguments to other functions \ndef shout(text): \n    return text.upper() \n \ndef whisper(text): \n    return text.lower() \n \ndef greet(func): \n    # storing the function in a variable \n    greeting = func(\"\"\"Hi, I am created by a function passed as an argument.\"\"\") \n    print (greeting)\n\n\ngreet(shout) \ngreet(whisper)\n\nHI, I AM CREATED BY A FUNCTION PASSED AS AN ARGUMENT.\nhi, i am created by a function passed as an argument.\n\n\n\n\nReturning functions from another function.\n\ndef create_adder(x): \n    def adder(y): \n        return x+y \n \n    return adder \n \nadd_15 = create_adder(15) \n \nprint(add_15(10))\n\n25\n\n\nAs stated above the decorators are used to modify the behaviour of function or class. In Decorators, functions are taken as the argument into another function and then called inside the wrapper function.\n@gfg_decorator\ndef hello_decorator():\n    print(\"Gfg\")\n\n'''Above code is equivalent to '''\n\ndef hello_decorator():\n    print(\"Gfg\")\n    \nhello_decorator = gfg_decorator(hello_decorator)\n\n\nDecorator can modify the behaviour:\n\n# importing libraries\nimport time\nimport math\n \n# decorator to calculate duration\n# taken by any function.\ndef calculate_time(func):\n    print('inside')\n    # added arguments inside the inner1,\n    # if function takes any arguments,\n    # can be added like this.\n    def inner1(*args, **kwargs):\n \n        # storing time before function execution\n        begin = time.time()\n        print('before')\n        a = func(*args, **kwargs)\n        \n        # storing time after function execution\n        end = time.time()\n        print(\"after: Total time taken in : \", func.__name__, end - begin)\n        \n        return a\n \n    return inner1\n \n \n \n# this can be added to any function present,\n# in this case to calculate a factorial\n#@calculate_time\ndef factorial(num):\n \n    # sleep 2 seconds because it takes very less time\n    # so that you can see the actual difference\n    return math.factorial(num)\n \n# calling the function.\nfactorial(10)\n\n3628800\n\n\n\ncalculate_time(factorial)(10)\n\ninside\nbefore\nTotal time taken in :  factorial 3.361701965332031e-05\n\n\n3628800\n\n\n\nfactorial = calculate_time(factorial)\n\ninside\n\n\n\nfactorial(10)\n\nbefore\nTotal time taken in :  factorial 0.00014400482177734375\n\n\n3628800\n\n\n\nfactorial(1)\n\nbefore\nTotal time taken in :  factorial 0.000186920166015625\n\n\n1\n\n\n\n@calculate_time\ndef factorial(num):\n \n    # sleep 2 seconds because it takes very less time\n    # so that you can see the actual difference\n\n    return math.factorial(num)\n\ninside\n\n\n\n# calling the function.\nfactorial(10)\n\nbefore\nTotal time taken in :  factorial 0.0002372264862060547\n\n\n3628800\n\n\n\nExample\n\ndef hello_decorator(func):\n    def inner1(*args, **kwargs):\n        \n        print(\"before Execution\")\n        \n        # getting the returned value\n        returned_value = func(*args, **kwargs)\n        print(\"after Execution\")\n        \n        # returning the value to the original frame\n        return returned_value\n        \n    return inner1\n\n\n# adding decorator to the function\n@hello_decorator\ndef sum_two_numbers(a, b):\n    print(\"Inside the function\")\n    return a + b\n\na, b = 1, 2\n\n# getting the value through return of the function\nprint(\"Sum =\", sum_two_numbers(a, b))\n\nbefore Execution\nInside the function\nafter Execution\nSum = 3\n\n\n\n\n\nDecorator Chaining\n\n# code for testing decorator chaining \ndef decor1(func):\n    def inner():\n        \n        x = func()\n        print(f'{x} * {x}')\n        return x * x\n    return inner \ndef decor(func):\n    def inner():\n        x = func()\n        print(f'2 * {x}')\n        return 2 * x\n    return inner\n \n\n\n@decor1\n@decor\ndef num(): \n    print(10)\n    return 10\n\n@decor\n@decor1\ndef num2():\n    print(10)\n    return 10\n\nprint(num()) \nprint(num2())\n\n10\n2 * 10\n20 * 20\n400\n10\n10 * 10\n2 * 100\n200\n\n\n\n\nDecorator with parameters\n\n# Python code to illustrate \n# Decorators with parameters in Python \n\ndef decorator_func(x, y):\n\n    def Inner(func):\n\n        def wrapper(*args, **kwargs):\n            print(\"I like Geeksforgeeks\")\n            print(\"Summation of values - {}\".format(x+y) )\n\n            func(*args, **kwargs)\n            \n        return wrapper\n    return Inner\n\n\n# Not using decorator \ndef my_fun(*args):\n    for ele in args:\n        print(ele)\n\n# another way of using decorators\ndecorator_func(12, 15)(my_fun)('Geeks', 'for', 'Geeks')\n\nI like Geeksforgeeks\nSummation of values - 27\nGeeks\nfor\nGeeks\n\n\n\n@decorator_func(12,15)\ndef my_fun(*args):\n    for ele in args:\n        print(ele)\n\n# another way of using decorators\nmy_fun('Geeks', 'for', 'Geeks')\n\nI like Geeksforgeeks\nSummation of values - 27\nGeeks\nfor\nGeeks",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#partials",
    "href": "Python/python_class.html#partials",
    "title": "Python Class",
    "section": "Partials",
    "text": "Partials\nPartial functions support both positional and keyword arguments to be used as fixed arguments.\ninput a function with inputs variables to be set\noutput new function with the variabes set\n\nfrom functools import partial\n\n\npartial??\n\n\nInit signature: partial(self, /, *args, **kwargs)\nDocstring:     \npartial(func, *args, **keywords) - new function with partial application\nof the given arguments and keywords.\nSource:        \nclass partial:\n    \"\"\"New function with partial application of the given arguments\n    and keywords.\n    \"\"\"\n    __slots__ = \"func\", \"args\", \"keywords\", \"__dict__\", \"__weakref__\"\n    def __new__(cls, func, /, *args, **keywords):\n        if not callable(func):\n            raise TypeError(\"the first argument must be callable\")\n        if hasattr(func, \"func\"):\n            args = func.args + args\n            keywords = {**func.keywords, **keywords}\n            func = func.func\n        self = super(partial, cls).__new__(cls)\n        self.func = func\n        self.args = args\n        self.keywords = keywords\n        return self\n    def __call__(self, /, *args, **keywords):\n        keywords = {**self.keywords, **keywords}\n        return self.func(*self.args, *args, **keywords)\n    @recursive_repr()\n    def __repr__(self):\n        qualname = type(self).__qualname__\n        args = [repr(self.func)]\n        args.extend(repr(x) for x in self.args)\n        args.extend(f\"{k}={v!r}\" for (k, v) in self.keywords.items())\n        if type(self).__module__ == \"functools\":\n            return f\"functools.{qualname}({', '.join(args)})\"\n        return f\"{qualname}({', '.join(args)})\"\n    def __reduce__(self):\n        return type(self), (self.func,), (self.func, self.args,\n               self.keywords or None, self.__dict__ or None)\n    def __setstate__(self, state):\n        if not isinstance(state, tuple):\n            raise TypeError(\"argument to __setstate__ must be a tuple\")\n        if len(state) != 4:\n            raise TypeError(f\"expected 4 items in state, got {len(state)}\")\n        func, args, kwds, namespace = state\n        if (not callable(func) or not isinstance(args, tuple) or\n           (kwds is not None and not isinstance(kwds, dict)) or\n           (namespace is not None and not isinstance(namespace, dict))):\n            raise TypeError(\"invalid partial state\")\n        args = tuple(args) # just in case it's a subclass\n        if kwds is None:\n            kwds = {}\n        elif type(kwds) is not dict: # XXX does it need to be *exactly* dict?\n            kwds = dict(kwds)\n        if namespace is None:\n            namespace = {}\n        self.__dict__ = namespace\n        self.func = func\n        self.args = args\n        self.keywords = kwds\nFile:           ~/mambaforge/envs/cfast/lib/python3.11/functools.py\nType:           type\nSubclasses:     \n\n\n\n\n# A normal function\ndef f(a, b, c, x):\n    return 1000*a + 100*b + 10*c + x\n \n# A partial function that calls f with\n# a as 3, b as 1 and c as 4.\ng = partial(f, 3, 1, 4)\n \n# Calling g()\nprint(g(5))\n\n3145\n\n\n\nfrom functools import *\n \n# A normal function\ndef add(a, b, c):\n    print(f'a:{a}, b:{b}, c:{c}')\n    return 100 * a + 10 * b + c\n \n# A partial function with b = 1 and c = 2\nadd_part = partial(add, c = 2, b = 1)\n \n# Calling partial function\nprint(add_part(3))\n\na:3, b:1, c:2\n312\n\n\n\ndef greater_than(a, b):\n    return a &lt; b\n\ngreater_than(5,10)\n\ndef make_comparator(n):\n    def inner(a):\n        return a &lt; n\n\n    return inner\n\n\ndef partial(*args):\n    def inner(a):\n        return args[0](args[1],a)\n    return inner\n\n\ngreater_than_20 = make_comparator(20)\n\n\ngreater_than_20(40)\n\nFalse\n\n\n\ngreater_than_2 = partial(greater_than,2)\n\n\ngreater_than_2(2)\n\nFalse",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#args-and-kwargs-in-python",
    "href": "Python/python_class.html#args-and-kwargs-in-python",
    "title": "Python Class",
    "section": "*args and **kwargs in Python",
    "text": "*args and **kwargs in Python\n\n*args\n\ndef myFun(*argv):\n    for arg in argv:\n        print(arg)\n \n \nmyFun('Hello', 'Welcome', 'to', 'GeeksforGeeks')\n\nHello\nWelcome\nto\nGeeksforGeeks\n\n\n\ndef myFun(arg1, *argv):\n    print(\"First argument :\", arg1)\n    for arg in argv:\n        print(\"Next argument through *argv :\", arg)\n \n \nmyFun('Hello', 'Welcome', 'to', 'GeeksforGeeks')\n\nFirst argument : Hello\nNext argument through *argv : Welcome\nNext argument through *argv : to\nNext argument through *argv : GeeksforGeeks\n\n\n\n\n**kwargs\n\ndef myFun(**kwargs):\n    for key, value in kwargs.items():\n        print(\"%s == %s\" % (key, value))\n \n \n# Driver code\nmyFun(first='Geeks', mid='for', last='Geeks')\n\nfirst == Geeks\nmid == for\nlast == Geeks\n\n\n\ndef myFun(arg1, **kwargs):\n    for key, value in kwargs.items():\n        print(\"%s == %s\" % (key, value))\n \n \n# Driver code\nmyFun(\"Hi\",  first='Geeks', mid='for', last='Geeks')\n\nfirst == Geeks\nmid == for\nlast == Geeks\n\n\n\ndef myFun(arg1, arg2, arg3):\n    print(\"arg1:\", arg1)\n    print(\"arg2:\", arg2)\n    print(\"arg3:\", arg3)\n \n \n# Now we can use *args or **kwargs to\n# pass arguments to this function :\nargs = (\"Geeks\", \"for\", \"Geeks\")\nmyFun(*args)\n \nkwargs = {\"arg1\": \"Geeks\", \"arg2\": \"for\", \"arg3\": \"Geeks\"}\nmyFun(**kwargs)\n\narg1: Geeks\narg2: for\narg3: Geeks\narg1: Geeks\narg2: for\narg3: Geeks\n\n\n\ndef myFun(*args, **kwargs):\n    print(\"args: \", args)\n    print(\"kwargs: \", kwargs)\n \n \n# Now we can use both *args ,**kwargs\n# to pass arguments to this function :\nmyFun('geeks', 'for', 'geeks', first=\"Geeks\", mid=\"for\", last=\"Geeks\")\n\nargs:  ('geeks', 'for', 'geeks')\nkwargs:  {'first': 'Geeks', 'mid': 'for', 'last': 'Geeks'}\n\n\n\n# defining car class\nclass car():\n    # args receives unlimited no. of arguments as an array\n    def __init__(self, *args):\n        # access args index like array does\n        self.speed = args[0]\n        self.color = args[1]\n \n \n# creating objects of car class\naudi = car(200, 'red')\nbmw = car(250, 'black')\nmb = car(190, 'white')\n \n# printing the color and speed of the cars\nprint(audi.color)\nprint(bmw.speed)\n\nred\n250\n\n\n\n# defining car class\nclass car():\n    # args receives unlimited no. of arguments as an array\n    def __init__(self, **kwargs):\n        # access args index like array does\n        self.speed = kwargs['s']\n        self.color = kwargs['c']\n \n \n# creating objects of car class\naudi = car(s=200, c='red')\nbmw = car(s=250, c='black')\nmb = car(s=190, c='white')\n \n# printing the color and speed of cars\nprint(audi.color)\nprint(bmw.speed)\n\nred\n250",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#yield",
    "href": "Python/python_class.html#yield",
    "title": "Python Class",
    "section": "Yield",
    "text": "Yield\n\ndef simpleGeneratorFun():\n    yield 1\n    yield 2\n    yield 3\n \n \n# Driver code to check above generator function\nfor value in simpleGeneratorFun():\n    print(value)\n\n1\n2\n3\n\n\n\ndef nextSquare():\n    i = 1\n \n    # An Infinite loop to generate squares\n    while True:\n        yield i*i\n        i += 1  # Next execution resumes\n        # from this point\n \n \n# Driver code to test above generator\n# function\nfor num in nextSquare():\n    if num &gt; 100:\n        break\n    print(num)\n\n1\n4\n9\n16\n25\n36\n49\n64\n81\n100",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#generators",
    "href": "Python/python_class.html#generators",
    "title": "Python Class",
    "section": "Generators",
    "text": "Generators\n\n# A generator function \ndef simpleGeneratorFun(): \n    yield 1\n    yield 2\n    yield 3\n    \n    \n    \n# x is a generator object \nx = simpleGeneratorFun() \n  \n# Iterating over the generator object using next \n  \n# In Python 3, __next__() \nprint(next(x)) \nprint(next(x)) \nprint(next(x))\n\n1\n2\n3\n\n\n\n# generator expression \ngenerator_exp = (i for i in range(5)) \n\nfor i in generator_exp: \n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\n# generator expression \ngenerator_exp = (i * 5 for i in range(5) if i%2==0) \n\nfor i in generator_exp: \n    print(i)\n\n0\n10\n20",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#lambda",
    "href": "Python/python_class.html#lambda",
    "title": "Python Class",
    "section": "Lambda",
    "text": "Lambda\n\ncalc = lambda num: \"Even number\" if num % 2 == 0 else \"Odd number\"\n \nprint(calc(20))\n\nEven number\n\n\n\ndef cube(y):\n    print(f\"Finding cube of number:{y}\")\n    return y * y * y\n \nlambda_cube = lambda num: num ** 3\n \n# invoking simple function\nprint(\"invoking function defined with def keyword:\")\nprint(cube(30))\n# invoking lambda function\nprint(\"invoking lambda function:\", lambda_cube(30))\n\ninvoking function defined with def keyword:\nFinding cube of number:30\n27000\ninvoking lambda function: 27000",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "Python/python_class.html#pdb",
    "href": "Python/python_class.html#pdb",
    "title": "Python Class",
    "section": "PDB",
    "text": "PDB\n\nimport pdb; pdb.set_trace()\n\n--Call--\n&gt; /home/benedict/mambaforge/envs/cfast/lib/python3.11/site-packages/IPython/core/displayhook.py(258)__call__()\n    256         sys.stdout.flush()\n    257 \n--&gt; 258     def __call__(self, result=None):\n    259         \"\"\"Printing with history cache management.\n    260 \n\n\n\nipdb&gt;  help\n\n\n\nDocumented commands (type help &lt;topic&gt;):\n========================================\nEOF    commands   enable    ll        pp       s                until \na      condition  exit      longlist  psource  skip_hidden      up    \nalias  cont       h         n         q        skip_predicates  w     \nargs   context    help      next      quit     source           whatis\nb      continue   ignore    p         r        step             where \nbreak  d          interact  pdef      restart  tbreak         \nbt     debug      j         pdoc      return   u              \nc      disable    jump      pfile     retval   unalias        \ncl     display    l         pinfo     run      undisplay      \nclear  down       list      pinfo2    rv       unt            \n\nMiscellaneous help topics:\n==========================\nexec  pdb\n\n\n\nipdb&gt;  exit",
    "crumbs": [
      "Blog",
      "Python",
      "Python Class"
    ]
  },
  {
    "objectID": "dask.html",
    "href": "dask.html",
    "title": "Dask",
    "section": "",
    "text": "Dask Arrays\n\n\nDask arrays extend NumPy arrays to support larger-than-memory computations by splitting the array into many smaller chunks, each one a NumPy array.\n\n\nDask DataFrames\n\n\nDask DataFrames extend pandas DataFrames for parallel and distributed computing. They are composed of many smaller pandas DataFrames.\n\n\nDask Bags\n\n\nDask Bags are like parallel lists that provide map, filter, and groupby operations on potentially larger-than-memory datasets.\n\n\nDask Delayed\n\n\nDask Delayed allows you to build task graphs in a low-level way, specifying operations and dependencies between them. It’s useful for custom workflows.\n\n\nDask Distributed\n\n\nDask Distributed is a distributed computing framework that scales Dask workflows to a cluster of machines. It includes a task scheduler and workers.",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#key-concepts-and-components",
    "href": "dask.html#key-concepts-and-components",
    "title": "Dask",
    "section": "",
    "text": "Dask Arrays\n\n\nDask arrays extend NumPy arrays to support larger-than-memory computations by splitting the array into many smaller chunks, each one a NumPy array.\n\n\nDask DataFrames\n\n\nDask DataFrames extend pandas DataFrames for parallel and distributed computing. They are composed of many smaller pandas DataFrames.\n\n\nDask Bags\n\n\nDask Bags are like parallel lists that provide map, filter, and groupby operations on potentially larger-than-memory datasets.\n\n\nDask Delayed\n\n\nDask Delayed allows you to build task graphs in a low-level way, specifying operations and dependencies between them. It’s useful for custom workflows.\n\n\nDask Distributed\n\n\nDask Distributed is a distributed computing framework that scales Dask workflows to a cluster of machines. It includes a task scheduler and workers.",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#installation",
    "href": "dask.html#installation",
    "title": "Dask",
    "section": "Installation",
    "text": "Installation\npip install dask[complete]  # Installs core Dask and extras\n\nFor the distributed scheduler, you might need\n\npip install dask distributed",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#dask-arrays",
    "href": "dask.html#dask-arrays",
    "title": "Dask",
    "section": "Dask Arrays",
    "text": "Dask Arrays\n\nDask arrays work similarly to NumPy arrays but can operate on data too large to fit into memory.\n\n\nimport dask.array as da\n\n# Create a large Dask array with chunks\nx = da.random.random((10000, 10000), chunks=(1000, 1000))\n\n# Compute the sum along an axis\nresult = x.mean(axis=0)\n\n# Trigger computation\nresult = result.compute()",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#dask-dataframes",
    "href": "dask.html#dask-dataframes",
    "title": "Dask",
    "section": "Dask DataFrames",
    "text": "Dask DataFrames\n\nDask DataFrames are similar to pandas DataFrames but designed for parallel processing on larger datasets.\n\n\nimport dask.dataframe as dd\nimport pandas as pd\n\nnew = pd.DataFrame(x)\n\n/home/ben/miniconda3/envs/pfast/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \nDask dataframe query planning is disabled because dask-expr is not installed.\n\nYou can install it with `pip install dask[dataframe]` or `conda install dask`.\nThis will raise in a future version.\n\n  warnings.warn(msg, FutureWarning)\n\n\n\ndask_df = dd.from_pandas(new, npartitions=10)\n\n\n# Read a large CSV file into a Dask DataFrame\ndf = dask_df\n\n# Perform some operations\nresult = df[df[0] &gt; 0.5].mean()\n\n# Compute the result\nresult = result.compute()\nresult\n\n0       0.752109\n1       0.498086\n2       0.500595\n3       0.501720\n4       0.501788\n          ...   \n9995    0.503008\n9996    0.497020\n9997    0.498570\n9998    0.494503\n9999    0.496511\nLength: 10000, dtype: float64",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#dask-bags",
    "href": "dask.html#dask-bags",
    "title": "Dask",
    "section": "Dask Bags",
    "text": "Dask Bags\n\nDask Bags are useful for working with unstructured or semi-structured data, such as text data\n\n\nimport dask.bag as db\n\n# Create a Dask Bag from a list\ndata = db.from_sequence([1, 2, 3, 4, 5])\n\n# Apply a function to each element\nsquares = data.map(lambda x: x ** 2)\n\n# Compute the result\nresult = squares.compute()",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#dask-delayed",
    "href": "dask.html#dask-delayed",
    "title": "Dask",
    "section": "Dask Delayed",
    "text": "Dask Delayed\n\nDask Delayed allows for parallel execution by specifying the dependencies between tasks\n\n\nfrom dask import delayed\n\n@delayed\ndef add(x, y):\n    return x + y\n\n@delayed\ndef sum_list(lst):\n    return sum(lst)\n\n# Define a computation graph\nx = add(1, 2)\ny = add(3, 4)\ntotal = sum_list([x, y])\ntotal\n\nDelayed('sum_list-bf70cda4-342a-46f4-8ebe-d863e28fea4e')\n\n\n\n# Compute the result\nresult = total.compute()",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#dask-distributed",
    "href": "dask.html#dask-distributed",
    "title": "Dask",
    "section": "Dask Distributed",
    "text": "Dask Distributed\n\nDask Distributed allows scaling computations to multiple machines. Start a local cluster\n\nfrom dask.distributed import Client\n\n# Start a local cluster\nclient = Client()\n\n# Check cluster status\nprint(client)\n\n# Example with Dask DataFrame\nimport dask.dataframe as dd\n\n# Read a CSV file and perform operations\ndf = dask_df\nresult = df.groupby(0).mean().compute()",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "dask.html#monitoring-and-debugging",
    "href": "dask.html#monitoring-and-debugging",
    "title": "Dask",
    "section": "Monitoring and Debugging",
    "text": "Monitoring and Debugging\n\nDask provides several tools for monitoring and debugging:\n\n\nDask Dashboard: A web-based interface that shows the status of computations and the Dask cluster.\nVisualizing Task Graphs: Use dask.visualize to visualize task graphs and understand dependencies.\nLogs and Errors: Dask provides detailed logging to help identify and fix issues.",
    "crumbs": [
      "Blog",
      "Dask"
    ]
  },
  {
    "objectID": "Other/mito.html",
    "href": "Other/mito.html",
    "title": "Mito",
    "section": "",
    "text": "!pip list | grep mitosheet\n\nmitosheet                     0.1.530\n\n\n\nimport mitosheet\n\n\nmitosheet.sheet(analysis_to_replay=\"id-qdjqkelpwx\")\n\n\n        \n    \n\n\n\nfrom mitosheet.public.v3 import *; # Analysis Name:id-qdjqkelpwx;\nimport pandas as pd\n\n# Imported salaries.csv\nsalaries = pd.read_csv(r'/home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/ML/nbs/Data/salaries.csv')\n\n# sort the column company in ascending order\nsalaries.sort_values('company', ascending=True, inplace=True)\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Other",
      "Mito"
    ]
  },
  {
    "objectID": "Other/pivottablesjs.html",
    "href": "Other/pivottablesjs.html",
    "title": "Pivot Tables js",
    "section": "",
    "text": "import pandas as pd\nfrom pivottablejs import pivot_ui\nimport ipypivot as pt\n\ndf = pd.read_csv('Data/salaries.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncompany\njob\ndegree\nsalary_more_then_100k\n\n\n\n\n0\ngoogle\nsales executive\nbachelors\n0\n\n\n1\ngoogle\nsales executive\nmasters\n0\n\n\n2\ngoogle\nbusiness manager\nbachelors\n1\n\n\n3\ngoogle\nbusiness manager\nmasters\n1\n\n\n4\ngoogle\ncomputer programmer\nbachelors\n0\n\n\n\n\n\n\n\n\npivot_ui(df)\n\n\n        \n        \n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Other",
      "Pivot Tables js"
    ]
  },
  {
    "objectID": "1_polars.html",
    "href": "1_polars.html",
    "title": "Polars",
    "section": "",
    "text": "pip install polars[all] jupyterlab",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#installation",
    "href": "1_polars.html#installation",
    "title": "Polars",
    "section": "",
    "text": "pip install polars[all] jupyterlab",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#basic-usage-in-jupyter",
    "href": "1_polars.html#basic-usage-in-jupyter",
    "title": "Polars",
    "section": "📦 2. Basic Usage in Jupyter",
    "text": "📦 2. Basic Usage in Jupyter\nimport polars as pl\n\n# Read CSV\ndf = pl.read_csv(\"data.csv\")\n\n# Show head\ndf.head()\n\n# Select and filter\ndf.select([\"col1\", \"col2\"]).filter(pl.col(\"col1\") &gt; 10)",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#eager-vs-lazy-mode",
    "href": "1_polars.html#eager-vs-lazy-mode",
    "title": "Polars",
    "section": "⚙️ 3. Eager vs Lazy Mode",
    "text": "⚙️ 3. Eager vs Lazy Mode\n\n\n\nMode\nDescription\n\n\n\n\nEager (default)\nExecutes immediately (like Pandas)\n\n\nLazy\nBuilds a computation graph and optimizes it\n\n\n\n\n# Lazy version\nldf = pl.read_csv(\"data.csv\").lazy()\nresult = ldf.filter(pl.col(\"price\") &gt; 100).select([\"item\", \"price\"]).collect()",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#advanced-polars-features",
    "href": "1_polars.html#advanced-polars-features",
    "title": "Polars",
    "section": "🧠 4. Advanced Polars Features",
    "text": "🧠 4. Advanced Polars Features\n\n📊 A. Custom Expressions\ndf.with_columns([\n    (pl.col(\"price\") * 0.1).alias(\"tax\"),\n    pl.col(\"name\").str.to_uppercase()\n])\n\n\n📈 B. GroupBy + Aggregations\ndf.groupby(\"category\").agg([\n    pl.col(\"price\").mean().alias(\"avg_price\"),\n    pl.count().alias(\"count\")\n])\n\n\n🔁 C. Join Operations\ndf1.join(df2, on=\"id\", how=\"inner\")\n\n\n\nJoin Type\nDescription\n\n\n\n\ninner\nOnly matching rows\n\n\nleft / outer\nKeep left/all rows\n\n\nsemi / anti\nExists / doesn’t exist in right\n\n\n\n\n\nD. Window Functions\n\ndf.sort(\"timestamp\").with_columns([\n   pl.col(\"price\").rolling_mean(window_size=3).over(\"category\")\n])\n\nUseful for moving averages, cumulative stats, and rankings.\n\n\n\n🧪 E. Pivot and Melt\n\n# Pivot\ndf.pivot(values=\"value\", index=\"date\", columns=\"category\", aggregate_fn=\"sum\")\n\n# Melt (unpivot)\ndf.melt(id_vars=\"date\", value_vars=[\"sales_a\", \"sales_b\"])",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#readwrite-support",
    "href": "1_polars.html#readwrite-support",
    "title": "Polars",
    "section": "📁 5. Read/Write Support",
    "text": "📁 5. Read/Write Support\n\n\n\nFormat\nMethod\n\n\n\n\nCSV\npl.read_csv, df.write_csv\n\n\nParquet\npl.read_parquet, df.write_parquet\n\n\nJSON\npl.read_json, df.write_json\n\n\nIPC/Arrow\npl.read_ipc, df.write_ipc",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#interoperability",
    "href": "1_polars.html#interoperability",
    "title": "Polars",
    "section": "🎯 6. Interoperability",
    "text": "🎯 6. Interoperability\n\n🔁 Convert between Polars ↔︎ Pandas\nimport pandas as pd\n\ndf_pl = pl.DataFrame(pd_df)       # from pandas\npd_df = df_pl.to_pandas()         # to pandas\n\n\n📊 Plotting\nPolars doesn’t support plotting directly — convert to Pandas:\n\nimport matplotlib.pyplot as plt\n\ndf_pl.to_pandas().plot(x=\"date\", y=\"sales\")\nplt.show()",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#performance-tuning-tips",
    "href": "1_polars.html#performance-tuning-tips",
    "title": "Polars",
    "section": "⚡ 7. Performance Tuning Tips",
    "text": "⚡ 7. Performance Tuning Tips\n\nUse lazy evaluation for large workflows\nMinimize .collect() calls\nPrefer pl.struct() for group-wise operations\nUse categorical or integer types for joins\nCombine .filter().select().groupby() in a lazy pipeline",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#debugging-inspection-in-jupyter",
    "href": "1_polars.html#debugging-inspection-in-jupyter",
    "title": "Polars",
    "section": "🔬 8. Debugging & Inspection in Jupyter",
    "text": "🔬 8. Debugging & Inspection in Jupyter\n# Schema inspection\ndf.schema\n\n# Data types\ndf.dtypes\n\n# Lazy query plan (before execution)\nldf.describe_plan()",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#streaming-chunked-data-advanced",
    "href": "1_polars.html#streaming-chunked-data-advanced",
    "title": "Polars",
    "section": "📦 9. Streaming & Chunked Data (Advanced)",
    "text": "📦 9. Streaming & Chunked Data (Advanced)\n\nfor chunk in pl.read_csv(\"big.csv\", chunk_size=100_000):\n    process(chunk)\nUseful for real-time or out-of-core processing.",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#plugins-ecosystem-integration",
    "href": "1_polars.html#plugins-ecosystem-integration",
    "title": "Polars",
    "section": "🧩 10. Plugins & Ecosystem Integration",
    "text": "🧩 10. Plugins & Ecosystem Integration\n\n\n\nTool\nIntegration\n\n\n\n\nDuckDB\nDirect querying via pl.read_database()\n\n\nArrow\nNative backend format; fast interop\n\n\nSQL (via DuckDB)\nduckdb.query(\"SELECT ...\").pl()\n\n\nMachine Learning\nUse .to_pandas() or convert to numpy()",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#benchmarking-example",
    "href": "1_polars.html#benchmarking-example",
    "title": "Polars",
    "section": "📈 11. Benchmarking Example",
    "text": "📈 11. Benchmarking Example\nimport time\ndf = pl.read_csv(\"big.csv\")\n\nstart = time.time()\ndf.groupby(\"category\").agg(pl.col(\"price\").mean())\nprint(\"Elapsed:\", time.time() - start)",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "1_polars.html#cheat-sheet-summary",
    "href": "1_polars.html#cheat-sheet-summary",
    "title": "Polars",
    "section": "📚 12. Cheat Sheet Summary",
    "text": "📚 12. Cheat Sheet Summary\n\n\n\nOperation\nCode\n\n\n\n\nFilter\ndf.filter(pl.col(\"x\") &gt; 5)\n\n\nSelect\ndf.select([\"a\", \"b\"])\n\n\nGroupBy + Mean\ndf.groupby(\"cat\").agg(pl.col(\"x\").mean())\n\n\nJoin\ndf1.join(df2, on=\"id\")\n\n\nConvert to Pandas\ndf.to_pandas()\n\n\nLazy collect\nldf.collect()\n\n\nSort\ndf.sort(\"x\", descending=True)\n\n\nWindow fn\npl.col(\"val\").cum_sum().over(\"group\")",
    "crumbs": [
      "Blog",
      "Polars"
    ]
  },
  {
    "objectID": "nbdev.html",
    "href": "nbdev.html",
    "title": "Nbdev",
    "section": "",
    "text": "Python\nA Python package manager: we recommend conda or pip - download anaconda\nJupyter Notebook - see below\nnbdev - see below\nQuarto - see quarto setup\n\n\n\npip install jupyterlab\nmamba install -c conda-forge jupyterlab\nTo launch jupyter labs\njupyter lab\nTo install nbdev\npip install nbdev\nmamba install -c fastai nbdev\n\nget instructin for quarto with\n\nnbdev_install_quarto\nInstall the extension by entering:\npip install jupyterlab-quarto",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#installation",
    "href": "nbdev.html#installation",
    "title": "Nbdev",
    "section": "",
    "text": "Python\nA Python package manager: we recommend conda or pip - download anaconda\nJupyter Notebook - see below\nnbdev - see below\nQuarto - see quarto setup\n\n\n\npip install jupyterlab\nmamba install -c conda-forge jupyterlab\nTo launch jupyter labs\njupyter lab\nTo install nbdev\npip install nbdev\nmamba install -c fastai nbdev\n\nget instructin for quarto with\n\nnbdev_install_quarto\nInstall the extension by entering:\npip install jupyterlab-quarto",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#create-an-empty-github-repo",
    "href": "nbdev.html#create-an-empty-github-repo",
    "title": "Nbdev",
    "section": "Create an empty GitHub repo",
    "text": "Create an empty GitHub repo\n\nmake it public\nadd a gitignore file\nclone it into project location\n\ngit clone https://github.com/PROEJECT_NAME.git",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#run-nbdev",
    "href": "nbdev.html#run-nbdev",
    "title": "Nbdev",
    "section": "RUN Nbdev",
    "text": "RUN Nbdev\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\nDo a git push to make sure everything is working\n\ngit add .\ngit commit -m'Initial commit'\ngit push\n\nGo to settings on Github, go to pages, Change Branch to gh-pages\n\n\nThen check on Actions",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#useful-commands",
    "href": "nbdev.html#useful-commands",
    "title": "Nbdev",
    "section": "Useful commands",
    "text": "Useful commands\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\nStart the preview by entering this into your terminal:\nnbdev_preview\nBefore every git push, run :\nnbdev_prepare\nWhich is the combination of:\nnbdev_export\nBuilds the .py modules from Jupyter notebooks\nnbdev_test\nTests your notebooks\nnbdev_clean\nCleans your notebooks to get rid of extreanous output for git\nnbdev_readme\nUpdates your repo’s README.md file from your index notebook.",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#directives-for-documentation",
    "href": "nbdev.html#directives-for-documentation",
    "title": "Nbdev",
    "section": "Directives for documentation:",
    "text": "Directives for documentation:\n#|hide\n\nHide cell input and output.\n\n#|echo: &lt;true|false&gt;\n\nToggle the visibility of code-cell inputs.\n\n#|output: &lt;true|false|asis&gt;\n\nSetting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown.\n\n#|hide_line\n\nHide a specific line of code in an input cell.\n\n#|code-fold: &lt;show|true&gt;\n\nThe #|code-fold directive allows you to collapse code cells. When set to true, the element is collapsed by default, when set to show show the element is shown by default.\n\n\nExports\n#|default_exp &lt;name&gt;\n\nNames the module where cells with the #|export directive will be exported to by default.\n\n#|export\n\nExports the items in the cell into the generated module and documentation.\n\n#|exports\n\nA source export. Like #|export but in addition to showing docs via showdoc.show_doc, it also shows the source code.\n\n#|exec_doc\n\nEnsures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here.\n\n#|eval: &lt;true|false&gt;\n\nWhen set to false, the cell is ignored during testing.",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "nbdev.html#testing",
    "href": "nbdev.html#testing",
    "title": "Nbdev",
    "section": "Testing",
    "text": "Testing\n\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\n\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nUsing\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as: \\[\\sum_{i=1}^{k+1}i\\]\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\n\nBecomes: This version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.",
    "crumbs": [
      "Blog",
      "Nbdev"
    ]
  },
  {
    "objectID": "black.html",
    "href": "black.html",
    "title": "Black",
    "section": "",
    "text": "Purpose: Black formats Python code to follow a consistent style. It automates formatting, saving time and avoiding manual reformatting errors.\nPhilosophy: Code formatting should be deterministic, and Black prioritizes code readability and simplicity.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#what-is-black",
    "href": "black.html#what-is-black",
    "title": "Black",
    "section": "",
    "text": "Purpose: Black formats Python code to follow a consistent style. It automates formatting, saving time and avoiding manual reformatting errors.\nPhilosophy: Code formatting should be deterministic, and Black prioritizes code readability and simplicity.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#key-features",
    "href": "black.html#key-features",
    "title": "Black",
    "section": "2. Key Features",
    "text": "2. Key Features\n\nDeterministic Formatting: Given the same code, Black will always produce the same output.\nMinimal Configuration: Black enforces a single style with very few customization options.\nSpeed and Safety: It’s fast and guarantees that formatting will not change your code’s functionality.\nSupport for Python Versions: Black supports Python 3.6+ and Python 2.7 (with reduced functionality for legacy versions).",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#installation",
    "href": "black.html#installation",
    "title": "Black",
    "section": "3. Installation",
    "text": "3. Installation\nInstall Black via pip:\npip install black\nAlternatively, use pipx for an isolated environment:\npipx install black",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#usage",
    "href": "black.html#usage",
    "title": "Black",
    "section": "4. Usage",
    "text": "4. Usage\nRun Black on a file or directory:\nblack filename.py\nblack path/to/code/\n\nCommon Options\n\nCheck for Formatting: Check if code is formatted without changing it:\nblack --check .\nShow Changes: See what changes Black would make:\nblack --diff .\nExclude Files: Skip specific files or directories:\nblack --exclude \"migrations|env\"\nLine Length: Adjust line length (default is 88):\nblack --line-length 79 .\nSafe Mode: Skip files with syntax errors:\nblack --safe .",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#configuration",
    "href": "black.html#configuration",
    "title": "Black",
    "section": "5. Configuration",
    "text": "5. Configuration\n\nUsing pyproject.toml\nBlack can be configured via a pyproject.toml file:\n[tool.black]\nline-length = 88\ntarget-version = ['py38']\ninclude = '\\.pyi?$'\nexclude = '''\n/(\n    \\.git\n  | \\.mypy_cache\n  | \\.pytest_cache\n  | \\.tox\n  | _build\n  | buck-out\n  | build\n  | dist\n)/\n'''\nPlace the pyproject.toml file in the root directory of your project.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#features",
    "href": "black.html#features",
    "title": "Black",
    "section": "6. Features",
    "text": "6. Features\n\na. Line Wrapping\n\nLines exceeding the specified length (--line-length) are automatically wrapped.\nBlack prioritizes readability when wrapping.\n\n\n\nb. String Normalization\n\nBy default, Black normalizes all strings to double quotes (\"):\nprint(\"This is Black-formatted.\")\n\nDisable this behavior with the --skip-string-normalization flag:\nblack --skip-string-normalization .\n\n\nc. Implicit vs. Explicit Line Joins\n\nBlack uses parentheses for line continuations instead of backslashes.\n\nExample:\n# Before\nx = 1 + 2 + \\\n    3\n\n# After\nx = (\n    1 + 2 +\n    3\n)",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#integration",
    "href": "black.html#integration",
    "title": "Black",
    "section": "7. Integration",
    "text": "7. Integration\n\na. IDE Integration\n\nVS Code:\n\nInstall the Python extension.\nSet Black as the formatter:\n\nGo to Settings &gt; Search for “Python Formatting Provider” &gt; Select Black.\n\nEnable “Format on Save”:\n\nGo to Settings &gt; Search for “Format on Save” &gt; Enable it.\n\n\nPyCharm:\n\nInstall Black globally or in your virtual environment.\nSet up a File Watcher:\n\nGo to File &gt; Settings &gt; Tools &gt; File Watchers.\nAdd a new watcher for Black.\n\n\n\n\n\nb. Pre-commit Hooks\nUse pre-commit to enforce Black before committing code:\n\nInstall pre-commit:\npip install pre-commit\nAdd .pre-commit-config.yaml:\nrepos:\n- repo: https://github.com/psf/black\n  rev: 23.1.0  # Replace with the latest version\n  hooks:\n  - id: black\nInstall the hook:\npre-commit install\nNow, Black will automatically run on changed files before every commit.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#continuous-integration",
    "href": "black.html#continuous-integration",
    "title": "Black",
    "section": "8. Continuous Integration",
    "text": "8. Continuous Integration\n\nExample: GitHub Actions\nAdd Black to your CI pipeline:\nname: Python Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: 3.9\n    - name: Install dependencies\n      run: pip install black\n    - name: Run Black\n      run: black --check .",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#combining-black-with-isort",
    "href": "black.html#combining-black-with-isort",
    "title": "Black",
    "section": "9. Combining Black with isort",
    "text": "9. Combining Black with isort\nisort formats imports. Use it alongside Black:\n\nInstall isort:\npip install isort\nRun isort and Black together:\nisort . && black .\nAdd both to your pre-commit hooks:\nrepos:\n- repo: https://github.com/pycqa/isort\n  rev: 5.10.1\n  hooks:\n  - id: isort\n\n- repo: https://github.com/psf/black\n  rev: 23.1.0\n  hooks:\n  - id: black",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#advantages-of-black",
    "href": "black.html#advantages-of-black",
    "title": "Black",
    "section": "10. Advantages of Black",
    "text": "10. Advantages of Black\n\nConsistency: Eliminates debates over style.\nAutomation: Saves time with automatic formatting.\nCollaboration: Teams can focus on functionality instead of style.\nTool Integration: Works seamlessly with IDEs, pre-commit, and CI tools.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#limitations",
    "href": "black.html#limitations",
    "title": "Black",
    "section": "11. Limitations",
    "text": "11. Limitations\n\nNo Custom Styles: Black enforces a strict style with minimal customization.\nChanges Code Structure: Some developers may find the formatting disruptive (e.g., line wrapping decisions).\nFormatting-First: Black does not lint for correctness; use tools like flake8 for that.",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "black.html#common-issues",
    "href": "black.html#common-issues",
    "title": "Black",
    "section": "12. Common Issues",
    "text": "12. Common Issues\n\na. Black Not Formatting Code\nEnsure Black is installed and the Python environment\n\nx = 1 + 2 + \\\n    3",
    "crumbs": [
      "Blog",
      "Black"
    ]
  },
  {
    "objectID": "request&httpx.html",
    "href": "request&httpx.html",
    "title": "Requests and Httpx",
    "section": "",
    "text": "pip install requests httpx",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#installing-requests-and-httpx",
    "href": "request&httpx.html#installing-requests-and-httpx",
    "title": "Requests and Httpx",
    "section": "",
    "text": "pip install requests httpx",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#basic-usage-get-and-post-requests",
    "href": "request&httpx.html#basic-usage-get-and-post-requests",
    "title": "Requests and Httpx",
    "section": "2. Basic Usage: GET and POST Requests",
    "text": "2. Basic Usage: GET and POST Requests\n\nUsing requests\nimport requests\n\n# GET Request\nresponse = requests.get(\"https://jsonplaceholder.typicode.com/todos/1\")\nprint(response.json())  # Convert response to JSON\n\n# POST Request\ndata = {\"title\": \"New Task\", \"completed\": False}\nresponse = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=data)\nprint(response.status_code, response.json())\n\n\nUsing httpx (Sync)\nimport httpx\n\n# GET Request\nresponse = httpx.get(\"https://jsonplaceholder.typicode.com/todos/1\")\nprint(response.json())\n\n# POST Request\nresponse = httpx.post(\"https://jsonplaceholder.typicode.com/todos\", json=data)\nprint(response.status_code, response.json())\n\n\nUsing httpx (Async)\nimport httpx\nimport asyncio\n\nasync def fetch():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://jsonplaceholder.typicode.com/todos/1\")\n        print(response.json())\n\nasyncio.run(fetch())",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#key-differences-between-requests-and-httpx",
    "href": "request&httpx.html#key-differences-between-requests-and-httpx",
    "title": "Requests and Httpx",
    "section": "3. Key Differences Between requests and httpx",
    "text": "3. Key Differences Between requests and httpx\n\n\n\nFeature\nrequests\nhttpx\n\n\n\n\nSync Support\n✅ Yes\n✅ Yes\n\n\nAsync Support\n❌ No\n✅ Yes (AsyncClient)\n\n\nHTTP/2 Support\n❌ No\n✅ Yes\n\n\nConnection Pooling\n❌ No\n✅ Yes\n\n\nTimeouts\n✅ Yes\n✅ Yes\n\n\nStreaming Support\n✅ Yes\n✅ Yes\n\n\nCookies & Sessions\n✅ Yes\n✅ Yes",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#handling-headers-parameters-and-cookies",
    "href": "request&httpx.html#handling-headers-parameters-and-cookies",
    "title": "Requests and Httpx",
    "section": "4. Handling Headers, Parameters, and Cookies",
    "text": "4. Handling Headers, Parameters, and Cookies\nheaders = {\"Authorization\": \"Bearer mytoken\"}\nparams = {\"search\": \"python\"}\n\n# With requests\nresponse = requests.get(\"https://api.example.com/data\", headers=headers, params=params)\nprint(response.json())\n\n# With httpx\nresponse = httpx.get(\"https://api.example.com/data\", headers=headers, params=params)\nprint(response.json())\n\nCookies Example\n# With requests\nsession = requests.Session()\nsession.cookies.set(\"session_id\", \"abc123\")\n\n# With httpx\nclient = httpx.Client()\nclient.cookies.set(\"session_id\", \"abc123\")",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#file-uploads",
    "href": "request&httpx.html#file-uploads",
    "title": "Requests and Httpx",
    "section": "5. File Uploads",
    "text": "5. File Uploads\nfiles = {\"file\": open(\"example.txt\", \"rb\")}\n\n# Using requests\nresponse = requests.post(\"https://api.example.com/upload\", files=files)\nprint(response.json())\n\n# Using httpx\nresponse = httpx.post(\"https://api.example.com/upload\", files=files)\nprint(response.json())",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#handling-timeouts-and-retries",
    "href": "request&httpx.html#handling-timeouts-and-retries",
    "title": "Requests and Httpx",
    "section": "6. Handling Timeouts and Retries",
    "text": "6. Handling Timeouts and Retries\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry\n\nsession = requests.Session()\nretries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\nsession.mount(\"https://\", HTTPAdapter(max_retries=retries))\n\ntry:\n    response = session.get(\"https://api.example.com/data\", timeout=5)\n    print(response.json())\nexcept requests.exceptions.Timeout:\n    print(\"Request timed out!\")\nimport httpx\n\nclient = httpx.Client(timeout=httpx.Timeout(10.0))\n\ntry:\n    response = client.get(\"https://api.example.com/data\")\n    print(response.json())\nexcept httpx.TimeoutException:\n    print(\"Request timed out!\")",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#authentication-basic-token-oauth",
    "href": "request&httpx.html#authentication-basic-token-oauth",
    "title": "Requests and Httpx",
    "section": "7. Authentication (Basic, Token, OAuth)",
    "text": "7. Authentication (Basic, Token, OAuth)\n\nBasic Authentication\nfrom requests.auth import HTTPBasicAuth\nimport requests\n\nresponse = requests.get(\"https://api.example.com/protected\", auth=HTTPBasicAuth(\"user\", \"pass\"))\nprint(response.status_code)\nimport httpx\n\nresponse = httpx.get(\"https://api.example.com/protected\", auth=(\"user\", \"pass\"))\nprint(response.status_code)\n\n\nBearer Token Authentication\nheaders = {\"Authorization\": \"Bearer my_token\"}\nresponse = requests.get(\"https://api.example.com/data\", headers=headers)\nprint(response.json())\n\nresponse = httpx.get(\"https://api.example.com/data\", headers=headers)\nprint(response.json())",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#handling-json-responses-errors",
    "href": "request&httpx.html#handling-json-responses-errors",
    "title": "Requests and Httpx",
    "section": "8. Handling JSON Responses & Errors",
    "text": "8. Handling JSON Responses & Errors\ntry:\n    response = requests.get(\"https://api.example.com/data\")\n    response.raise_for_status()  # Raises error if status code is 4xx or 5xx\n    data = response.json()\nexcept requests.exceptions.HTTPError as err:\n    print(f\"HTTP Error: {err}\")\ntry:\n    response = httpx.get(\"https://api.example.com/data\")\n    response.raise_for_status()\n    data = response.json()\nexcept httpx.HTTPStatusError as err:\n    print(f\"HTTP Error: {err}\")",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#streaming-large-responses",
    "href": "request&httpx.html#streaming-large-responses",
    "title": "Requests and Httpx",
    "section": "9. Streaming Large Responses",
    "text": "9. Streaming Large Responses\n# With requests\nwith requests.get(\"https://api.example.com/largefile\", stream=True) as r:\n    for chunk in r.iter_content(chunk_size=1024):\n        print(chunk)\n\n# With httpx\nwith httpx.stream(\"GET\", \"https://api.example.com/largefile\") as response:\n    for chunk in response.iter_bytes():\n        print(chunk)",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#using-proxy-servers",
    "href": "request&httpx.html#using-proxy-servers",
    "title": "Requests and Httpx",
    "section": "10. Using Proxy Servers",
    "text": "10. Using Proxy Servers\nproxies = {\n    \"http\": \"http://proxy.example.com:8080\",\n    \"https\": \"https://proxy.example.com:8080\"\n}\n\n# Using requests\nresponse = requests.get(\"https://api.example.com/data\", proxies=proxies)\n\n# Using httpx\nresponse = httpx.get(\"https://api.example.com/data\", proxies=proxies)",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#http2-and-connection-pooling-httpx-only",
    "href": "request&httpx.html#http2-and-connection-pooling-httpx-only",
    "title": "Requests and Httpx",
    "section": "11. HTTP/2 and Connection Pooling (httpx Only)",
    "text": "11. HTTP/2 and Connection Pooling (httpx Only)\nimport httpx\n\n# Enable HTTP/2\nclient = httpx.Client(http2=True)\nresponse = client.get(\"https://api.example.com/data\")\nprint(response.http_version)  # Should return 'HTTP/2'",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "request&httpx.html#benchmarking-speed-comparison",
    "href": "request&httpx.html#benchmarking-speed-comparison",
    "title": "Requests and Httpx",
    "section": "12. Benchmarking: Speed Comparison",
    "text": "12. Benchmarking: Speed Comparison\n```python import time import requests import httpx\nurl = “https://jsonplaceholder.typicode.com/todos/1”",
    "crumbs": [
      "Blog",
      "Requests and Httpx"
    ]
  },
  {
    "objectID": "rich.html",
    "href": "rich.html",
    "title": "Rich",
    "section": "",
    "text": "rich is a Python library for rich text and beautiful formatting in the terminal — including:\n\n🌈 Colored text & styles\n📊 Tables, progress bars, trees\n🪵 Log rendering\n📦 JSON + syntax highlighting\n🖼️ Markdown and emoji rendering\n\nIt’s used in projects like Textual, FastAPI, Typer, pipx, and Pydantic.",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#what-is-rich",
    "href": "rich.html#what-is-rich",
    "title": "Rich",
    "section": "",
    "text": "rich is a Python library for rich text and beautiful formatting in the terminal — including:\n\n🌈 Colored text & styles\n📊 Tables, progress bars, trees\n🪵 Log rendering\n📦 JSON + syntax highlighting\n🖼️ Markdown and emoji rendering\n\nIt’s used in projects like Textual, FastAPI, Typer, pipx, and Pydantic.",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#installation",
    "href": "rich.html#installation",
    "title": "Rich",
    "section": "🚀 Installation",
    "text": "🚀 Installation\npip install rich\nOr with uv:\nuv pip install rich",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#basic-usage",
    "href": "rich.html#basic-usage",
    "title": "Rich",
    "section": "🧱 Basic Usage",
    "text": "🧱 Basic Usage\nfrom rich import print\n\nprint(\"[bold magenta]Hello[/bold magenta] [green]World![/green] :rocket:\")\n✅ Output with colors and emoji.\n\nRich Console\nfrom rich.console import Console\n\nconsole = Console()\nconsole.print(\"Hello [cyan]World[/cyan]!\", style=\"bold\")",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#text-formatting",
    "href": "rich.html#text-formatting",
    "title": "Rich",
    "section": "🧾 Text Formatting",
    "text": "🧾 Text Formatting\nSupports:\n\nStyles: bold, italic, underline, strike\nColors: names, hex (#ff00ff), RGB tuples\nEmoji shortcodes (like :rocket:)\n\nconsole.print(\"This is [bold red]error[/bold red] and [green]success[/green]!\")",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#layouts",
    "href": "rich.html#layouts",
    "title": "Rich",
    "section": "📐 Layouts",
    "text": "📐 Layouts\n\n✅ Tables\nfrom rich.table import Table\n\ntable = Table(title=\"User Info\")\ntable.add_column(\"Name\", style=\"cyan\")\ntable.add_column(\"Email\", style=\"magenta\")\ntable.add_row(\"Ben\", \"ben@example.com\")\ntable.add_row(\"Kiera\", \"kiera@example.com\")\n\nconsole.print(table)\n\n\n🌳 Trees\nfrom rich.tree import Tree\n\ntree = Tree(\"📁 Root\")\ntree.add(\"📄 File1.txt\")\nbranch = tree.add(\"📂 Folder\")\nbranch.add(\"📄 NestedFile.txt\")\n\nconsole.print(tree)\n\n\n🔄 Progress Bars\nfrom rich.progress import track\nimport time\n\nfor step in track(range(10), description=\"Processing...\"):\n    time.sleep(0.1)\n\n\n⏳ Manual Progress Bars\nfrom rich.progress import Progress\n\nwith Progress() as progress:\n    task = progress.add_task(\"Downloading...\", total=100)\n    while not progress.finished:\n        progress.update(task, advance=10)\n        time.sleep(0.2)",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#logging-with-rich",
    "href": "rich.html#logging-with-rich",
    "title": "Rich",
    "section": "🐞 Logging with Rich",
    "text": "🐞 Logging with Rich\nimport logging\nfrom rich.logging import RichHandler\n\nlogging.basicConfig(\n    level=\"DEBUG\",\n    handlers=[RichHandler()],\n    format=\"%(message)s\",\n)\n\nlogger = logging.getLogger(\"rich\")\nlogger.info(\"Info log\")\nlogger.error(\"Error log\")",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#syntax-highlighting",
    "href": "rich.html#syntax-highlighting",
    "title": "Rich",
    "section": "🧬 Syntax Highlighting",
    "text": "🧬 Syntax Highlighting\nfrom rich.syntax import Syntax\n\ncode = '''\ndef greet(name):\n    print(f\"Hello, {name}\")\n'''\n\nsyntax = Syntax(code, \"python\", theme=\"monokai\", line_numbers=True)\nconsole.print(syntax)",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#pretty-print-json",
    "href": "rich.html#pretty-print-json",
    "title": "Rich",
    "section": "📚 Pretty Print JSON",
    "text": "📚 Pretty Print JSON\nfrom rich.pretty import pprint\nfrom rich.json import JSON\n\npprint({\"foo\": \"bar\", \"baz\": [1, 2, 3]})\n\nconsole.print(JSON('{\"key\": \"value\", \"list\": [1, 2, 3]}'))",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#markdown-rendering",
    "href": "rich.html#markdown-rendering",
    "title": "Rich",
    "section": "✨ Markdown Rendering",
    "text": "✨ Markdown Rendering\nfrom rich.markdown import Markdown\n\nmd = Markdown(\"# Title\\n\\n**Bold** and *italic* text.\")\nconsole.print(md)",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#error-tracebacks",
    "href": "rich.html#error-tracebacks",
    "title": "Rich",
    "section": "💥 Error Tracebacks",
    "text": "💥 Error Tracebacks\nfrom rich.traceback import install\ninstall()\n\n# Raise any exception after this and it'll show a beautiful traceback\nraise ValueError(\"Oops!\")",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#testing-integration",
    "href": "rich.html#testing-integration",
    "title": "Rich",
    "section": "🧪 Testing & Integration",
    "text": "🧪 Testing & Integration\n\nDjango Logging\nUse RichHandler in settings.py:\nLOGGING = {\n    \"version\": 1,\n    \"handlers\": {\n        \"console\": {\n            \"class\": \"rich.logging.RichHandler\",\n            \"level\": \"DEBUG\",\n        },\n    },\n    \"root\": {\n        \"handlers\": [\"console\"],\n        \"level\": \"INFO\",\n    },\n}",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#combining-components",
    "href": "rich.html#combining-components",
    "title": "Rich",
    "section": "🧵 Combining Components",
    "text": "🧵 Combining Components\nfrom rich.panel import Panel\nfrom rich.align import Align\n\npanel = Panel.fit(\n    Align.center(\"[bold green]Task Complete![/bold green]\"),\n    border_style=\"green\",\n    title=\"Status\",\n)\n\nconsole.print(panel)",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#advanced-live-dashboards",
    "href": "rich.html#advanced-live-dashboards",
    "title": "Rich",
    "section": "⚙️ Advanced: Live Dashboards",
    "text": "⚙️ Advanced: Live Dashboards\nfrom rich.live import Live\nfrom rich.table import Table\nimport time\n\ntable = Table()\ntable.add_column(\"Task\")\ntable.add_column(\"Progress\")\n\nwith Live(table, refresh_per_second=4):\n    for i in range(5):\n        table.add_row(f\"Task {i}\", f\"{i*20}%\")\n        time.sleep(0.5)",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#rich-cli",
    "href": "rich.html#rich-cli",
    "title": "Rich",
    "section": "📦 Rich CLI",
    "text": "📦 Rich CLI\nrich [FILE]          # Pretty-print file content\nrich --traceback     # See a rich traceback on crash",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "rich.html#summary-cheat-sheet",
    "href": "rich.html#summary-cheat-sheet",
    "title": "Rich",
    "section": "📊 Summary Cheat Sheet",
    "text": "📊 Summary Cheat Sheet\n\n\n\nFeature\nModule\n\n\n\n\nStyled text\nconsole.print()\n\n\nTables\nrich.table.Table\n\n\nProgress Bars\nrich.progress.Progress\n\n\nLogging\nrich.logging.RichHandler\n\n\nSyntax Highlighting\nrich.syntax.Syntax\n\n\nJSON/Pretty Print\nrich.json, rich.pretty\n\n\nMarkdown\nrich.markdown.Markdown\n\n\nError Tracebacks\nrich.traceback.install()\n\n\n\n\nLet me know if you’d like:\n\nA custom CLI logger setup\nA Rich-based dashboard\nA Textual app starter I can scaffold one for you.",
    "crumbs": [
      "Blog",
      "Rich"
    ]
  },
  {
    "objectID": "scipy.html",
    "href": "scipy.html",
    "title": "Scipy",
    "section": "",
    "text": "!pip list | grep scipy\n\nscipy                         1.12.0",
    "crumbs": [
      "Blog",
      "Scipy"
    ]
  },
  {
    "objectID": "scipy.html#interpolation",
    "href": "scipy.html#interpolation",
    "title": "Scipy",
    "section": "Interpolation",
    "text": "Interpolation\n\n1-D Interpolation\n\nlinear interpolation\n\nimport numpy as np\n\nx = np.linspace(0, 10, num=11)\n\ny = np.cos(-x**2 / 9.0)\n\n\nxnew = np.linspace(0, 10, num=1001)\n\nynew = np.interp(xnew, x, y)\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(xnew, ynew, '-', label='linear interp')\n\nplt.plot(x, y, 'o', label='data')\n\nplt.legend(loc='best')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCubic splines\n\nfrom scipy.interpolate import CubicSpline\n\nspl = CubicSpline([1, 2, 3, 4, 5, 6], [1, 4, 8, 16, 25, 36])\n\nspl(2.5)\n\narray(5.57083333)\n\n\n\nfrom scipy.interpolate import CubicSpline\n\nx = np.linspace(0, 10, num=11)\n\ny = np.cos(-x**2 / 9.)\n\nspl = CubicSpline(x, y)\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(4, 1, figsize=(5, 7))\n\nxnew = np.linspace(0, 10, num=1001)\n\nax[0].plot(xnew, spl(xnew))\n\nax[0].plot(x, y, 'o', label='data')\n\nax[1].plot(xnew, spl(xnew, nu=1), '--', label='1st derivative')\n\nax[2].plot(xnew, spl(xnew, nu=2), '--', label='2nd derivative')\n\nax[3].plot(xnew, spl(xnew, nu=3), '--', label='3rd derivative')\n\nfor j in range(4):\n\n    ax[j].legend(loc='best')\n\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nMonotone interpolants\n\nfrom scipy.interpolate import CubicSpline, PchipInterpolator, Akima1DInterpolator\n\nx = np.array([1., 2., 3., 4., 4.5, 5., 6., 7., 8])\n\ny = x**2\n\ny[4] += 101\n\n\nimport matplotlib.pyplot as plt\n\nxx = np.linspace(1, 8, 51)\n\nplt.plot(xx, CubicSpline(x, y)(xx), '--', label='spline')\n\nplt.plot(xx, Akima1DInterpolator(x, y)(xx), '-', label='Akima1D')\n\nplt.plot(xx, PchipInterpolator(x, y)(xx), '-', label='pchip')\n\nplt.plot(x, y, 'o')\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpolation with B-splines\n\nx = np.linspace(0, 3/2, 7)\n\ny = np.sin(np.pi*x)\n\n\nfrom scipy.interpolate import make_interp_spline\n\nbspl = make_interp_spline(x, y, k=3)\n\n\nder = bspl.derivative()      # a BSpline representing the derivative\n\nimport matplotlib.pyplot as plt\n\nxx = np.linspace(0, 3/2, 51)\n\nplt.plot(xx, bspl(xx), '--', label=r'$\\sin(\\pi x)$ approx')\n\nplt.plot(x, y, 'o', label='data')\n\nplt.plot(xx, der(xx)/np.pi, '--', label='$d \\sin(\\pi x)/dx / \\pi$ approx')\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nbspl.k, der.k\n\n(3, 2)\n\n\n\n\nParametric spline curves\n\nx = [0, 1, 2, 3, 4, 5, 6]\n\ny = [0, 0, 0, 9, 0, 0, 0]\n\np = np.stack((x, y))\n\np\n\narray([[0, 1, 2, 3, 4, 5, 6],\n       [0, 0, 0, 9, 0, 0, 0]])\n\n\n\nu_unif = x\n\n\ndp = p[:, 1:] - p[:, :-1]      # 2-vector distances between points\n\nl = (dp**2).sum(axis=0)        # squares of lengths of 2-vectors between points\n\nu_cord = np.sqrt(l).cumsum()   # cumulative sums of 2-norms\n\nu_cord = np.r_[0, u_cord]      # the first point is parameterized at zero\n\n\nu_c = np.r_[0, np.cumsum((dp**2).sum(axis=0)**0.25)]\n\n\nfrom scipy.interpolate import make_interp_spline\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 3, figsize=(8, 3))\n\nparametrizations = ['uniform', 'cord length', 'centripetal']\n\n\nfor j, u in enumerate([u_unif, u_cord, u_c]):\n    spl = make_interp_spline(u, p, axis=1)    # note p is a 2D array\n    uu = np.linspace(u[0], u[-1], 51)\n    xx, yy = spl(uu)\n    ax[j].plot(xx, yy, '--')\n    ax[j].plot(p[0, :], p[1, :], 'o')\n    ax[j].set_title(parametrizations[j])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPiecewise polynomials Manipulating PPoly objectsand splines\n\nManipulating PPoly objects\n\nfrom scipy.interpolate import CubicSpline\n\nx = np.linspace(0, 10, 71)\n\ny = np.sin(x)\n\nspl = CubicSpline(x, y)\n\n\ndspl = spl.derivative()\n\n\ndspl(1.1), spl(1.1, nu=1)\n\n(array(0.45361436), array(0.45361436))\n\n\n\ndspl.roots() / np.pi\n\narray([-0.45480801,  0.50000034,  1.50000099,  2.5000016 ,  3.46249993])\n\n\n\ndspl.roots(extrapolate=False) / np.pi\n\narray([0.50000034, 1.50000099, 2.5000016 ])\n\n\n\ndspl.solve(0.5, extrapolate=False) / np.pi\n\narray([0.33332755, 1.66667195, 2.3333271 ])\n\n\n\nfrom scipy.special import ellipk\n\nm = 0.5\n\nellipk(m)\n\n1.8540746773013719\n\n\n\nfrom scipy.interpolate import PchipInterpolator\n\nx = np.linspace(0, np.pi/2, 70)\n\ny = (1 - m*np.sin(x)**2)**(-1/2)\n\nspl = PchipInterpolator(x, y)\n\n\nspl.integrate(0, np.pi/2)\n\narray(1.85407467)\n\n\n\nfrom scipy.interpolate import PchipInterpolator\n\nm = np.linspace(0, 0.9, 11)\n\nx = np.linspace(0, np.pi/2, 70)\n\ny = 1 / np.sqrt(1 - m[:, None]*np.sin(x)**2)\n\n\nspl = PchipInterpolator(x, y, axis=1)  # the default is axis=0\n\nimport matplotlib.pyplot as plt\n\nplt.plot(m, spl.integrate(0, np.pi/2), '--')\n\n\n\n\n\n\n\n\n\nfrom scipy.special import ellipk\n\nplt.plot(m, ellipk(m), 'o')\n\nplt.legend(['`ellipk`', 'integrated piecewise polynomial'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nB-splines: knots and coefficients\n\nx = np.linspace(0, 3/2, 7)\n\ny = np.sin(np.pi*x)\n\nfrom scipy.interpolate import make_interp_spline\n\nbspl = make_interp_spline(x, y, k=3)\n\nprint(bspl.t)\n\n[0.   0.   0.   0.   0.5  0.75 1.   1.5  1.5  1.5  1.5 ]\n\n\n\nprint(x)\n\n[0.   0.25 0.5  0.75 1.   1.25 1.5 ]\n\n\n\nlen(bspl.c)\n\n7\n\n\n\nk = 3      # cubic splines\n\nt = [0., 1.4, 2., 3.1, 5.]   # internal knots\n\nt = np.r_[[0]*k, t, [5]*k]   # add boundary knots\n\n\nfrom scipy.interpolate import BSpline\n\nimport matplotlib.pyplot as plt\n\nfor j in [-2, -1, 0, 1, 2]:\n\n    a, b = t[k+j], t[-k+j-1]\n\n    xx = np.linspace(a, b, 101)\n\n    bspl = BSpline.basis_element(t[k+j:-k+j])\n\n    plt.plot(xx, bspl(xx), label=f'j = {j}')\n\nplt.legend(loc='best')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nc = np.zeros(t.size - k - 1)\n\nc[-2] = 1\n\nb = BSpline(t, c, k)\n\nnp.allclose(b(xx), bspl(xx))\n\nTrue\n\n\n\nt = [0., 0., 0., 0., 2., 3., 4., 6., 6., 6., 6.]\n\n\nxnew = [1, 2, 3]\n\n\nfrom scipy.interpolate import BSpline\n\nmat = BSpline.design_matrix(xnew, t, k=3)\n\nmat\n\n&lt;3x7 sparse array of type '&lt;class 'numpy.float64'&gt;'\n    with 12 stored elements in Compressed Sparse Row format&gt;\n\n\n\nwith np.printoptions(precision=3):\n\n    print(mat.toarray())\n\n[[0.125 0.514 0.319 0.042 0.    0.    0.   ]\n [0.    0.111 0.556 0.333 0.    0.    0.   ]\n [0.    0.    0.125 0.75  0.125 0.    0.   ]]\n\n\n\n\n\nSmoothing splines\n\nSpline smoothing in 1-D\n\nimport numpy as np\n\nfrom scipy.interpolate import splrep, BSpline\n\n\nx = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/16)\n\nrng = np.random.default_rng()\n\ny =  np.sin(x) + 0.4*rng.standard_normal(size=len(x))\n\n\ntck = splrep(x, y, s=0)\n\ntck_s = splrep(x, y, s=len(x))\n\n\nimport matplotlib.pyplot as plt\n\nxnew = np.arange(0, 9/4, 1/50) * np.pi\n\nplt.plot(xnew, np.sin(xnew), '-.', label='sin(x)')\n\nplt.plot(xnew, BSpline(*tck)(xnew), '-', label='s=0')\n\nplt.plot(xnew, BSpline(*tck_s)(xnew), '-', label=f's={len(x)}')\n\nplt.plot(x, y, 'o')\n\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom scipy import interpolate\n\n\nx = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/8)\n\ny = np.sin(x)\n\ntck = interpolate.splrep(x, y, s=0)\n\nxnew = np.arange(0, 2*np.pi, np.pi/50)\n\nynew = interpolate.splev(xnew, tck, der=0)\n\n\nplt.figure()\n\nplt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')\n\nplt.legend(['Linear', 'Cubic Spline', 'True'])\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('Cubic-spline interpolation')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nyder = interpolate.splev(xnew, tck, der=1)   # or BSpline(*tck)(xnew, 1)\n\nplt.figure()\n\nplt.plot(xnew, yder, xnew, np.cos(xnew),'--')\n\nplt.legend(['Cubic Spline', 'True'])\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('Derivative estimation from spline')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nyders = interpolate.spalde(xnew, tck)\n\nplt.figure()\n\nfor i in range(len(yders[0])):\n\n   plt.plot(xnew, [d[i] for d in yders], '--', label=f\"{i} derivative\")\n\nplt.legend()\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('All derivatives of a B-spline')\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndef integ(x, tck, constant=-1):\n\n    x = np.atleast_1d(x)\n\n    out = np.zeros(x.shape, dtype=x.dtype)\n\n    for n in range(len(out)):\n\n        out[n] = interpolate.splint(0, x[n], tck)\n\n    out += constant\n\n    return out\n\n\nyint = integ(xnew, tck)\n\nplt.figure()\n\nplt.plot(xnew, yint, xnew, -np.cos(xnew), '--')\n\nplt.legend(['Cubic Spline', 'True'])\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('Integral estimation from spline')\n\nplt.show()\n\n\n\n\n\n\n\n\n\ninterpolate.sproot(tck)\n\narray([3.14159265])\n\n\n\nx = np.linspace(-np.pi/4, 2.*np.pi + np.pi/4, 21)\n\ny = np.sin(x)\n\ntck = interpolate.splrep(x, y, s=0)\n\ninterpolate.sproot(tck)\n\narray([-2.22044605e-16,  3.14159265e+00,  6.28318531e+00])\n\n\n\nt = np.arange(0, 1.1, .1)\n\nx = np.sin(2*np.pi*t)\n\ny = np.cos(2*np.pi*t)\n\ntck, u = interpolate.splprep([x, y], s=0)\n\nunew = np.arange(0, 1.01, 0.01)\n\nout = interpolate.splev(unew, tck)\n\nplt.figure()\n\nplt.plot(x, y, 'x', out[0], out[1], np.sin(2*np.pi*unew), np.cos(2*np.pi*unew), x, y, 'b')\n\nplt.legend(['Linear', 'Cubic Spline', 'True'])\n\nplt.axis([-1.05, 1.05, -1.05, 1.05])\n\nplt.title('Spline of parametrically-defined curve')\n\nplt.show()\n\n\n\n\n\n\n\n\n\ntt, cc, k = tck\n\ncc = np.array(cc)\n\nbspl = BSpline(tt, cc.T, k)    # note the transpose\n\nxy = bspl(u)\n\nxx, yy = xy.T   # transpose to unpack into a pair of arrays\n\nnp.allclose(x, xx)\n\nTrue\n\n\n\nnp.allclose(y, yy)\n\nTrue\n\n\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom scipy import interpolate\n\n\nx = np.arange(0, 2*np.pi+np.pi/4, 2*np.pi/8)\n\ny = np.sin(x)\n\ns = interpolate.InterpolatedUnivariateSpline(x, y)\n\nxnew = np.arange(0, 2*np.pi, np.pi/50)\n\nynew = s(xnew)\n\n\nplt.figure()\n\nplt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')\n\nplt.legend(['Linear', 'InterpolatedUnivariateSpline', 'True'])\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('InterpolatedUnivariateSpline')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nt = [np.pi/2-.1, np.pi/2+.1, 3*np.pi/2-.1, 3*np.pi/2+.1]\n\ns = interpolate.LSQUnivariateSpline(x, y, t, k=2)\n\nynew = s(xnew)\n\n\nplt.figure()\n\nplt.plot(x, y, 'x', xnew, ynew, xnew, np.sin(xnew), x, y, 'b')\n\nplt.legend(['Linear', 'LSQUnivariateSpline', 'True'])\n\nplt.axis([-0.05, 6.33, -1.05, 1.05])\n\nplt.title('Spline with Specified Interior Knots')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2-D smoothing splines\n\nx_edges, y_edges = np.mgrid[-1:1:21j, -1:1:21j]\n\nx = x_edges[:-1, :-1] + np.diff(x_edges[:2, 0])[0] / 2.\n\ny = y_edges[:-1, :-1] + np.diff(y_edges[0, :2])[0] / 2.\n\nz = (x+y) * np.exp(-6.0*(x*x+y*y))\n\n\nplt.figure()\n\nlims = dict(cmap='RdBu_r', vmin=-0.25, vmax=0.25)\n\nplt.pcolormesh(x_edges, y_edges, z, shading='flat', **lims)\n\nplt.colorbar()\n\nplt.title(\"Sparsely sampled function.\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nxnew_edges, ynew_edges = np.mgrid[-1:1:71j, -1:1:71j]\n\nxnew = xnew_edges[:-1, :-1] + np.diff(xnew_edges[:2, 0])[0] / 2.\n\nynew = ynew_edges[:-1, :-1] + np.diff(ynew_edges[0, :2])[0] / 2.\n\ntck = interpolate.bisplrep(x, y, z, s=0)\n\nznew = interpolate.bisplev(xnew[:,0], ynew[0,:], tck)\n\n\nplt.figure()\n\nplt.pcolormesh(xnew_edges, ynew_edges, znew, shading='flat', **lims)\n\nplt.colorbar()\n\nplt.title(\"Interpolated function.\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import SmoothBivariateSpline\n\nimport warnings\nwarnings.simplefilter('ignore')\n\ntrain_x, train_y = np.meshgrid(np.arange(-5, 5, 0.5), np.arange(-5, 5, 0.5))\ntrain_x = train_x.flatten()\ntrain_y = train_y.flatten()\n\ndef z_func(x, y):\n    return np.cos(x) + np.sin(y) ** 2 + 0.05 * x + 0.1 * y\n\ntrain_z = z_func(train_x, train_y)\ninterp_func = SmoothBivariateSpline(train_x, train_y, train_z, s=0.0)\nsmth_func = SmoothBivariateSpline(train_x, train_y, train_z)\n\ntest_x = np.arange(-9, 9, 0.01)\ntest_y = np.arange(-9, 9, 0.01)\ngrid_x, grid_y = np.meshgrid(test_x, test_y)\n\ninterp_result = interp_func(test_x, test_y).T\nsmth_result = smth_func(test_x, test_y).T\nperfect_result = z_func(grid_x, grid_y)\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 8))\nextent = [test_x[0], test_x[-1], test_y[0], test_y[-1]]\nopts = dict(aspect='equal', cmap='nipy_spectral', extent=extent, vmin=-1.5, vmax=2.5)\n\nim = axes[0].imshow(perfect_result, **opts)\nfig.colorbar(im, ax=axes[0], orientation='horizontal')\naxes[0].plot(train_x, train_y, 'w.')\naxes[0].set_title('Perfect result, sampled function', fontsize=21)\n\nim = axes[1].imshow(smth_result, **opts)\naxes[1].plot(train_x, train_y, 'w.')\nfig.colorbar(im, ax=axes[1], orientation='horizontal')\naxes[1].set_title('s=default', fontsize=21)\n\nim = axes[2].imshow(interp_result, **opts)\nfig.colorbar(im, ax=axes[2], orientation='horizontal')\naxes[2].plot(train_x, train_y, 'w.')\naxes[2].set_title('s=0', fontsize=21)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import RectBivariateSpline\n\nx = np.arange(-5.01, 5.01, 0.25)        # the grid is an outer product\ny = np.arange(-5.01, 7.51, 0.25)        # of x and y arrays\n\nxx, yy = np.meshgrid(x, y, indexing='ij')\nz = np.sin(xx**2 + 2.*yy**2)            # z array needs to be 2-D\n\nfunc = RectBivariateSpline(x, y, z, s=0)\n\nxnew = np.arange(-5.01, 5.01, 1e-2)\nynew = np.arange(-5.01, 7.51, 1e-2)\nznew = func(xnew, ynew)\n\nplt.imshow(znew)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMultivariate data interpolation on a regular grid (RegularGridInterpolator)\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.interpolate import RegularGridInterpolator\n\n\ndef F(u, v):\n\n    return u * np.cos(u * v) + v * np.sin(u * v)\n\n\nfit_points = [np.linspace(0, 3, 8), np.linspace(0, 3, 11)]\n\nvalues = F(*np.meshgrid(*fit_points, indexing='ij'))\n\n\nut, vt = np.meshgrid(np.linspace(0, 3, 80), np.linspace(0, 3, 80), indexing='ij')\n\ntrue_values = F(ut, vt)\n\ntest_points = np.array([ut.ravel(), vt.ravel()]).T\n\n\ninterp = RegularGridInterpolator(fit_points, values)\n\nfig, axes = plt.subplots(2, 3, figsize=(10, 6))\n\naxes = axes.ravel()\n\nfig_index = 0\n\nfor method in ['linear', 'nearest', 'slinear', 'cubic', 'quintic']:\n\n    im = interp(test_points, method=method).reshape(80, 80)\n\n    axes[fig_index].imshow(im)\n\n    axes[fig_index].set_title(method)\n\n    axes[fig_index].axis(\"off\")\n\n    fig_index += 1\n\naxes[fig_index].imshow(true_values)\n\naxes[fig_index].set_title(\"True values\")\n\nfig.tight_layout()\n\nfig.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.interpolate import interpn\n\nrgi = RegularGridInterpolator(fit_points, values)\n\nresult_rgi = rgi(test_points)\n\n\nresult_interpn = interpn(fit_points, values, test_points)\n\nnp.allclose(result_rgi, result_interpn, atol=1e-15)\n\nTrue\n\n\n\nx = np.array([0, 5, 10])\n\ny = np.array([0])\n\ndata = np.array([[0], [5], [10]])\n\nrgi = RegularGridInterpolator((x, y), data,\n\n                              bounds_error=False, fill_value=None)\n\nrgi([(2, 0), (2, 1), (2, -1)])\n\narray([2., 2., 2.])\n\n\n\nrgi.fill_value = -101\n\nrgi([(2, 0), (2, 1), (2, -1)])\n\narray([   2., -101., -101.])\n\n\n\nclass CartesianGridInterpolator:\n    def __init__(self, points, values, method='linear'):\n        self.limits = np.array([[min(x), max(x)] for x in points])\n        self.values = np.asarray(values, dtype=float)\n        self.order = {'linear': 1, 'cubic': 3, 'quintic': 5}[method]\n\n    def __call__(self, xi):\n        \"\"\"\n        `xi` here is an array-like (an array or a list) of points.\n\n        Each \"point\" is an ndim-dimensional array_like, representing\n        the coordinates of a point in ndim-dimensional space.\n        \"\"\"\n        # transpose the xi array into the ``map_coordinates`` convention\n        # which takes coordinates of a point along columns of a 2D array.\n        xi = np.asarray(xi).T\n\n        # convert from data coordinates to pixel coordinates\n        ns = self.values.shape\n        coords = [(n-1)*(val - lo) / (hi - lo)\n                  for val, n, (lo, hi) in zip(xi, ns, self.limits)]\n\n        # interpolate\n        return map_coordinates(self.values, coords,\n                               order=self.order,\n                               cval=np.nan)  # fill_value\n\n\nx, y = np.arange(5), np.arange(6)\n\nxx, yy = np.meshgrid(x, y, indexing='ij')\n\nvalues = xx**3 + yy**3\n\nrgi = RegularGridInterpolator((x, y), values, method='linear')\n\nrgi([[1.5, 1.5], [3.5, 2.6]])\n\narray([ 9. , 64.9])\n\n\n\ncgi = CartesianGridInterpolator((x, y), values, method='linear')\n\n\n\nScattered data interpolation (griddata)\n\ndef func(x, y):\n\n    return x*(1-x)*np.cos(4*np.pi*x) * np.sin(4*np.pi*y**2)**2\n\n\ngrid_x, grid_y = np.meshgrid(np.linspace(0, 1, 100),\n\n                             np.linspace(0, 1, 200), indexing='ij')\n\n\nrng = np.random.default_rng()\n\npoints = rng.random((1000, 2))\n\nvalues = func(points[:,0], points[:,1])\n\n\nfrom scipy.interpolate import griddata\n\ngrid_z0 = griddata(points, values, (grid_x, grid_y), method='nearest')\n\ngrid_z1 = griddata(points, values, (grid_x, grid_y), method='linear')\n\ngrid_z2 = griddata(points, values, (grid_x, grid_y), method='cubic')\n\n\nimport matplotlib.pyplot as plt\n\nplt.subplot(221)\n\nplt.imshow(func(grid_x, grid_y).T, extent=(0, 1, 0, 1), origin='lower')\n\nplt.plot(points[:, 0], points[:, 1], 'k.', ms=1)   # data\n\nplt.title('Original')\n\nplt.subplot(222)\n\nplt.imshow(grid_z0.T, extent=(0, 1, 0, 1), origin='lower')\n\nplt.title('Nearest')\n\nplt.subplot(223)\n\nplt.imshow(grid_z1.T, extent=(0, 1, 0, 1), origin='lower')\n\nplt.title('Linear')\n\nplt.subplot(224)\n\nplt.imshow(grid_z2.T, extent=(0, 1, 0, 1), origin='lower')\n\nplt.title('Cubic')\n\nplt.gcf().set_size_inches(6, 6)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nUsing radial basis functions for smoothing/interpolation\n\nimport numpy as np\n\nfrom scipy.interpolate import RBFInterpolator, InterpolatedUnivariateSpline\n\nimport matplotlib.pyplot as plt\n\n\n# setup data\n\nx = np.linspace(0, 10, 9).reshape(-1, 1)\n\ny = np.sin(x)\n\nxi = np.linspace(0, 10, 101).reshape(-1, 1)\n\n# use fitpack2 method\n\nius = InterpolatedUnivariateSpline(x, y)\n\nyi = ius(xi)\n\nplt.subplot(2, 1, 1)\n\nplt.plot(x, y, 'bo')\n\nplt.plot(xi, yi, 'g')\n\nplt.plot(xi, np.sin(xi), 'r')\n\nplt.title('Interpolation using univariate spline')\n\n# use RBF method\n\nrbf = RBFInterpolator(x, y)\n\nfi = rbf(xi)\n\nplt.subplot(2, 1, 2)\n\nplt.plot(x, y, 'bo')\n\nplt.plot(xi, fi, 'g')\n\nplt.plot(xi, np.sin(xi), 'r')\n\nplt.title('Interpolation using RBF - multiquadrics')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nfrom scipy.interpolate import RBFInterpolator\n\nimport matplotlib.pyplot as plt\n\n# 2-d tests - setup scattered data\n\nrng = np.random.default_rng()\n\nxy = rng.random((100, 2))*4.0-2.0\n\nz = xy[:, 0]*np.exp(-xy[:, 0]**2-xy[:, 1]**2)\n\nedges = np.linspace(-2.0, 2.0, 101)\n\ncenters = edges[:-1] + np.diff(edges[:2])[0] / 2.\n\nx_i, y_i = np.meshgrid(centers, centers)\n\nx_i = x_i.reshape(-1, 1)\n\ny_i = y_i.reshape(-1, 1)\n\nxy_i = np.concatenate([x_i, y_i], axis=1)\n\n# use RBF\n\nrbf = RBFInterpolator(xy, z, epsilon=2)\n\nz_i = rbf(xy_i)\n\n# plot the result\n\nfig, ax = plt.subplots()\n\nX_edges, Y_edges = np.meshgrid(edges, edges)\n\nlims = dict(cmap='RdBu_r', vmin=-0.4, vmax=0.4)\n\nmapping = ax.pcolormesh(\n\n    X_edges, Y_edges, z_i.reshape(100, 100),\n\n    shading='flat', **lims\n\n)\n\nax.scatter(xy[:, 0], xy[:, 1], 100, z, edgecolor='w', lw=0.1, **lims)\n\nax.set(\n\n    title='RBF interpolation - multiquadrics',\n\n    xlim=(-2, 2),\n\n    ylim=(-2, 2),\n\n)\n\nfig.colorbar(mapping)\n\n\n\n\n\n\n\n\n\n\n\nExtrapolation tips and tricks\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import interp1d\n\nx = np.linspace(0, 1.5*np.pi, 11)\ny = np.column_stack((np.cos(x), np.sin(x)))   # y.shape is (11, 2)\n\nfunc = interp1d(x, y,\n                axis=0,  # interpolate along columns\n                bounds_error=False,\n                kind='linear',\n                fill_value=(y[0], y[-1]))\nxnew = np.linspace(-np.pi, 2.5*np.pi, 51)\nynew = func(xnew)\n\nfix, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.plot(xnew, ynew[:, 0])\nax1.plot(x, y[:, 0], 'o')\n\nax2.plot(xnew, ynew[:, 1])\nax2.plot(x, y[:, 1], 'o')\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import CubicSpline\n\nxs = [1, 2, 3, 4, 5, 6, 7, 8]\nys = [4.5, 3.6, 1.6, 0.0, -3.3, -3.1, -1.8, -1.7]\n\nnotaknot = CubicSpline(xs, ys, bc_type='not-a-knot')\nnatural = CubicSpline(xs, ys, bc_type='natural')\nclamped = CubicSpline(xs, ys, bc_type='clamped')\nxnew = np.linspace(min(xs) - 4, max(xs) + 4, 101)\n\nsplines = [notaknot, natural, clamped]\ntitles = ['not-a-knot', 'natural', 'clamped']\n\nfig, axs = plt.subplots(3, 3, figsize=(12, 12))\nfor i in [0, 1, 2]:\n    for j, spline, title in zip(range(3), splines, titles):\n        axs[i, j].plot(xs, spline(xs, nu=i),'o')\n        axs[i, j].plot(xnew, spline(xnew, nu=i),'-')\n        axs[i, j].set_title(f'{title}, deriv={i}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import CubicSpline\n\ndef add_boundary_knots(spline):\n    \"\"\"\n    Add knots infinitesimally to the left and right.\n\n    Additional intervals are added to have zero 2nd and 3rd derivatives,\n    and to maintain the first derivative from whatever boundary condition\n    was selected. The spline is modified in place.\n    \"\"\"\n    # determine the slope at the left edge\n    leftx = spline.x[0]\n    lefty = spline(leftx)\n    leftslope = spline(leftx, nu=1)\n\n    # add a new breakpoint just to the left and use the\n    # known slope to construct the PPoly coefficients.\n    leftxnext = np.nextafter(leftx, leftx - 1)\n    leftynext = lefty + leftslope*(leftxnext - leftx)\n    leftcoeffs = np.array([0, 0, leftslope, leftynext])\n    spline.extend(leftcoeffs[..., None], np.r_[leftxnext])\n\n    # repeat with additional knots to the right\n    rightx = spline.x[-1]\n    righty = spline(rightx)\n    rightslope = spline(rightx,nu=1)\n    rightxnext = np.nextafter(rightx, rightx + 1)\n    rightynext = righty + rightslope * (rightxnext - rightx)\n    rightcoeffs = np.array([0, 0, rightslope, rightynext])\n    spline.extend(rightcoeffs[..., None], np.r_[rightxnext])\n\nxs = [1, 2, 3, 4, 5, 6, 7, 8]\nys = [4.5, 3.6, 1.6, 0.0, -3.3, -3.1, -1.8, -1.7]\n\nnotaknot = CubicSpline(xs,ys, bc_type='not-a-knot')\n# not-a-knot does not require additional intervals\n\nnatural = CubicSpline(xs,ys, bc_type='natural')\n# extend the natural natural spline with linear extrapolating knots\nadd_boundary_knots(natural)\n\nclamped = CubicSpline(xs,ys, bc_type='clamped')\n# extend the clamped spline with constant extrapolating knots\nadd_boundary_knots(clamped)\n\nxnew = np.linspace(min(xs) - 5, max(xs) + 5, 201)\n\nfig, axs = plt.subplots(3, 3,figsize=(12,12))\n\nsplines = [notaknot, natural, clamped]\ntitles = ['not-a-knot', 'natural', 'clamped']\n\nfor i in [0, 1, 2]:\n    for j, spline, title in zip(range(3), splines, titles):\n        axs[i, j].plot(xs, spline(xs, nu=i),'o')\n        axs[i, j].plot(xnew, spline(xnew, nu=i),'-')\n        axs[i, j].set_title(f'{title}, deriv={i}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nManually implement the asymptotics\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import brentq\n\ndef f(x, a):\n    return a*x - 1/np.tan(x)\n\na = 3\nx0 = brentq(f, 1e-16, np.pi/2, args=(a,))   # here we shift the left edge\n                                            # by a machine epsilon to avoid\n                                            # a division by zero at x=0\nxx = np.linspace(0.2, np.pi/2, 101)\nplt.plot(xx, a*xx, '--')\nplt.plot(xx, 1/np.tan(xx), '--')\nplt.plot(x0, a*x0, 'o', ms=12)\nplt.text(0.1, 0.9, fr'$x_0 = {x0:.3f}$',\n               transform=plt.gca().transAxes, fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import BPoly\n\ndef f(x, a):\n    return a*x - 1/np.tan(x)\n\nxleft, xright = 0.2, np.pi/2\nx = np.linspace(xleft, xright, 11)\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nfor j, a in enumerate([3, 93]):\n    y = f(x, a)\n    dydx = a + 1./np.sin(x)**2    # d(ax - 1/tan(x)) / dx\n    dxdy = 1 / dydx               # dx/dy = 1 / (dy/dx)\n\n    xdx = np.c_[x, dxdy]\n    spl = BPoly.from_derivatives(y, xdx)   # inverse interpolation\n\n    yy = np.linspace(f(xleft, a), f(xright, a), 51)\n    ax[j].plot(yy, spl(yy), '--')\n    ax[j].plot(y, x, 'o')\n    ax[j].set_xlabel(r'$y$')\n    ax[j].set_ylabel(r'$x$')\n    ax[j].set_title(rf'$a = {a}$')\n\n    ax[j].plot(0, spl(0), 'o', ms=12)\n    ax[j].text(0.1, 0.85, fr'$x_0 = {spl(0):.3f}$',\n               transform=ax[j].transAxes, fontsize=18)\n    ax[j].grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nclass RootWithAsymptotics:\n    def __init__(self, a):\n        # construct the interpolant\n        xleft, xright = 0.2, np.pi/2\n        x = np.linspace(xleft, xright, 11)\n\n        y = f(x, a)\n        dydx = a + 1./np.sin(x)**2    # d(ax - 1/tan(x)) / dx\n        dxdy = 1 / dydx               # dx/dy = 1 / (dy/dx)\n\n        # inverse interpolation\n        self.spl = BPoly.from_derivatives(y, np.c_[x, dxdy])\n        self.a = a\n\n    def root(self):\n        out = self.spl(0)\n        asympt = 1./np.sqrt(self.a)\n        return np.where(spl.x.min() &lt; asympt, out, asympt)\n\n\nr = RootWithAsymptotics(93)\n\nr.root()\n\narray(0.10369517)\n\n\n\n\nExtrapolation in D &gt; 1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import CloughTocher2DInterpolator as CT\n\ndef my_CT(xy, z):\n    \"\"\"CT interpolator + nearest-neighbor extrapolation.\n\n    Parameters\n    ----------\n    xy : ndarray, shape (npoints, ndim)\n        Coordinates of data points\n    z : ndarray, shape (npoints)\n        Values at data points\n\n    Returns\n    -------\n    func : callable\n        A callable object which mirrors the CT behavior,\n        with an additional neareast-neighbor extrapolation\n        outside of the data range.\n    \"\"\"\n    x = xy[:, 0]\n    y = xy[:, 1]\n    f = CT(xy, z)\n\n    # this inner function will be returned to a user\n    def new_f(xx, yy):\n        # evaluate the CT interpolator. Out-of-bounds values are nan.\n        zz = f(xx, yy)\n        nans = np.isnan(zz)\n\n        if nans.any():\n            # for each nan point, find its nearest neighbor\n            inds = np.argmin(\n                (x[:, None] - xx[nans])**2 +\n                (y[:, None] - yy[nans])**2\n                , axis=0)\n            # ... and use its value\n            zz[nans] = z[inds]\n        return zz\n\n    return new_f\n\n# Now illustrate the difference between the original ``CT`` interpolant\n# and ``my_CT`` on a small example:\n\nx = np.array([1, 1, 1, 2, 2, 2, 4, 4, 4])\ny = np.array([1, 2, 3, 1, 2, 3, 1, 2, 3])\nz = np.array([0, 7, 8, 3, 4, 7, 1, 3, 4])\n\nxy = np.c_[x, y]\nlut = CT(xy, z)\nlut2 = my_CT(xy, z)\n\nX = np.linspace(min(x) - 0.5, max(x) + 0.5, 71)\nY = np.linspace(min(y) - 0.5, max(y) + 0.5, 71)\nX, Y = np.meshgrid(X, Y)\n\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\n\nax.plot_wireframe(X, Y, lut(X, Y), label='CT')\nax.plot_wireframe(X, Y, lut2(X, Y), color='m',\n                  cstride=10, rstride=10, alpha=0.7, label='CT + n.n.')\n\nax.scatter(x, y, z,  'o', color='k', s=48, label='data')\nax.legend()\nplt.tight_layout()",
    "crumbs": [
      "Blog",
      "Scipy"
    ]
  },
  {
    "objectID": "scipy.html#fourier-transforms",
    "href": "scipy.html#fourier-transforms",
    "title": "Scipy",
    "section": "Fourier transforms",
    "text": "Fourier transforms\n\nFast Fourier transforms\n\n1-D discrete Fourier transforms\n\nfrom scipy.fft import fft, ifft\n\nimport numpy as np\n\nx = np.array([1.0, 2.0, 1.0, -1.0, 1.5])\n\ny = fft(x)\n\ny\n\narray([ 4.5       -0.j        ,  2.08155948-1.65109876j,\n       -1.83155948+1.60822041j, -1.83155948-1.60822041j,\n        2.08155948+1.65109876j])\n\n\n\nyinv = ifft(y)\n\nyinv\n\narray([ 1. +0.j,  2. +0.j,  1. +0.j, -1. +0.j,  1.5+0.j])\n\n\n\nnp.sum(x)\n\n4.5\n\n\n\nfrom scipy.fft import fft, fftfreq\n\nimport numpy as np\n\n# Number of sample points\n\nN = 600\n\n# sample spacing\n\nT = 1.0 / 800.0\n\nx = np.linspace(0.0, N*T, N, endpoint=False)\n\ny = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n\nyf = fft(y)\n\nxf = fftfreq(N, T)[:N//2]\n\nimport matplotlib.pyplot as plt\n\nplt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.fft import fft, fftfreq\n\nimport numpy as np\n\n# Number of sample points\n\nN = 600\n\n# sample spacing\n\nT = 1.0 / 800.0\n\nx = np.linspace(0.0, N*T, N, endpoint=False)\n\ny = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n\nyf = fft(y)\n\nfrom scipy.signal.windows import blackman\n\nw = blackman(N)\n\nywf = fft(y*w)\n\nxf = fftfreq(N, T)[:N//2]\n\nimport matplotlib.pyplot as plt\n\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(yf[1:N//2]), '-b')\n\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(ywf[1:N//2]), '-r')\n\nplt.legend(['FFT', 'FFT w. window'])\n\nplt.grid()\nfrom scipy.fft import fftshift\n\nx = np.arange(8)\n\nfftshift(x)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.fft import fftfreq\n\nfreq = fftfreq(8, 0.125)\n\nfreq\n\narray([ 0.,  1.,  2.,  3., -4., -3., -2., -1.])\n\n\n\nfrom scipy.fft import fftshift\n\nx = np.arange(8)\n\nfftshift(x)\n\nfrom scipy.fft import fft, fftfreq, fftshift\n\nimport numpy as np\n\n# number of signal points\n\nN = 400\n\n# sample spacing\n\nT = 1.0 / 800.0\n\nx = np.linspace(0.0, N*T, N, endpoint=False)\n\ny = np.exp(50.0 * 1.j * 2.0*np.pi*x) + 0.5*np.exp(-80.0 * 1.j * 2.0*np.pi*x)\n\nyf = fft(y)\n\nxf = fftfreq(N, T)\n\nxf = fftshift(xf)\n\nyplot = fftshift(yf)\n\nimport matplotlib.pyplot as plt\n\nplt.plot(xf, 1.0/N * np.abs(yplot))\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.fft import fft, rfft, irfft\n\nx = np.array([1.0, 2.0, 1.0, -1.0, 1.5, 1.0])\n\nfft(x)\n\narray([ 5.5 -0.j        ,  2.25-0.4330127j , -2.75-1.29903811j,\n        1.5 -0.j        , -2.75+1.29903811j,  2.25+0.4330127j ])\n\n\n\nyr = rfft(x)\n\nyr\n\narray([ 5.5 +0.j        ,  2.25-0.4330127j , -2.75-1.29903811j,\n        1.5 +0.j        ])\n\n\n\nirfft(yr)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5,  1. ])\n\n\n\nx = np.array([1.0, 2.0, 1.0, -1.0, 1.5])\n\nfft(x)\n\narray([ 4.5       -0.j        ,  2.08155948-1.65109876j,\n       -1.83155948+1.60822041j, -1.83155948-1.60822041j,\n        2.08155948+1.65109876j])\n\n\n\nyr = rfft(x)\n\nyr\n\narray([ 4.5       +0.j        ,  2.08155948-1.65109876j,\n       -1.83155948+1.60822041j])\n\n\n\nirfft(yr)\n\narray([ 1.70788987,  2.40843925, -0.37366961,  0.75734049])\n\n\n\nirfft(yr, n=len(x))\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\n\n2- and N-D discrete Fourier transforms\n\nfrom scipy.fft import ifftn\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib.cm as cm\n\nimport numpy as np\n\nN = 30\n\nf, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, sharex='col', sharey='row')\n\nxf = np.zeros((N,N))\n\nxf[0, 5] = 1\n\nxf[0, N-5] = 1\n\nZ = ifftn(xf)\n\nax1.imshow(xf, cmap=cm.Reds)\n\nax4.imshow(np.real(Z), cmap=cm.gray)\n\nxf = np.zeros((N, N))\n\nxf[5, 0] = 1\n\nxf[N-5, 0] = 1\n\nZ = ifftn(xf)\n\nax2.imshow(xf, cmap=cm.Reds)\n\nax5.imshow(np.real(Z), cmap=cm.gray)\n\nxf = np.zeros((N, N))\n\nxf[5, 10] = 1\n\nxf[N-5, N-10] = 1\n\nZ = ifftn(xf)\n\nax3.imshow(xf, cmap=cm.Reds)\n\nax6.imshow(np.real(Z), cmap=cm.gray)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nDiscrete Cosine Transforms\n\nDCT and IDCT\n\nfrom scipy.fft import dct, idct\n\nx = np.array([1.0, 2.0, 1.0, -1.0, 1.5])\n\n\ndct(dct(x, type=2, norm='ortho'), type=3, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndct(dct(x, type=2), type=3)\n\narray([ 10.,  20.,  10., -10.,  15.])\n\n\n\n# Normalized inverse: no scaling factor\n\nidct(dct(x, type=2), type=2)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndct(dct(x, type=1, norm='ortho'), type=1, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\n# Unnormalized round-trip via DCT-I: scaling factor 2*(N-1) = 8\n\ndct(dct(x, type=1), type=1)\n\narray([ 8., 16.,  8., -8., 12.])\n\n\n\n# Normalized inverse: no scaling factor\n\nidct(dct(x, type=1), type=1)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndct(dct(x, type=4, norm='ortho'), type=4, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\n# Unnormalized round-trip via DCT-IV: scaling factor 2*N = 10\n\ndct(dct(x, type=4), type=4)\n\narray([ 10.,  20.,  10., -10.,  15.])\n\n\n\n# Normalized inverse: no scaling factor\n\nidct(dct(x, type=4), type=4)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\nfrom scipy.fft import dct, idct\n\nimport matplotlib.pyplot as plt\n\nN = 100\n\nt = np.linspace(0,20,N, endpoint=False)\n\nx = np.exp(-t/3)*np.cos(2*t)\n\ny = dct(x, norm='ortho')\n\nwindow = np.zeros(N)\n\nwindow[:20] = 1\n\nyr = idct(y*window, norm='ortho')\n\nsum(abs(x-yr)**2) / sum(abs(x)**2)\n\n0.0009872817275276098\n\n\n\nplt.plot(t, x, '-bx')\n\nplt.plot(t, yr, 'ro')\n\nwindow = np.zeros(N)\n\nwindow[:15] = 1\n\nyr = idct(y*window, norm='ortho')\n\nsum(abs(x-yr)**2) / sum(abs(x)**2)\n\nplt.plot(t, yr, 'g+')\n\nplt.legend(['x', '$x_{20}$', '$x_{15}$'])\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nDiscrete Sine Transforms\n\nDST and IDST\n\nfrom scipy.fft import dst, idst\n\nx = np.array([1.0, 2.0, 1.0, -1.0, 1.5])\n\n\ndst(dst(x, type=2, norm='ortho'), type=3, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndst(dst(x, type=2), type=3)\n\narray([ 10.,  20.,  10., -10.,  15.])\n\n\n\nidst(dst(x, type=2), type=2)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndst(dst(x, type=1, norm='ortho'), type=1, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\n# scaling factor 2*(N+1) = 12\n\ndst(dst(x, type=1), type=1)\n\narray([ 12.,  24.,  12., -12.,  18.])\n\n\n\n# no scaling factor\n\nidst(dst(x, type=1), type=1)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\ndst(dst(x, type=4, norm='ortho'), type=4, norm='ortho')\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])\n\n\n\n# scaling factor 2*N = 10\n\ndst(dst(x, type=4), type=4)\n\narray([ 10.,  20.,  10., -10.,  15.])\n\n\n\n# no scaling factor\n\nidst(dst(x, type=4), type=4)\n\narray([ 1. ,  2. ,  1. , -1. ,  1.5])",
    "crumbs": [
      "Blog",
      "Scipy"
    ]
  },
  {
    "objectID": "scipy.html#signal-processing",
    "href": "scipy.html#signal-processing",
    "title": "Scipy",
    "section": "Signal Processing",
    "text": "Signal Processing\n\nB-splines\n\nimport numpy as np\n\nfrom scipy import signal, datasets\n\nimport matplotlib.pyplot as plt\n\n\nimage = datasets.face(gray=True).astype(np.float32)\n\nderfilt = np.array([1.0, -2, 1.0], dtype=np.float32)\n\nck = signal.cspline2d(image, 8.0)\n\nderiv = (signal.sepfir2d(ck, derfilt, [1]) +\n\n         signal.sepfir2d(ck, [1], derfilt))\n\n\nplt.figure()\n\nplt.imshow(image)\n\nplt.gray()\n\nplt.title('Original image')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\n\nplt.imshow(deriv)\n\nplt.gray()\n\nplt.title('Output of spline edge filter')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFiltering\n\nx = np.array([1.0, 2.0, 3.0])\n\nh = np.array([0.0, 1.0, 0.0, 0.0, 0.0])\n\nsignal.convolve(x, h)\n\narray([0., 1., 2., 3., 0., 0., 0.])\n\n\n\nsignal.convolve(x, h, 'same')\n\narray([2., 3., 0.])\n\n\n\nx = np.array([[1., 1., 0., 0.], [1., 1., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]])\n\nh = np.array([[1., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 0.]])\n\nsignal.convolve(x, h)\n\narray([[1., 1., 0., 0., 0., 0., 0.],\n       [1., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 1., 0., 0., 0.],\n       [0., 0., 1., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0.]])\n\n\n\nimport numpy as np\n\nfrom scipy import signal, datasets\n\nimport matplotlib.pyplot as plt\n\n\nimage = datasets.face(gray=True)\n\nw = np.zeros((50, 50))\n\nw[0][0] = 1.0\n\nw[49][25] = 1.0\n\nimage_new = signal.fftconvolve(image, w)\n\n\nplt.figure()\n\nplt.imshow(image)\n\nplt.gray()\n\nplt.title('Original image')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\n\nplt.imshow(image_new)\n\nplt.gray()\n\nplt.title('Filtered image')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nfrom scipy import signal, datasets\n\nimport matplotlib.pyplot as plt\n\n\nimage = np.asarray(datasets.ascent(), np.float64)\n\nw = signal.windows.gaussian(51, 10.0)\n\nimage_new = signal.sepfir2d(image, w, w)\n\n\nplt.figure()\n\nplt.imshow(image)\n\nplt.gray()\n\nplt.title('Original image')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\n\nplt.imshow(image_new)\n\nplt.gray()\n\nplt.title('Filtered image')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nfrom scipy import signal\n\n\nx = np.array([1., 0., 0., 0.])\n\nb = np.array([1.0/2, 1.0/4])\n\na = np.array([1.0, -1.0/3])\n\nsignal.lfilter(b, a, x)\n\narray([0.5       , 0.41666667, 0.13888889, 0.0462963 ])\n\n\n\nzi = signal.lfiltic(b, a, y=[2.])\n\nsignal.lfilter(b, a, x, zi=zi)\n\n(array([1.16666667, 0.63888889, 0.21296296, 0.07098765]), array([0.02366255]))\n\n\n\nb = np.array([1.0/2, 1.0/4])\n\na = np.array([1.0, -1.0/3])\n\nsignal.tf2zpk(b, a)\n\n(array([-0.5]), array([0.33333333]), 0.5)\n\n\n\nFilter Design - FIR\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nb1 = signal.firwin(40, 0.5)\n\nb2 = signal.firwin(41, [0.3, 0.8])\n\nw1, h1 = signal.freqz(b1)\n\nw2, h2 = signal.freqz(b2)\n\nplt.title('Digital filter frequency response')\n\nplt.plot(w1, 20*np.log10(np.abs(h1)), 'b')\n\nplt.plot(w2, 20*np.log10(np.abs(h2)), 'r')\n\nplt.ylabel('Amplitude Response (dB)')\n\nplt.xlabel('Frequency (rad/sample)')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nb = signal.firwin2(150, [0.0, 0.3, 0.6, 1.0], [1.0, 2.0, 0.5, 0.0])\n\nw, h = signal.freqz(b)\n\nplt.title('Digital filter frequency response')\n\nplt.plot(w, np.abs(h))\n\nplt.title('Digital filter frequency response')\n\nplt.ylabel('Amplitude Response')\n\nplt.xlabel('Frequency (rad/sample)')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIIR Filter\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nb, a = signal.iirfilter(4, Wn=0.2, rp=5, rs=60, btype='lowpass', ftype='ellip')\n\nw, h = signal.freqz(b, a)\n\nplt.title('Digital filter frequency response')\n\nplt.plot(w, 20*np.log10(np.abs(h)))\n\nplt.title('Digital filter frequency response')\n\nplt.ylabel('Amplitude Response [dB]')\n\nplt.xlabel('Frequency (rad/sample)')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nb, a = signal.iirdesign(wp=100, ws=200, gpass=2.0, gstop=40., analog=True)\n\nw, h = signal.freqs(b, a)\n\nplt.title('Analog filter frequency response')\n\nplt.plot(w, 20*np.log10(np.abs(h)))\n\nplt.ylabel('Amplitude Response [dB]')\n\nplt.xlabel('Frequency')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nz, p, k = signal.tf2zpk(b, a)\n\nplt.plot(np.real(z), np.imag(z), 'ob', markerfacecolor='none')\n\nplt.plot(np.real(p), np.imag(p), 'xr')\n\nplt.legend(['Zeros', 'Poles'], loc=2)\n\nplt.title('Pole / Zero Plot')\n\nplt.xlabel('Real')\n\nplt.ylabel('Imaginary')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSpectral Analysis\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nfs = 10e3\n\nN = 1e5\n\namp = 2*np.sqrt(2)\n\nfreq = 1270.0\n\nnoise_power = 0.001 * fs / 2\n\ntime = np.arange(N) / fs\n\nx = amp*np.sin(2*np.pi*freq*time)\n\nx += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n\nf, Pper_spec = signal.periodogram(x, fs, 'flattop', scaling='spectrum')\n\nplt.semilogy(f, Pper_spec)\n\nplt.xlabel('frequency [Hz]')\n\nplt.ylabel('PSD')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\nfs = 10e3\n\nN = 1e5\n\namp = 2*np.sqrt(2)\n\nfreq = 1270.0\n\nnoise_power = 0.001 * fs / 2\n\ntime = np.arange(N) / fs\n\nx = amp*np.sin(2*np.pi*freq*time)\n\nx += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n\nf, Pwelch_spec = signal.welch(x, fs, scaling='spectrum')\n\nplt.semilogy(f, Pwelch_spec)\n\nplt.xlabel('frequency [Hz]')\n\nplt.ylabel('PSD')\n\nplt.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nDetrend\n\nimport numpy as np\n\nimport scipy.signal as signal\n\nimport matplotlib.pyplot as plt\n\n\nt = np.linspace(-10, 10, 20)\n\ny = 1 + t + 0.01*t**2\n\nyconst = signal.detrend(y, type='constant')\n\nylin = signal.detrend(y, type='linear')\n\n\nplt.plot(t, y, '-rx')\n\nplt.plot(t, yconst, '-bo')\n\nplt.plot(t, ylin, '-k+')\n\nplt.grid()\n\nplt.legend(['signal', 'const. detrend', 'linear detrend'])\n\nplt.show()",
    "crumbs": [
      "Blog",
      "Scipy"
    ]
  },
  {
    "objectID": "scipy.html#multidimensional-image-processing",
    "href": "scipy.html#multidimensional-image-processing",
    "title": "Scipy",
    "section": "Multidimensional image processing",
    "text": "Multidimensional image processing\n\nProperties shared by all functions\n\nfrom scipy.ndimage import correlate\n\nimport numpy as np\n\ncorrelate(np.arange(10), [1, 2.5])\n\narray([ 0,  2,  6,  9, 13, 16, 20, 23, 27, 30])\n\n\n\ncorrelate(np.arange(10), [1, 2.5], output=np.float64)\n\narray([ 0. ,  2.5,  6. ,  9.5, 13. , 16.5, 20. , 23.5, 27. , 30.5])\n\n\n\n\nFilter functions\n\nfootprint = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n\nfootprint\n\narray([[0, 1, 0],\n       [1, 1, 1],\n       [0, 1, 0]])\n\n\n\nfrom scipy.ndimage import correlate1d\n\na = [0, 0, 0, 1, 0, 0, 0]\n\ncorrelate1d(a, [1, 1, 1])\n\narray([0, 0, 1, 1, 1, 0, 0])\n\n\n\na = [0, 0, 0, 1, 0, 0, 0]\n\ncorrelate1d(a, [1, 1, 1], origin = -1)\n\narray([0, 1, 1, 1, 0, 0, 0])\n\n\n\na = [0, 0, 1, 1, 1, 0, 0]\n\ncorrelate1d(a, [-1, 1])               # backward difference\n\narray([ 0,  0,  1,  0,  0, -1,  0])\n\n\n\ncorrelate1d(a, [-1, 1], origin = -1)  # forward difference\n\narray([ 0,  1,  0,  0, -1,  0,  0])\n\n\n\ncorrelate1d(a, [0, -1, 1])\n\narray([ 0,  1,  0,  0, -1,  0,  0])\n\n\n\n\n\nmode\ndescription\nexample\n\n\n\n\n“nearest”\nuse the value at the boundary\n[1 2 3]-&gt;[1 1 2 3 3]\n\n\n“wrap”\nperiodically replicate the array\n[1 2 3]-&gt;[3 1 2 3 1]\n\n\n“reflect”\nreflect the array at the boundary\n[1 2 3]-&gt;[1 1 2 3 3]\n\n\n“mirror”\nmirror the array at the boundary\n[1 2 3]-&gt;[2 1 2 3 2]\n\n\n“constant”\nuse a constant value, default is 0.0\n[1 2 3]-&gt;[0 1 2 3 0]\n\n\n\nThe following synonyms are also supported for consistency with the interpolation routines:\n\n\n\nmode\ndescription\n\n\n\n\n“grid-constant”\nequivalent to “constant”*\n\n\n“grid-mirror”\nequivalent to “reflect”\n\n\n“grid-wrap”\nequivalent to “wrap”\n\n\n\n\n\nDerivatives\n\ndef d2(input, axis, output, mode, cval):\n    return correlate1d(input, [1, -2, 1], axis, output, mode, cval, 0)\n\na = np.zeros((5, 5))\n\na[2, 2] = 1\n\nfrom scipy.ndimage import generic_laplace\n\ngeneric_laplace(a, d2)\n\narray([[ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  1., -4.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.]])\n\n\n\ndef d2(input, axis, output, mode, cval, weights):\n\n    return correlate1d(input, weights, axis, output, mode, cval, 0,)\n\n\na = np.zeros((5, 5))\n\na[2, 2] = 1\n\ngeneric_laplace(a, d2, extra_arguments = ([1, -2, 1],))\n\narray([[ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  1., -4.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.]])\n\n\n\ngeneric_laplace(a, d2, extra_keywords = {'weights': [1, -2, 1]})\n\narray([[ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  1., -4.,  1.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.]])\n\n\n\na = np.zeros((5, 5))\n\na[2, 2] = 1\n\nfrom scipy.ndimage import sobel, generic_gradient_magnitude\n\ngeneric_gradient_magnitude(a, sobel)\n\narray([[0.        , 0.        , 0.        , 0.        , 0.        ],\n       [0.        , 1.41421356, 2.        , 1.41421356, 0.        ],\n       [0.        , 2.        , 0.        , 2.        , 0.        ],\n       [0.        , 1.41421356, 2.        , 1.41421356, 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ]])\n\n\n\na = np.arange(12).reshape(3,4)\n\ncorrelate1d(a, [1, 2, 3])\n\narray([[ 3,  8, 14, 17],\n       [27, 32, 38, 41],\n       [51, 56, 62, 65]])\n\n\n\ndef fnc(iline, oline):\n    oline[...] = iline[:-2] + 2 * iline[1:-1] + 3 * iline[2:]\n\nfrom scipy.ndimage import generic_filter1d\n\ngeneric_filter1d(a, fnc, 3)\n\narray([[ 3,  8, 14, 17],\n       [27, 32, 38, 41],\n       [51, 56, 62, 65]])\n\n\n\ndef fnc(iline, oline, a, b):\n\n    oline[...] = iline[:-2] + a * iline[1:-1] + b * iline[2:]\n\n\ngeneric_filter1d(a, fnc, 3, extra_arguments = (2, 3))\n\narray([[ 3,  8, 14, 17],\n       [27, 32, 38, 41],\n       [51, 56, 62, 65]])\n\n\n\ngeneric_filter1d(a, fnc, 3, extra_keywords = {'a':2, 'b':3})\n\narray([[ 3,  8, 14, 17],\n       [27, 32, 38, 41],\n       [51, 56, 62, 65]])\n\n\n\na = np.arange(12).reshape(3,4)\n\ncorrelate(a, [[1, 0], [0, 3]])\n\narray([[ 0,  3,  7, 11],\n       [12, 15, 19, 23],\n       [28, 31, 35, 39]])\n\n\n\ndef fnc(buffer):\n\n    return (buffer * np.array([1, 3])).sum()\n\n\nfrom scipy.ndimage import generic_filter\n\ngeneric_filter(a, fnc, footprint = [[1, 0], [0, 1]])\n\narray([[ 0,  3,  7, 11],\n       [12, 15, 19, 23],\n       [28, 31, 35, 39]])\n\n\n\ndef fnc(buffer, weights):\n\n    weights = np.asarray(weights)\n\n    return (buffer * weights).sum()\n\n\ngeneric_filter(a, fnc, footprint = [[1, 0], [0, 1]], extra_arguments = ([1, 3],))\n\narray([[ 0,  3,  7, 11],\n       [12, 15, 19, 23],\n       [28, 31, 35, 39]])\n\n\n\ngeneric_filter(a, fnc, footprint = [[1, 0], [0, 1]], extra_keywords= {'weights': [1, 3]})\n\narray([[ 0,  3,  7, 11],\n       [12, 15, 19, 23],\n       [28, 31, 35, 39]])\n\n\n\na = np.arange(12).reshape(3,4)\n\nclass fnc_class:\n    def __init__(self, shape):\n        # store the shape:\n        self.shape = shape\n        # initialize the coordinates:\n        self.coordinates = [0] * len(shape)\n\n    def filter(self, buffer):\n        result = (buffer * np.array([1, 3])).sum()\n        print(self.coordinates)\n        # calculate the next coordinates:\n        axes = list(range(len(self.shape)))\n        axes.reverse()\n        for jj in axes:\n            if self.coordinates[jj] &lt; self.shape[jj] - 1:\n                self.coordinates[jj] += 1\n                break\n            else:\n                self.coordinates[jj] = 0\n        return result\n\nfnc = fnc_class(shape = (3,4))\n\ngeneric_filter(a, fnc.filter, footprint = [[1, 0], [0, 1]])\n\n[0, 0]\n[0, 1]\n[0, 2]\n[0, 3]\n[1, 0]\n[1, 1]\n[1, 2]\n[1, 3]\n[2, 0]\n[2, 1]\n[2, 2]\n[2, 3]\n\n\narray([[ 0,  3,  7, 11],\n       [12, 15, 19, 23],\n       [28, 31, 35, 39]])\n\n\n\na = np.arange(12).reshape(3,4)\n\nclass fnc1d_class:\n    def __init__(self, shape, axis = -1):\n        # store the filter axis:\n        self.axis = axis\n        # store the shape:\n        self.shape = shape\n        # initialize the coordinates:\n        self.coordinates = [0] * len(shape)\n\n    def filter(self, iline, oline):\n        oline[...] = iline[:-2] + 2 * iline[1:-1] + 3 * iline[2:]\n        print(self.coordinates)\n        # calculate the next coordinates:\n        axes = list(range(len(self.shape)))\n        # skip the filter axis:\n        del axes[self.axis]\n        axes.reverse()\n        for jj in axes:\n            if self.coordinates[jj] &lt; self.shape[jj] - 1:\n                self.coordinates[jj] += 1\n                break\n            else:\n                self.coordinates[jj] = 0\n\nfnc = fnc1d_class(shape = (3,4))\n\ngeneric_filter1d(a, fnc.filter, 3)\n\n[0, 0]\n[1, 0]\n[2, 0]\n\n\narray([[ 3,  8, 14, 17],\n       [27, 32, 38, 41],\n       [51, 56, 62, 65]])\n\n\n\n\nInterpolation functions\n\na = np.arange(12).reshape(4,3).astype(np.float64)\n\ndef shift_func(output_coordinates):\n\n    return (output_coordinates[0] - 0.5, output_coordinates[1] - 0.5)\n\n\nfrom scipy.ndimage import geometric_transform\n\ngeometric_transform(a, shift_func)\n\narray([[0.    , 0.    , 0.    ],\n       [0.    , 1.3625, 2.7375],\n       [0.    , 4.8125, 6.1875],\n       [0.    , 8.2625, 9.6375]])\n\n\n\ndef shift_func(output_coordinates, s0, s1):\n\n    return (output_coordinates[0] - s0, output_coordinates[1] - s1)\n\n\ngeometric_transform(a, shift_func, extra_arguments = (0.5, 0.5))\n\narray([[0.    , 0.    , 0.    ],\n       [0.    , 1.3625, 2.7375],\n       [0.    , 4.8125, 6.1875],\n       [0.    , 8.2625, 9.6375]])\n\n\n\ngeometric_transform(a, shift_func, extra_keywords = {'s0': 0.5, 's1': 0.5})\n\narray([[0.    , 0.    , 0.    ],\n       [0.    , 1.3625, 2.7375],\n       [0.    , 4.8125, 6.1875],\n       [0.    , 8.2625, 9.6375]])\n\n\n\na = np.arange(12).reshape(4,3).astype(np.float64)\n\na\n\narray([[ 0.,  1.,  2.],\n       [ 3.,  4.,  5.],\n       [ 6.,  7.,  8.],\n       [ 9., 10., 11.]])\n\n\n\nfrom scipy.ndimage import map_coordinates\n\nmap_coordinates(a, [[0.5, 2], [0.5, 1]])\n\narray([1.3625, 7.    ])\n\n\n\n\nBinary morphology\n\nfrom scipy.ndimage import generate_binary_structure\n\ngenerate_binary_structure(2, 1)\n\narray([[False,  True, False],\n       [ True,  True,  True],\n       [False,  True, False]])\n\n\n\ngenerate_binary_structure(2, 2)\n\narray([[ True,  True,  True],\n       [ True,  True,  True],\n       [ True,  True,  True]])\n\n\n\nstruct = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n\na = np.array([[1,0,0,0,0], [1,1,0,1,0], [0,0,1,1,0], [0,0,0,0,0]])\n\na\n\narray([[1, 0, 0, 0, 0],\n       [1, 1, 0, 1, 0],\n       [0, 0, 1, 1, 0],\n       [0, 0, 0, 0, 0]])\n\n\n\nfrom scipy.ndimage import binary_dilation\n\nbinary_dilation(np.zeros(a.shape), struct, -1, a, border_value=1)\n\narray([[ True, False, False, False, False],\n       [ True,  True, False, False, False],\n       [False, False, False, False, False],\n       [False, False, False, False, False]])\n\n\n\nstruct = generate_binary_structure(2, 1)\n\nstruct\n\narray([[False,  True, False],\n       [ True,  True,  True],\n       [False,  True, False]])\n\n\n\nfrom scipy.ndimage import iterate_structure\n\niterate_structure(struct, 2)\n\narray([[False, False,  True, False, False],\n       [False,  True,  True,  True, False],\n       [ True,  True,  True,  True,  True],\n       [False,  True,  True,  True, False],\n       [False, False,  True, False, False]])\n\n\n\n\nSegmentation and labeling\n\na = np.array([[1,2,2,1,1,0],\n\n              [0,2,3,1,2,0],\n\n              [1,1,1,3,3,2],\n\n              [1,1,1,1,2,1]])\n\nnp.where(a &gt; 1, 1, 0)\n\narray([[0, 1, 1, 0, 0, 0],\n       [0, 1, 1, 0, 1, 0],\n       [0, 0, 0, 1, 1, 1],\n       [0, 0, 0, 0, 1, 0]])\n\n\n\na = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])\n\ns = [[0, 1, 0], [1,1,1], [0,1,0]]\n\nfrom scipy.ndimage import label\n\nlabel(a, s)\n\n(array([[0, 1, 1, 0, 0, 0],\n        [0, 1, 1, 0, 2, 0],\n        [0, 0, 0, 2, 2, 2],\n        [0, 0, 0, 0, 2, 0]], dtype=int32),\n 2)\n\n\n\na = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])\n\ns = [[1,1,1], [1,1,1], [1,1,1]]\n\nlabel(a, s)[0]\n\narray([[0, 1, 1, 0, 0, 0],\n       [0, 1, 1, 0, 1, 0],\n       [0, 0, 0, 1, 1, 1],\n       [0, 0, 0, 0, 1, 0]], dtype=int32)\n\n\n\nl, n = label([1, 0, 1, 0, 1])\n\nl\n\narray([1, 0, 2, 0, 3], dtype=int32)\n\n\n\nl = np.where(l != 2, l, 0)\n\nl\n\narray([1, 0, 0, 0, 3], dtype=int32)\n\n\n\nlabel(l)[0]\n\narray([1, 0, 0, 0, 2], dtype=int32)\n\n\n\ninput = np.array([[0, 0, 0, 0, 0, 0, 0],\n                  [0, 1, 1, 1, 1, 1, 0],\n                  [0, 1, 0, 0, 0, 1, 0],\n                  [0, 1, 0, 0, 0, 1, 0],\n                  [0, 1, 0, 0, 0, 1, 0],\n                  [0, 1, 1, 1, 1, 1, 0],\n                  [0, 0, 0, 0, 0, 0, 0]], np.uint8)\nmarkers = np.array([[1, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 2, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0]], np.int8)\n\nfrom scipy.ndimage import watershed_ift\n\nwatershed_ift(input, markers)\n\narray([[1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 2, 2, 2, 1, 1],\n       [1, 2, 2, 2, 2, 2, 1],\n       [1, 2, 2, 2, 2, 2, 1],\n       [1, 2, 2, 2, 2, 2, 1],\n       [1, 1, 2, 2, 2, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1]], dtype=int8)\n\n\n\nmarkers = np.array([[0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 2, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 1]], np.int8)\n\nwatershed_ift(input, markers)\n\narray([[1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 2, 2, 2, 1, 1],\n       [1, 1, 2, 2, 2, 1, 1],\n       [1, 1, 2, 2, 2, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1]], dtype=int8)\n\n\n\nmarkers = np.array([[0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 2, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, -1]], np.int8)\n\nwatershed_ift(input, markers)\n\narray([[-1, -1, -1, -1, -1, -1, -1],\n       [-1, -1,  2,  2,  2, -1, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1, -1,  2,  2,  2, -1, -1],\n       [-1, -1, -1, -1, -1, -1, -1]], dtype=int8)\n\n\n\nwatershed_ift(input, markers,\n\n              structure = [[1,1,1], [1,1,1], [1,1,1]])\n\narray([[-1, -1, -1, -1, -1, -1, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1,  2,  2,  2,  2,  2, -1],\n       [-1, -1, -1, -1, -1, -1, -1]], dtype=int8)\n\n\n\n\nObject measurements\n\na = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])\n\nl, n = label(a)\n\nfrom scipy.ndimage import find_objects\n\nf = find_objects(l)\n\na[f[0]]\n\narray([[1, 1],\n       [1, 1]])\n\n\n\na[f[1]]\n\narray([[0, 1, 0],\n       [1, 1, 1],\n       [0, 1, 0]])\n\n\n\nfrom scipy.ndimage import find_objects\n\nfind_objects([1, 0, 3, 4], max_label = 3)\n\n[(slice(0, 1, None),), None, (slice(2, 3, None),)]\n\n\n\nimage = np.arange(4 * 6).reshape(4, 6)\n\nmask = np.array([[0,1,1,0,0,0],[0,1,1,0,1,0],[0,0,0,1,1,1],[0,0,0,0,1,0]])\n\nlabels = label(mask)[0]\n\nslices = find_objects(labels)\n\n\nnp.where(labels[slices[1]] == 2, image[slices[1]], 0).sum()\n\n80\n\n\n\nfrom scipy.ndimage import sum as ndi_sum\n\nndi_sum(image, labels, 2)\n\n80\n\n\n\nndi_sum(image[slices[1]], labels[slices[1]], 2)\n\n80\n\n\n\nndi_sum(image, labels, [0, 2])\n\narray([178.,  80.])",
    "crumbs": [
      "Blog",
      "Scipy"
    ]
  },
  {
    "objectID": "Display/altair.html",
    "href": "Display/altair.html",
    "title": "Altair",
    "section": "",
    "text": "pip install altair vega_datasets\n\n!pip list | grep altair\n!pip list | grep vega_datasets\n!pip list | grep pandas\n!pip list | grep geopandas\n\naltair                        5.1.2\ngeopandas                     0.14.1\npandas                        1.5.3\ngeopandas                     0.14.1\n\n\n\nimport altair as alt\nimport numpy as np\nimport pandas as pd\n\n# Compute x^2 + y^2 across a 2D grid\nx, y = np.meshgrid(range(-5, 5), range(-5, 5))\nz = x ** 2 + y ** 2\n\n# Convert this grid to columnar data expected by Altair\nsource = pd.DataFrame({'x': x.ravel(),\n                     'y': y.ravel(),\n                     'z': z.ravel()})\n\nalt.Chart(source).mark_rect().encode(\n    x='x:O',\n    y='y:O',\n    color='z:Q'\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nimport pandas as pd\n\nsource = pd.DataFrame(\n    [\n        {\"a\": \"a1\", \"b\": \"b1\", \"c\": \"x\", \"p\": \"0.14\"},\n        {\"a\": \"a1\", \"b\": \"b1\", \"c\": \"y\", \"p\": \"0.60\"},\n        {\"a\": \"a1\", \"b\": \"b1\", \"c\": \"z\", \"p\": \"0.03\"},\n        {\"a\": \"a1\", \"b\": \"b2\", \"c\": \"x\", \"p\": \"0.80\"},\n        {\"a\": \"a1\", \"b\": \"b2\", \"c\": \"y\", \"p\": \"0.38\"},\n        {\"a\": \"a1\", \"b\": \"b2\", \"c\": \"z\", \"p\": \"0.55\"},\n        {\"a\": \"a1\", \"b\": \"b3\", \"c\": \"x\", \"p\": \"0.11\"},\n        {\"a\": \"a1\", \"b\": \"b3\", \"c\": \"y\", \"p\": \"0.58\"},\n        {\"a\": \"a1\", \"b\": \"b3\", \"c\": \"z\", \"p\": \"0.79\"},\n        {\"a\": \"a2\", \"b\": \"b1\", \"c\": \"x\", \"p\": \"0.83\"},\n        {\"a\": \"a2\", \"b\": \"b1\", \"c\": \"y\", \"p\": \"0.87\"},\n        {\"a\": \"a2\", \"b\": \"b1\", \"c\": \"z\", \"p\": \"0.67\"},\n        {\"a\": \"a2\", \"b\": \"b2\", \"c\": \"x\", \"p\": \"0.97\"},\n        {\"a\": \"a2\", \"b\": \"b2\", \"c\": \"y\", \"p\": \"0.84\"},\n        {\"a\": \"a2\", \"b\": \"b2\", \"c\": \"z\", \"p\": \"0.90\"},\n        {\"a\": \"a2\", \"b\": \"b3\", \"c\": \"x\", \"p\": \"0.74\"},\n        {\"a\": \"a2\", \"b\": \"b3\", \"c\": \"y\", \"p\": \"0.64\"},\n        {\"a\": \"a2\", \"b\": \"b3\", \"c\": \"z\", \"p\": \"0.19\"},\n        {\"a\": \"a3\", \"b\": \"b1\", \"c\": \"x\", \"p\": \"0.57\"},\n        {\"a\": \"a3\", \"b\": \"b1\", \"c\": \"y\", \"p\": \"0.35\"},\n        {\"a\": \"a3\", \"b\": \"b1\", \"c\": \"z\", \"p\": \"0.49\"},\n        {\"a\": \"a3\", \"b\": \"b2\", \"c\": \"x\", \"p\": \"0.91\"},\n        {\"a\": \"a3\", \"b\": \"b2\", \"c\": \"y\", \"p\": \"0.38\"},\n        {\"a\": \"a3\", \"b\": \"b2\", \"c\": \"z\", \"p\": \"0.91\"},\n        {\"a\": \"a3\", \"b\": \"b3\", \"c\": \"x\", \"p\": \"0.99\"},\n        {\"a\": \"a3\", \"b\": \"b3\", \"c\": \"y\", \"p\": \"0.80\"},\n        {\"a\": \"a3\", \"b\": \"b3\", \"c\": \"z\", \"p\": \"0.37\"},\n    ]\n)\n\nalt.Chart(source, width=60, height=alt.Step(8)).mark_bar().encode(\n    alt.Y(\"c:N\").axis(None),\n    alt.X(\"p:Q\").title(None).axis(format=\"%\"),\n    alt.Color(\"c:N\").title(\"settings\").legend(orient=\"bottom\", titleOrient=\"left\"),\n    alt.Row(\"a:N\").title(\"Factor A\").header(labelAngle=0),\n    alt.Column(\"b:N\").title(\"Factor B\"),\n).interactive()\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.stocks()\n\nhighlight = alt.selection_point(on='mouseover', fields=['symbol'], nearest=True)\n\nbase = alt.Chart(source).encode(\n    x='date:T',\n    y='price:Q',\n    color='symbol:N'\n)\n\npoints = base.mark_circle().encode(\n    opacity=alt.value(0)\n).add_params(\n    highlight\n).properties(\n    width=600\n)\n\nlines = base.mark_line().encode(\n    size=alt.condition(~highlight, alt.value(1), alt.value(3))\n)\n\npoints + lines\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.unemployment_across_industries.url\n\nselection = alt.selection_point(fields=['series'], bind='legend')\n\nalt.Chart(source).mark_area().encode(\n    alt.X('yearmonth(date):T').axis(domain=False, format='%Y', tickSize=0),\n    alt.Y('sum(count):Q').stack('center').axis(None),\n    alt.Color('series:N').scale(scheme='category20b'),\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n).add_params(\n    selection\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.cars()\n\nalt.Chart(source).mark_circle().encode(\n    alt.X(alt.repeat(\"column\"), type='quantitative'),\n    alt.Y(alt.repeat(\"row\"), type='quantitative'),\n    color='Origin:N'\n).properties(\n    width=150,\n    height=150\n).repeat(\n    row=['Horsepower', 'Acceleration', 'Miles_per_Gallon'],\n    column=['Miles_per_Gallon', 'Acceleration', 'Horsepower']\n).interactive()\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.seattle_weather.url\n\nstep = 20\noverlap = 1\n\nalt.Chart(source, height=step).transform_timeunit(\n    Month='month(date)'\n).transform_joinaggregate(\n    mean_temp='mean(temp_max)', groupby=['Month']\n).transform_bin(\n    ['bin_max', 'bin_min'], 'temp_max'\n).transform_aggregate(\n    value='count()', groupby=['Month', 'mean_temp', 'bin_min', 'bin_max']\n).transform_impute(\n    impute='value', groupby=['Month', 'mean_temp'], key='bin_min', value=0\n).mark_area(\n    interpolate='monotone',\n    fillOpacity=0.8,\n    stroke='lightgray',\n    strokeWidth=0.5\n).encode(\n    alt.X('bin_min:Q')\n        .bin('binned')\n        .title('Maximum Daily Temperature (C)'),\n    alt.Y('value:Q')\n        .axis(None)\n        .scale(range=[step, -step * overlap]),\n    alt.Fill('mean_temp:Q')\n        .legend(None)\n        .scale(domain=[30, 5], scheme='redyellowblue')\n).facet(\n    row=alt.Row('Month:T')\n        .title(None)\n        .header(labelAngle=0, labelAlign='left', format='%B')\n).properties(\n    title='Seattle Weather',\n    bounds='flush'\n).configure_facet(\n    spacing=0\n).configure_view(\n    stroke=None\n).configure_title(\n    anchor='end'\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.seattle_weather()\n\nalt.Chart(source, title=\"Daily Max Temperatures (C) in Seattle, WA\").mark_rect().encode(\n    alt.X(\"date(date):O\").title(\"Day\").axis(format=\"%e\", labelAngle=0),\n    alt.Y(\"month(date):O\").title(\"Month\"),\n    alt.Color(\"max(temp_max)\").title(None),\n    tooltip=[\n        alt.Tooltip(\"monthdate(date)\", title=\"Date\"),\n        alt.Tooltip(\"max(temp_max)\", title=\"Max Temp\"),\n    ],\n).configure_view(\n    step=13,\n    strokeWidth=0\n).configure_axis(\n    domain=False\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nstates = alt.topo_feature(data.us_10m.url, 'states')\nsource = data.income.url\n\nalt.Chart(source).mark_geoshape().encode(\n    shape='geo:G',\n    color='pct:Q',\n    tooltip=['name:N', 'pct:Q'],\n    facet=alt.Facet('group:N', columns=2),\n).transform_lookup(\n    lookup='id',\n    from_=alt.LookupData(data=states, key='id'),\n    as_='geo'\n).properties(\n    width=300,\n    height=175,\n).project(\n    type='albersUsa'\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\nimport geopandas as gpd\n\n# load data\ngdf_quakies = gpd.read_file(data.earthquakes.url, driver=\"GeoJSON\")\ngdf_world = gpd.read_file(data.world_110m.url, driver=\"TopoJSON\")\n\n# defintion for interactive brush\nbrush = alt.selection_interval(\n    encodings=[\"longitude\"],\n    empty=False,\n    value={\"longitude\": [-50, -110]}\n)\n\n# world disk\nsphere = alt.Chart(alt.sphere()).mark_geoshape(\n    fill=\"transparent\", stroke=\"lightgray\", strokeWidth=1\n)\n\n# countries as shapes\nworld = alt.Chart(gdf_world).mark_geoshape(\n    fill=\"lightgray\", stroke=\"white\", strokeWidth=0.1\n)\n\n# earthquakes as dots on map\nquakes = alt.Chart(gdf_quakies).transform_calculate(\n    lon=\"datum.geometry.coordinates[0]\",\n    lat=\"datum.geometry.coordinates[1]\",\n).mark_circle(opacity=0.35, tooltip=True).encode(\n    longitude=\"lon:Q\",\n    latitude=\"lat:Q\",\n    color=alt.condition(brush, alt.value(\"goldenrod\"), alt.value(\"steelblue\")),\n    size=alt.Size(\"mag:Q\").scale(type=\"pow\", range=[1, 1000], domain=[0, 7], exponent=4),\n).add_params(brush)\n\n# combine layers for the map\nleft_map = alt.layer(sphere, world, quakes).project(type=\"mercator\")\n\n# histogram of binned earthquakes\nbars = alt.Chart(gdf_quakies).mark_bar().encode(\n    x=alt.X(\"mag:Q\").bin(extent=[0,7]),\n    y=\"count(mag):Q\",\n    color=alt.value(\"steelblue\")\n)\n\n# filtered earthquakes\nbars_overlay = bars.encode(color=alt.value(\"goldenrod\")).transform_filter(brush)\n\n# combine layers for histogram\nright_bars = alt.layer(bars, bars_overlay)\n\n# vertical concatenate map and bars\nleft_map | right_bars\n\n\n\n\n\n\n\n\nimport altair as alt\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(0)\n\nn_objects = 20\nn_times = 50\n\n# Create one (x, y) pair of metadata per object\nlocations = pd.DataFrame({\n    'id': range(n_objects),\n    'x': np.random.randn(n_objects),\n    'y': np.random.randn(n_objects)\n})\n\n# Create a 50-element time-series for each object\ntimeseries = pd.DataFrame(np.random.randn(n_times, n_objects).cumsum(0),\n                          columns=locations['id'],\n                          index=pd.RangeIndex(0, n_times, name='time'))\n\n# Melt the wide-form timeseries into a long-form view\ntimeseries = timeseries.reset_index().melt('time')\n\n# Merge the (x, y) metadata into the long-form view\ntimeseries['id'] = timeseries['id'].astype(int)  # make merge not complain\ndata = pd.merge(timeseries, locations, on='id')\n\n# Data is prepared, now make a chart\n\nselector = alt.selection_point(fields=['id'])\n\nbase = alt.Chart(data).properties(\n    width=250,\n    height=250\n).add_params(selector)\n\npoints = base.mark_point(filled=True, size=200).encode(\n    x='mean(x)',\n    y='mean(y)',\n    color=alt.condition(selector, 'id:O', alt.value('lightgray'), legend=None),\n)\n\ntimeseries = base.mark_line().encode(\n    x='time',\n    y=alt.Y('value').scale(domain=(-15, 15)),\n    color=alt.Color('id:O').legend(None)\n).transform_filter(\n    selector\n)\n\npoints | timeseries\n\n\n\n\n\n\n\n\nimport altair as alt\nimport vega_datasets\n\nalt.Chart(\n    vega_datasets.data.barley.url,\n    title='Barley Yield comparison between 1932 and 1931'\n).mark_trail().encode(\n    alt.X('year:O').title(None),\n    alt.Y('variety:N').title('Variety'),\n    alt.Size('yield:Q')\n        .scale(range=[0, 12])\n        .legend(values=[20, 60])\n        .title('Barley Yield (bushels/acre)'),\n    alt.Color('delta:Q')\n        .scale(domainMid=0)\n        .title('Yield Delta (%)'),\n    alt.Tooltip(['year:O', 'yield:Q']),\n    alt.Column('site:N').title('Site')\n).transform_pivot(\n    \"year\",\n    value=\"yield\",\n    groupby=[\"variety\", \"site\"]\n).transform_fold(\n    [\"1931\", \"1932\"],\n    as_=[\"year\", \"yield\"]\n).transform_calculate(\n    calculate=\"datum['1932'] - datum['1931']\",\n    as_=\"delta\"\n).configure_legend(\n    orient='bottom',\n    direction='horizontal'\n).configure_view(\n    stroke=None\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.disasters.url\n\nalt.Chart(source).transform_filter(\n    alt.datum.Entity != 'All natural disasters'\n).mark_circle(\n    opacity=0.8,\n    stroke='black',\n    strokeWidth=1,\n    strokeOpacity=0.4\n).encode(\n    alt.X('Year:T')\n        .title(None)\n        .scale(domain=['1899','2018']),\n    alt.Y('Entity:N')\n        .title(None)\n        .sort(field=\"Deaths\", op=\"sum\", order='descending'),\n    alt.Size('Deaths:Q')\n        .scale(range=[0, 2500])\n        .title('Deaths')\n        .legend(clipHeight=30, format='s'),\n    alt.Color('Entity:N').legend(None),\n    tooltip=[\n        \"Entity:N\",\n        alt.Tooltip(\"Year:T\", format='%Y'),\n        alt.Tooltip(\"Deaths:Q\", format='~s')\n    ],\n).properties(\n    width=450,\n    height=320,\n    title=alt.Title(\n        text=\"Global Deaths from Natural Disasters (1900-2017)\",\n        subtitle=\"The size of the bubble represents the total death count per year, by type of disaster\",\n        anchor='start'\n    )\n).configure_axisY(\n    domain=False,\n    ticks=False,\n    offset=10\n).configure_axisX(\n    grid=False,\n).configure_view(\n    stroke=None\n)\n\n\n\n\n\n\n\n\nimport altair as alt\nfrom vega_datasets import data\n\nsource = data.seattle_weather()\n\ncolor = alt.Color('weather:N').scale(\n    domain=['sun', 'fog', 'drizzle', 'rain', 'snow'],\n    range=['#e7ba52', '#a7a7a7', '#aec7e8', '#1f77b4', '#9467bd']\n)\n\n# We create two selections:\n# - a brush that is active on the top panel\n# - a multi-click that is active on the bottom panel\nbrush = alt.selection_interval(encodings=['x'])\nclick = alt.selection_point(encodings=['color'])\n\n# Top panel is scatter plot of temperature vs time\npoints = alt.Chart().mark_point().encode(\n    alt.X('monthdate(date):T').title('Date'),\n    alt.Y('temp_max:Q')\n        .title('Maximum Daily Temperature (C)')\n        .scale(domain=[-5, 40]),\n    alt.Size('precipitation:Q').scale(range=[5, 200]),\n    color=alt.condition(brush, color, alt.value('lightgray')),\n).properties(\n    width=550,\n    height=300\n).add_params(\n    brush\n).transform_filter(\n    click\n)\n\n# Bottom panel is a bar chart of weather type\nbars = alt.Chart().mark_bar().encode(\n    x='count()',\n    y='weather:N',\n    color=alt.condition(click, color, alt.value('lightgray')),\n).transform_filter(\n    brush\n).properties(\n    width=550,\n).add_params(\n    click\n)\n\nalt.vconcat(\n    points,\n    bars,\n    data=source,\n    title=\"Seattle Weather: 2012-2015\"\n)\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Display",
      "Altair"
    ]
  },
  {
    "objectID": "Display/plotly.html",
    "href": "Display/plotly.html",
    "title": "Plotly",
    "section": "",
    "text": "Plotly is an open-source graphing library that makes interactive, publication-quality graphs.\nIt is built on top of D3.js and WebGL.\nIntegrates seamlessly with Jupyter Labs and supports inline rendering.\nIt has two main interfaces:\n\nPlotly Express: High-level interface for quick, concise plotting.\nGraph Objects: Low-level, flexible interface for detailed customization.",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#overview",
    "href": "Display/plotly.html#overview",
    "title": "Plotly",
    "section": "",
    "text": "Plotly is an open-source graphing library that makes interactive, publication-quality graphs.\nIt is built on top of D3.js and WebGL.\nIntegrates seamlessly with Jupyter Labs and supports inline rendering.\nIt has two main interfaces:\n\nPlotly Express: High-level interface for quick, concise plotting.\nGraph Objects: Low-level, flexible interface for detailed customization.",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#installing-plotly-for-jupyter-labs",
    "href": "Display/plotly.html#installing-plotly-for-jupyter-labs",
    "title": "Plotly",
    "section": "2. Installing Plotly for Jupyter Labs",
    "text": "2. Installing Plotly for Jupyter Labs\nTo get started with Plotly in Jupyter Labs, you need to install the following:\n\nInstall Plotly Library\npip install plotly\n\n\nInstall JupyterLab Extensions\nTo render Plotly figures within JupyterLab, you need to install the following extensions:\n# JupyterLab 3.x and above (Extensions are auto-managed)\npip install jupyterlab \"ipywidgets&gt;=7.5\"\n\n# For older JupyterLab versions, you might need:\njupyter labextension install jupyterlab-plotly\njupyter labextension install @jupyter-widgets/jupyterlab-manager\n\n\nCheck Installation\n\nimport plotly\nprint(plotly.__version__)  # Should be 5.x or above\nEnsure you have Plotly version 5.x or above for the latest features.\n\n\nimport plotly\nprint(plotly.__version__)  # Should be 5.x or above\n\n6.0.0",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#importing-plotly",
    "href": "Display/plotly.html#importing-plotly",
    "title": "Plotly",
    "section": "3. Importing Plotly",
    "text": "3. Importing Plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nPlotly Express (px): High-level, easy-to-use interface for rapid plotting.\nGraph Objects (go): Low-level, flexible API for detailed customization.\n\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#plotly-express-basics",
    "href": "Display/plotly.html#plotly-express-basics",
    "title": "Plotly",
    "section": "4. Plotly Express Basics",
    "text": "4. Plotly Express Basics\n\n4.1. Line Chart\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\n\n# Sample Data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Line Plot\nfig = px.line(df, x='x', y='y', title='Sine Wave')\nfig.show()\n\n### **4.2. Scatter Plot**\n\n```python\nfig = px.scatter(df, x='x', y='y', title='Scatter Plot of Sine Wave')\nfig.show()\n\n\n4.3. Bar Chart\ndata = {'Fruits': ['Apple', 'Banana', 'Cherry', 'Date'],\n        'Quantity': [10, 20, 15, 5]}\n\ndf = pd.DataFrame(data)\n\nfig = px.bar(df, x='Fruits', y='Quantity', title='Fruit Quantity')\nfig.show()\n\n\n4.4. Histogram\nfig = px.histogram(df, x='Quantity', title='Histogram of Quantity')\nfig.show()\n\n\n4.5. Pie Chart\nfig = px.pie(df, names='Fruits', values='Quantity', title='Fruit Distribution')\nfig.show()\n\n\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nimport plotly.offline as pyo\nfrom IPython.display import HTML, display\n# Sample Data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\ndf = pd.DataFrame({'x': x, 'y': y})\n# Turn off the menu bar\nconfig = {\n    'displayModeBar': False  # Disable the mode bar (menu bar)\n}\n\n# Line Plot\nfig = px.line(df, x='x', y='y', title='Sine Wave')\n# fig.show(config=config)\nfig_html = fig.to_html(full_html=False, config=config)\ndisplay(HTML(fig_html))\n\nfig = px.scatter(df, x='x', y='y', title='Scatter Plot of Sine Wave')\n# fig.show(config=config)\nfig_html = fig.to_html(full_html=False, config=config)\ndisplay(HTML(fig_html))\n\n                        \n                                            \n\n\n                        \n                                            \n\n\n\ndata = {'Fruits': ['Apple', 'Banana', 'Cherry', 'Date'],\n        'Quantity': [10, 20, 15, 5]}\n\ndf = pd.DataFrame(data)\n\nfig = px.bar(df, x='Fruits', y='Quantity', title='Fruit Quantity')\nfig_html = fig.to_html(full_html=False, config=config)\ndisplay(HTML(fig_html))\n\n\nfig = px.histogram(df, x='Quantity', title='Histogram of Quantity')\nfig_html = fig.to_html(full_html=False, config=config)\ndisplay(HTML(fig_html))\n\n\nfig = px.pie(df, names='Fruits', values='Quantity', title='Fruit Distribution')\nfig_html = fig.to_html(full_html=False, config=config)\ndisplay(HTML(fig_html))",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#advanced-plotly-express-features",
    "href": "Display/plotly.html#advanced-plotly-express-features",
    "title": "Plotly",
    "section": "5. Advanced Plotly Express Features",
    "text": "5. Advanced Plotly Express Features\n\n5.1. Facet Plots\ndf = px.data.tips()\n\nfig = px.scatter(df, x=\"total_bill\", y=\"tip\", color=\"sex\",\n                 facet_col=\"time\", facet_row=\"smoker\",\n                 title=\"Facet Plot of Tips\")\nfig.show()\n\n\n5.2. Animations\ndf = px.data.gapminder()\n\nfig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", \n                 animation_group=\"country\", size=\"pop\", color=\"continent\",\n                 hover_name=\"country\", log_x=True, size_max=55, \n                 range_x=[100,100000], range_y=[25,90],\n                 title=\"Gapminder Animation\")\nfig.show()\n\n\n5.3. 3D Scatter Plot\nfig = px.scatter_3d(df, x='gdpPercap', y='lifeExp', z='pop', \n                    color='continent', size='pop', \n                    hover_name='country', log_x=True, \n                    title=\"3D Scatter Plot of Gapminder Data\")\nfig.show()\n\n\n5.4. Geographic Plots\nfig = px.choropleth(df, locations=\"iso_alpha\",\n                    color=\"lifeExp\",\n                    hover_name=\"country\",\n                    animation_frame=\"year\",\n                    title=\"World Life Expectancy Over Time\")\nfig.show()\n\n\ndf = px.data.tips()\n\nfig = px.scatter(df, x=\"total_bill\", y=\"tip\", color=\"sex\",\n                 facet_col=\"time\", facet_row=\"smoker\",\n                 title=\"Facet Plot of Tips\")\nfig.show()\n\ndf = px.data.gapminder()\n\nfig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", \n                 animation_group=\"country\", size=\"pop\", color=\"continent\",\n                 hover_name=\"country\", log_x=True, size_max=55, \n                 range_x=[100,10000], range_y=[25,90],\n                 title=\"Gapminder Animation\")\nfig.show()",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#plotly-graph-objects-advanced-customization",
    "href": "Display/plotly.html#plotly-graph-objects-advanced-customization",
    "title": "Plotly",
    "section": "6. Plotly Graph Objects (Advanced Customization)",
    "text": "6. Plotly Graph Objects (Advanced Customization)\n\n6.1. Line Chart\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name='Sine Wave'))\nfig.update_layout(title='Sine Wave', xaxis_title='X', yaxis_title='Y')\nfig.show()\n\n\n6.2. Subplots\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=2, cols=2)\n\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Line Plot'), row=1, col=1)\nfig.add_trace(go.Scatter(x=x, y=np.cos(x), mode='markers', name='Scatter Plot'), row=1, col=2)\nfig.add_trace(go.Bar(x=['A', 'B', 'C'], y=[5, 10, 15], name='Bar Chart'), row=2, col=1)\nfig.add_trace(go.Pie(labels=['Apple', 'Banana', 'Cherry'], values=[10, 20, 30], name='Pie Chart'), row=2, col=2)\n\nfig.update_layout(title='Multiple Plots')\nfig.show()\n\n\n6.3. Annotations and Shapes\nfig.update_layout(\n    annotations=[dict(x=2, y=0, xref=\"x\", yref=\"y\", text=\"Annotation\",\n                      showarrow=True, arrowhead=2)],\n    shapes=[dict(type=\"line\", x0=2, y0=-1, x1=2, y1=1, \n                 line=dict(color=\"RoyalBlue\", width=2))]\n)\nfig.show()\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines+markers', name='Sine Wave'))\nfig.update_layout(title='Sine Wave', xaxis_title='X', yaxis_title='Y')\nfig.show()\n\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(rows=2, cols=2)\n\nfig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Line Plot'), row=1, col=1)\nfig.add_trace(go.Scatter(x=x, y=np.cos(x), mode='markers', name='Scatter Plot'), row=1, col=2)\nfig.add_trace(go.Bar(x=['A', 'B', 'C'], y=[5, 10, 15], name='Bar Chart'), row=2, col=1)\n# fig.add_trace(go.Pie(labels=['Apple', 'Banana', 'Cherry'], values=[10, 20, 30], name='Pie Chart'), row=2, col=2)\n\nfig.update_layout(title='Multiple Plots')\nfig.show()\n\nfig.update_layout(\n    annotations=[dict(x=2, y=0, xref=\"x\", yref=\"y\", text=\"Annotation\",\n                      showarrow=True, arrowhead=2)],\n    shapes=[dict(type=\"line\", x0=2, y0=-1, x1=2, y1=1, \n                 line=dict(color=\"RoyalBlue\", width=2))]\n)\nfig.show()",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#saving-and-exporting",
    "href": "Display/plotly.html#saving-and-exporting",
    "title": "Plotly",
    "section": "7. Saving and Exporting",
    "text": "7. Saving and Exporting\n\n7.1. Static Images\nfig.write_image(\"plot.png\")   # PNG format\nfig.write_image(\"plot.pdf\")   # PDF format\nDependencies:\npip install -U kaleido  # Required for static image export\n\n\n7.2. Interactive HTML\nfig.write_html(\"plot.html\", auto_open=True)",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#integration-with-jupyter-widgets",
    "href": "Display/plotly.html#integration-with-jupyter-widgets",
    "title": "Plotly",
    "section": "8. Integration with Jupyter Widgets",
    "text": "8. Integration with Jupyter Widgets\nimport ipywidgets as widgets\n\ndef update_plot(change):\n    new_data = np.sin(x + change['new'])\n    fig = px.line(x=x, y=new_data, title='Interactive Sine Wave')\n    fig.show()\n\nslider = widgets.FloatSlider(value=0, min=0, max=10, step=0.1, description='Phase')\nslider.observe(update_plot, names='value')\ndisplay(slider)",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#best-practices-and-tips",
    "href": "Display/plotly.html#best-practices-and-tips",
    "title": "Plotly",
    "section": "9. Best Practices and Tips",
    "text": "9. Best Practices and Tips\n\nUse Plotly Express for quick prototyping and rapid visualization.\nUse Graph Objects for advanced customizations and complex layouts.\nOptimize Performance:\n\nUse scattergl for large datasets (WebGL acceleration).\nReduce DOM size by limiting data points or using aggregation.\n\nJupyterLab Integration:\n\nEnsure JupyterLab extensions are up to date for optimal rendering.\nUse fig.show(renderer='notebook') for inline rendering in some cases.",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/plotly.html#common-issues-and-solutions",
    "href": "Display/plotly.html#common-issues-and-solutions",
    "title": "Plotly",
    "section": "10. Common Issues and Solutions",
    "text": "10. Common Issues and Solutions\n\n10.1. Graphs Not Displaying in Jupyter Lab\n\nEnsure JupyterLab extensions are installed and updated.\nClear browser cache or try a different browser.\nUse %matplotlib inline to avoid conflicts with Matplotlib.\n\n\n\n10.2. Exporting as Static Images Not Working\n\nInstall kaleido for image exporting:\npip install -U kaleido\n\n\n\n10.3. Performance Lag with Large Datasets\n\nUse scattergl for WebGL acceleration.\nConsider down-sampling or aggregating data.",
    "crumbs": [
      "Blog",
      "Display",
      "Plotly"
    ]
  },
  {
    "objectID": "Display/manim.html",
    "href": "Display/manim.html",
    "title": "Manim",
    "section": "",
    "text": "pip install manim\npip list | grep manim\n\nmanim                     0.18.1\nNote: you may need to restart the kernel to use updated packages.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#quickstart",
    "href": "Display/manim.html#quickstart",
    "title": "Manim",
    "section": "Quickstart",
    "text": "Quickstart\n\nfrom manim import *\n\n\nclass SquareToCircle(Scene):\n   def construct(self):\n      square = Square()\n      circle = Circle()\n&lt;/video&gt;\n      circle.set_fill(PINK, opacity=0.5)\n      self.play(Create(square))\n      self.play(Transform(square, circle))\n      self.wait()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#animating-a-circle",
    "href": "Display/manim.html#animating-a-circle",
    "title": "Manim",
    "section": "Animating a circle",
    "text": "Animating a circle\n\nclass CreateCircle(Scene):\n    def construct(self):\n        circle = Circle()  # create a circle\n        circle.set_fill(PINK, opacity=0.5)  # set the color and transparency\n        self.play(Create(circle))  # show the circle on screen\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#positioning-mobjects",
    "href": "Display/manim.html#positioning-mobjects",
    "title": "Manim",
    "section": "Positioning Mobjects",
    "text": "Positioning Mobjects\n\nclass SquareAndCircle(Scene):\n    def construct(self):\n        circle = Circle()  # create a circle\n        circle.set_fill(PINK, opacity=0.5)  # set the color and transparency\n\n        square = Square()  # create a square\n        square.set_fill(BLUE, opacity=0.5)  # set the color and transparency\n\n        square.next_to(circle, RIGHT, buff=0.5)  # set the position\n        self.play(Create(circle), Create(square))  # show the shapes on screen\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#using-.animate-syntax-to-animate-methodsm2",
    "href": "Display/manim.html#using-.animate-syntax-to-animate-methodsm2",
    "title": "Manim",
    "section": "Using .animate syntax to animate methodsm2",
    "text": "Using .animate syntax to animate methodsm2\n\nclass AnimatedSquareToCircle(Scene):\n    def construct(self):\n        circle = Circle()  # create a circle\n        square = Square()  # create a square\n\n        self.play(Create(square))  # show the square on screen\n        self.play(square.animate.rotate(PI / 4))  # rotate the square\n        self.play(Transform(square, circle))  # transform the square into a circle\n        self.play(\n            square.animate.set_fill(PINK, opacity=0.5)\n        )  # color the circle on screen\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass DifferentRotations(Scene):\n    def construct(self):\n        left_square = Square(color=BLUE, fill_opacity=0.7).shift(2 * LEFT)\n        right_square = Square(color=GREEN, fill_opacity=0.7).shift(2 * RIGHT)\n        self.play(\n            left_square.animate.rotate(PI), Rotate(right_square, angle=PI), run_time=2\n        )\n        self.wait()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#transform-vs-replacementtransform",
    "href": "Display/manim.html#transform-vs-replacementtransform",
    "title": "Manim",
    "section": "Transform vs ReplacementTransform",
    "text": "Transform vs ReplacementTransform\nThe difference between Transform and ReplacementTransform is that Transform(mob1, mob2) transforms the points (as well as other attributes like color) of mob1 into the points/attributes of mob2.\nReplacementTransform(mob1, mob2) on the other hand literally replaces mob1 on the scene with mob2.\nThe use of ReplacementTransform or Transform is mostly up to personal preference. They can be used to accomplish the same effect, as shown below.\n\nclass TwoTransforms(Scene):\n    def transform(self):\n        a = Circle()\n        b = Square()\n        c = Triangle()\n        self.play(Transform(a, b))\n        self.play(Transform(a, c))\n        self.play(FadeOut(a))\n\n    def replacement_transform(self):\n        a = Circle()\n        b = Square()\n        c = Triangle()\n        self.play(ReplacementTransform(a, b))\n        self.play(ReplacementTransform(b, c))\n        self.play(FadeOut(c))\n\n    def construct(self):\n        self.transform()\n        self.wait(0.5)  # wait for 0.5 seconds\n        self.replacement_transform()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\n\n\nfrom IPython.display import Video\n\nVideo(\"media/jupyter/AnimatedSquareToCircle@2024-05-01@18-04-50.mp4\")\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#advanced",
    "href": "Display/manim.html#advanced",
    "title": "Manim",
    "section": "Advanced",
    "text": "Advanced\n\nShapes\n\nclass Shapes(Scene):\n    def construct(self):\n        circle = Circle()\n        square = Square()\n        triangle = Triangle()\n\n        circle.shift(LEFT)\n        square.shift(UP)\n        triangle.shift(RIGHT)\n\n        self.add(circle, square, triangle)\n        # self.wait(1)\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\n\nMobjectPlacement\n\nclass MobjectPlacement(Scene):\n    def construct(self):\n        circle = Circle()\n        square = Square()\n        triangle = Triangle()\n\n        # place the circle two units left from the origin\n        circle.move_to(LEFT * 2)\n        # place the square to the left of the circle\n        square.next_to(circle, LEFT)\n        # align the left border of the triangle to the left border of the circle\n        triangle.align_to(circle, LEFT)\n\n        self.add(circle, square, triangle)\n        self.wait(1)\n\nManim Community v0.18.1\n\n\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nMobjectStyling\n\nclass MobjectStyling(Scene):\n    def construct(self):\n        circle = Circle().shift(LEFT)\n        square = Square().shift(UP)\n        triangle = Triangle().shift(RIGHT)\n\n        circle.set_stroke(color=GREEN, width=20)\n        square.set_fill(YELLOW, opacity=1.0)\n        triangle.set_fill(PINK, opacity=0.5)\n\n        self.add(circle, square, triangle)\n        self.wait(1)\n\nManim Community v0.18.1\n\n\n\n\n\n      Your browser does not support the video element.\n    \n\n\n\n\nAnimations\n\nclass SomeAnimations(Scene):\n    def construct(self):\n        square = Square().set_fill(RED, opacity=1.0)\n        self.add(square)\n        # some animations display mobjects, ...\n        self.play(FadeIn(square))\n\n        # ... some move or rotate mobjects around...\n        self.play(Rotate(square, PI/4))\n        \n        self.play(square.animate.set_fill(WHITE).shift(UP).rotate(PI / 3), run_time=2)\n        \n        # some animations remove mobjects from the screen\n        self.play(FadeOut(square))\n        \n\n        self.wait(1)\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass MobjectExample(Scene):\n    def construct(self):\n        p1 = [-1,-1, 0]\n        p2 = [ 1,-1, 0]\n        p3 = [ 1, 1, 0]\n        p4 = [-1, 1, 0]\n        a  = Line(p1,p2).append_points(Line(p2,p3).points).append_points(Line(p3,p4).points)\n        point_start  = a.get_start()\n        point_end    = a.get_end()\n        point_center = a.get_center()\n        self.add(Text(f\"a.get_start() = {np.round(point_start,2).tolist()}\", font_size=24).to_edge(UR).set_color(YELLOW))\n        self.add(Text(f\"a.get_end() = {np.round(point_end,2).tolist()}\", font_size=24).next_to(self.mobjects[-1],DOWN).set_color(RED))\n        self.add(Text(f\"a.get_center() = {np.round(point_center,2).tolist()}\", font_size=24).next_to(self.mobjects[-1],DOWN).set_color(BLUE))\n\n        self.add(Dot(a.get_start()).set_color(YELLOW).scale(2))\n        self.add(Dot(a.get_end()).set_color(RED).scale(2))\n        self.add(Dot(a.get_top()).set_color(GREEN_A).scale(2))\n        self.add(Dot(a.get_bottom()).set_color(GREEN_D).scale(2))\n        self.add(Dot(a.get_center()).set_color(BLUE).scale(2))\n        self.add(Dot(a.point_from_proportion(0.5)).set_color(ORANGE).scale(2))\n        self.add(*[Dot(x) for x in a.points])\n        self.add(a)\n\nManim Community v0.18.1",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "Display/manim.html#example",
    "href": "Display/manim.html#example",
    "title": "Manim",
    "section": "Example",
    "text": "Example\n\nclass BraceAnnotation(Scene):\n    def construct(self):\n        dot = Dot([-2, -1, 0])\n        dot2 = Dot([2, 1, 0])\n        line = Line(dot.get_center(), dot2.get_center()).set_color(ORANGE)\n        b1 = Brace(line)\n        b1text = b1.get_text(f\"Horizontal distance\")\n        b2 = Brace(line, direction=line.copy().rotate(PI / 2).get_unit_vector())\n        b2text = b2.get_tex(f\"x-x_1\")\n        self.add(line, dot, dot2, b1, b2, b1text, b2text)\n\nManim Community v0.18.1\n\n\n\n\n[05/01/24 19:15:57] ERROR    LaTeX compilation error: LaTeX Error: File `standalone.cls'    tex_file_writing.py:314\n                             not found.                                                                            \n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n                    ERROR    LaTeX compilation error: Emergency stop.                       tex_file_writing.py:314\n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 get_ipython().run_cell_magic('manim', '-qm -v WARNING BraceAnnotation', '\\nclass BraceAnnotation(Scene):\\n    def construct(self):\\n        dot = Dot([-2, -1, 0])\\n        dot2 = Dot([2, 1, 0])\\n        line = Line(dot.get_center(), dot2.get_center()).set_color(ORANGE)\\n        b1 = Brace(line)\\n        b1text = b1.get_text(f\"Horizontal distance\")\\n        b2 = Brace(line, direction=line.copy().rotate(PI / 2).get_unit_vector())\\n        b2text = b2.get_tex(f\"x-x_1\")\\n        self.add(line, dot, dot2, b1, b2, b1text, b2text)\\n')\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-&gt; 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/ipython_magic.py:143, in ManimMagic.manim(self, line, cell, local_ns)\n    141     SceneClass = local_ns[config[\"scene_names\"][0]]\n    142     scene = SceneClass(renderer=renderer)\n--&gt; 143     scene.render()\n    144 finally:\n    145     # Shader cache becomes invalid as the context is destroyed\n    146     shader_program_cache.clear()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/scene/scene.py:229, in Scene.render(self, preview)\n    227 self.setup()\n    228 try:\n--&gt; 229     self.construct()\n    230 except EndSceneEarlyException:\n    231     pass\n\nFile &lt;string&gt;:8, in construct(self)\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/svg/brace.py:139, in Brace.get_text(self, *text, **kwargs)\n    138 def get_text(self, *text, **kwargs):\n--&gt; 139     text_mob = Tex(*text)\n    140     self.put_at_tip(text_mob, **kwargs)\n    141     return text_mob\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:443, in Tex.__init__(self, arg_separator, tex_environment, *tex_strings, **kwargs)\n    440 def __init__(\n    441     self, *tex_strings, arg_separator=\"\", tex_environment=\"center\", **kwargs\n    442 ):\n--&gt; 443     super().__init__(\n    444         *tex_strings,\n    445         arg_separator=arg_separator,\n    446         tex_environment=tex_environment,\n    447         **kwargs,\n    448     )\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:293, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    280     if self.brace_notation_split_occurred:\n    281         logger.error(\n    282             dedent(\n    283                 \"\"\"\\\n   (...)\n    291             ),\n    292         )\n--&gt; 293     raise compilation_error\n    294 self.set_color_by_tex_to_color_map(self.tex_to_color_map)\n    296 if self.organize_left_to_right:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:272, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    270 self.tex_strings = self._break_up_tex_strings(tex_strings)\n    271 try:\n--&gt; 272     super().__init__(\n    273         self.arg_separator.join(self.tex_strings),\n    274         tex_environment=self.tex_environment,\n    275         tex_template=self.tex_template,\n    276         **kwargs,\n    277     )\n    278     self._break_up_by_substrings()\n    279 except ValueError as compilation_error:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:81, in SingleStringMathTex.__init__(self, tex_string, stroke_width, should_center, height, organize_left_to_right, tex_environment, tex_template, font_size, **kwargs)\n     79 assert isinstance(tex_string, str)\n     80 self.tex_string = tex_string\n---&gt; 81 file_name = tex_to_svg_file(\n     82     self._get_modified_expression(tex_string),\n     83     environment=self.tex_environment,\n     84     tex_template=self.tex_template,\n     85 )\n     86 super().__init__(\n     87     file_name=file_name,\n     88     should_center=should_center,\n   (...)\n     95     **kwargs,\n     96 )\n     97 self.init_colors()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:63, in tex_to_svg_file(expression, environment, tex_template)\n     60 if svg_file.exists():\n     61     return svg_file\n---&gt; 63 dvi_file = compile_tex(\n     64     tex_file,\n     65     tex_template.tex_compiler,\n     66     tex_template.output_format,\n     67 )\n     68 svg_file = convert_to_svg(dvi_file, tex_template.output_format)\n     69 if not config[\"no_latex_cleanup\"]:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:213, in compile_tex(tex_file, tex_compiler, output_format)\n    211         log_file = tex_file.with_suffix(\".log\")\n    212         print_all_tex_errors(log_file, tex_compiler, tex_file)\n--&gt; 213         raise ValueError(\n    214             f\"{tex_compiler} error converting to\"\n    215             f\" {output_format[1:]}. See log output above or\"\n    216             f\" the log file: {log_file}\",\n    217         )\n    218 return result\n\nValueError: latex error converting to dvi. See log output above or the log file: media/Tex/1c22c507eca0dfce.log\n\n\n\n\nclass VectorArrow(Scene):\n    def construct(self):\n        dot = Dot(ORIGIN)\n        arrow = Arrow(ORIGIN, [2, 2, 0], buff=0)\n        numberplane = NumberPlane()\n        origin_text = Text('(0, 0)').next_to(dot, DOWN)\n        tip_text = Text('(2, 2)').next_to(arrow.get_end(), RIGHT)\n        self.add(numberplane, dot, arrow, origin_text, tip_text)\n\nManim Community v0.18.1\n\n\n\n\n\n\n\n\n\n\n\n\nclass PointMovingOnShapes(Scene):\n    def construct(self):\n        circle = Circle(radius=1, color=BLUE)\n        dot = Dot()\n        dot2 = dot.copy().shift(RIGHT)\n        self.add(dot)\n\n        line = Line([3, 0, 0], [5, 0, 0])\n        self.add(line)\n\n        self.play(GrowFromCenter(circle))\n        self.play(Transform(dot, dot2))\n        self.play(MoveAlongPath(dot, circle), run_time=2, rate_func=linear)\n        self.play(Rotating(dot, about_point=[2, 0, 0]), run_time=1.5)\n        self.wait()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass MovingAngle(Scene):\n    def construct(self):\n        rotation_center = LEFT\n\n        theta_tracker = ValueTracker(110)\n        line1 = Line(LEFT, RIGHT)\n        line_moving = Line(LEFT, RIGHT)\n        line_ref = line_moving.copy()\n        line_moving.rotate(\n            theta_tracker.get_value() * DEGREES, about_point=rotation_center\n        )\n        a = Angle(line1, line_moving, radius=0.5, other_angle=False)\n        tex = MathTex(r\"\\theta\").move_to(\n            Angle(\n                line1, line_moving, radius=0.5 + 3 * SMALL_BUFF, other_angle=False\n            ).point_from_proportion(0.5)\n        )\n\n        self.add(line1, line_moving, a, tex)\n        self.wait()\n\n        line_moving.add_updater(\n            lambda x: x.become(line_ref.copy()).rotate(\n                theta_tracker.get_value() * DEGREES, about_point=rotation_center\n            )\n        )\n\n        a.add_updater(\n            lambda x: x.become(Angle(line1, line_moving, radius=0.5, other_angle=False))\n        )\n        tex.add_updater(\n            lambda x: x.move_to(\n                Angle(\n                    line1, line_moving, radius=0.5 + 3 * SMALL_BUFF, other_angle=False\n                ).point_from_proportion(0.5)\n            )\n        )\n\n        self.play(theta_tracker.animate.set_value(40))\n        self.play(theta_tracker.animate.increment_value(140))\n        self.play(tex.animate.set_color(RED), run_time=0.5)\n        self.play(theta_tracker.animate.set_value(350))\n\nManim Community v0.18.1\n\n\n\n\n[05/01/24 19:16:10] ERROR    LaTeX compilation error: LaTeX Error: File `standalone.cls'    tex_file_writing.py:314\n                             not found.                                                                            \n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n                    ERROR    LaTeX compilation error: Emergency stop.                       tex_file_writing.py:314\n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 get_ipython().run_cell_magic('manim', '-qm -v WARNING MovingAngle', '\\nclass MovingAngle(Scene):\\n    def construct(self):\\n        rotation_center = LEFT\\n\\n        theta_tracker = ValueTracker(110)\\n        line1 = Line(LEFT, RIGHT)\\n        line_moving = Line(LEFT, RIGHT)\\n        line_ref = line_moving.copy()\\n        line_moving.rotate(\\n            theta_tracker.get_value() * DEGREES, about_point=rotation_center\\n        )\\n        a = Angle(line1, line_moving, radius=0.5, other_angle=False)\\n        tex = MathTex(r\"\\\\theta\").move_to(\\n            Angle(\\n                line1, line_moving, radius=0.5 + 3 * SMALL_BUFF, other_angle=False\\n            ).point_from_proportion(0.5)\\n        )\\n\\n        self.add(line1, line_moving, a, tex)\\n        self.wait()\\n\\n        line_moving.add_updater(\\n            lambda x: x.become(line_ref.copy()).rotate(\\n                theta_tracker.get_value() * DEGREES, about_point=rotation_center\\n            )\\n        )\\n\\n        a.add_updater(\\n            lambda x: x.become(Angle(line1, line_moving, radius=0.5, other_angle=False))\\n        )\\n        tex.add_updater(\\n            lambda x: x.move_to(\\n                Angle(\\n                    line1, line_moving, radius=0.5 + 3 * SMALL_BUFF, other_angle=False\\n                ).point_from_proportion(0.5)\\n            )\\n        )\\n\\n        self.play(theta_tracker.animate.set_value(40))\\n        self.play(theta_tracker.animate.increment_value(140))\\n        self.play(tex.animate.set_color(RED), run_time=0.5)\\n        self.play(theta_tracker.animate.set_value(350))\\n')\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-&gt; 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/ipython_magic.py:143, in ManimMagic.manim(self, line, cell, local_ns)\n    141     SceneClass = local_ns[config[\"scene_names\"][0]]\n    142     scene = SceneClass(renderer=renderer)\n--&gt; 143     scene.render()\n    144 finally:\n    145     # Shader cache becomes invalid as the context is destroyed\n    146     shader_program_cache.clear()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/scene/scene.py:229, in Scene.render(self, preview)\n    227 self.setup()\n    228 try:\n--&gt; 229     self.construct()\n    230 except EndSceneEarlyException:\n    231     pass\n\nFile &lt;string&gt;:14, in construct(self)\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:293, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    280     if self.brace_notation_split_occurred:\n    281         logger.error(\n    282             dedent(\n    283                 \"\"\"\\\n   (...)\n    291             ),\n    292         )\n--&gt; 293     raise compilation_error\n    294 self.set_color_by_tex_to_color_map(self.tex_to_color_map)\n    296 if self.organize_left_to_right:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:272, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    270 self.tex_strings = self._break_up_tex_strings(tex_strings)\n    271 try:\n--&gt; 272     super().__init__(\n    273         self.arg_separator.join(self.tex_strings),\n    274         tex_environment=self.tex_environment,\n    275         tex_template=self.tex_template,\n    276         **kwargs,\n    277     )\n    278     self._break_up_by_substrings()\n    279 except ValueError as compilation_error:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:81, in SingleStringMathTex.__init__(self, tex_string, stroke_width, should_center, height, organize_left_to_right, tex_environment, tex_template, font_size, **kwargs)\n     79 assert isinstance(tex_string, str)\n     80 self.tex_string = tex_string\n---&gt; 81 file_name = tex_to_svg_file(\n     82     self._get_modified_expression(tex_string),\n     83     environment=self.tex_environment,\n     84     tex_template=self.tex_template,\n     85 )\n     86 super().__init__(\n     87     file_name=file_name,\n     88     should_center=should_center,\n   (...)\n     95     **kwargs,\n     96 )\n     97 self.init_colors()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:63, in tex_to_svg_file(expression, environment, tex_template)\n     60 if svg_file.exists():\n     61     return svg_file\n---&gt; 63 dvi_file = compile_tex(\n     64     tex_file,\n     65     tex_template.tex_compiler,\n     66     tex_template.output_format,\n     67 )\n     68 svg_file = convert_to_svg(dvi_file, tex_template.output_format)\n     69 if not config[\"no_latex_cleanup\"]:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:213, in compile_tex(tex_file, tex_compiler, output_format)\n    211         log_file = tex_file.with_suffix(\".log\")\n    212         print_all_tex_errors(log_file, tex_compiler, tex_file)\n--&gt; 213         raise ValueError(\n    214             f\"{tex_compiler} error converting to\"\n    215             f\" {output_format[1:]}. See log output above or\"\n    216             f\" the log file: {log_file}\",\n    217         )\n    218 return result\n\nValueError: latex error converting to dvi. See log output above or the log file: media/Tex/0cec1e994feab60e.log\n\n\n\n\nclass MovingDots(Scene):\n    def construct(self):\n        d1,d2=Dot(color=BLUE),Dot(color=GREEN)\n        dg=VGroup(d1,d2).arrange(RIGHT,buff=1)\n        l1=Line(d1.get_center(),d2.get_center()).set_color(RED)\n        x=ValueTracker(0)\n        y=ValueTracker(0)\n        d1.add_updater(lambda z: z.set_x(x.get_value()))\n        d2.add_updater(lambda z: z.set_y(y.get_value()))\n        l1.add_updater(lambda z: z.become(Line(d1.get_center(),d2.get_center())))\n        self.add(d1,d2,l1)\n        self.play(x.animate.set_value(5))\n        self.play(y.animate.set_value(4))\n        self.wait()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass MovingGroupToDestination(Scene):\n    def construct(self):\n        group = VGroup(Dot(LEFT), Dot(ORIGIN), Dot(RIGHT, color=RED), Dot(2 * RIGHT)).scale(1.4)\n        dest = Dot([4, 3, 0], color=YELLOW)\n        self.add(group, dest)\n        self.play(group.animate.shift(dest.get_center() - group[2].get_center()))\n        self.wait(0.5)\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass SinAndCosFunctionPlot(Scene):\n    def construct(self):\n        axes = Axes(\n            x_range=[-10, 10.3, 1],\n            y_range=[-1.5, 1.5, 1],\n            x_length=10,\n            axis_config={\"color\": GREEN},\n            x_axis_config={\n                \"numbers_to_include\": np.arange(-10, 10.01, 2),\n                \"numbers_with_elongated_ticks\": np.arange(-10, 10.01, 2),\n            },\n            tips=False,\n        )\n        axes_labels = axes.get_axis_labels()\n        sin_graph = axes.plot(lambda x: np.sin(x), color=BLUE)\n        cos_graph = axes.plot(lambda x: np.cos(x), color=RED)\n\n        sin_label = axes.get_graph_label(\n            sin_graph, \"\\\\sin(x)\", x_val=-10, direction=UP / 2\n        )\n        cos_label = axes.get_graph_label(cos_graph, label=\"\\\\cos(x)\")\n\n        vert_line = axes.get_vertical_line(\n            axes.i2gp(TAU, cos_graph), color=YELLOW, line_func=Line\n        )\n        line_label = axes.get_graph_label(\n            cos_graph, \"x=2\\pi\", x_val=TAU, direction=UR, color=WHITE\n        )\n\n        plot = VGroup(axes, sin_graph, cos_graph, vert_line)\n        labels = VGroup(axes_labels, sin_label, cos_label, line_label)\n        self.add(plot, labels)\n\n&lt;string&gt;:28: SyntaxWarning: invalid escape sequence '\\p'\n\n\nManim Community v0.18.1\n\n\n\n\n[05/01/24 19:16:12] ERROR    LaTeX compilation error: LaTeX Error: File `standalone.cls'    tex_file_writing.py:314\n                             not found.                                                                            \n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n                    ERROR    LaTeX compilation error: Emergency stop.                       tex_file_writing.py:314\n                                                                                                                   \n\n\n\n                    ERROR    Context of error:                                              tex_file_writing.py:348\n                             -&gt; \\documentclass[preview]{standalone}                                                \n                             \\usepackage[english]{babel}                                                           \n                             \\usepackage{amsmath}                                                                  \n                             \\usepackage{amssymb}                                                                  \n                                                                                                                   \n\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[21], line 1\n----&gt; 1 get_ipython().run_cell_magic('manim', '-qm -v WARNING SinAndCosFunctionPlot', '\\nclass SinAndCosFunctionPlot(Scene):\\n    def construct(self):\\n        axes = Axes(\\n            x_range=[-10, 10.3, 1],\\n            y_range=[-1.5, 1.5, 1],\\n            x_length=10,\\n            axis_config={\"color\": GREEN},\\n            x_axis_config={\\n                \"numbers_to_include\": np.arange(-10, 10.01, 2),\\n                \"numbers_with_elongated_ticks\": np.arange(-10, 10.01, 2),\\n            },\\n            tips=False,\\n        )\\n        axes_labels = axes.get_axis_labels()\\n        sin_graph = axes.plot(lambda x: np.sin(x), color=BLUE)\\n        cos_graph = axes.plot(lambda x: np.cos(x), color=RED)\\n\\n        sin_label = axes.get_graph_label(\\n            sin_graph, \"\\\\\\\\sin(x)\", x_val=-10, direction=UP / 2\\n        )\\n        cos_label = axes.get_graph_label(cos_graph, label=\"\\\\\\\\cos(x)\")\\n\\n        vert_line = axes.get_vertical_line(\\n            axes.i2gp(TAU, cos_graph), color=YELLOW, line_func=Line\\n        )\\n        line_label = axes.get_graph_label(\\n            cos_graph, \"x=2\\\\pi\", x_val=TAU, direction=UR, color=WHITE\\n        )\\n\\n        plot = VGroup(axes, sin_graph, cos_graph, vert_line)\\n        labels = VGroup(axes_labels, sin_label, cos_label, line_label)\\n        self.add(plot, labels)\\n')\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2541, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2539 with self.builtin_trap:\n   2540     args = (magic_arg_s, cell)\n-&gt; 2541     result = fn(*args, **kwargs)\n   2543 # The code below prevents the output from being displayed\n   2544 # when using magics with decorator @output_can_be_silenced\n   2545 # when the last Python token in the expression is a ';'.\n   2546 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/ipython_magic.py:143, in ManimMagic.manim(self, line, cell, local_ns)\n    141     SceneClass = local_ns[config[\"scene_names\"][0]]\n    142     scene = SceneClass(renderer=renderer)\n--&gt; 143     scene.render()\n    144 finally:\n    145     # Shader cache becomes invalid as the context is destroyed\n    146     shader_program_cache.clear()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/scene/scene.py:229, in Scene.render(self, preview)\n    227 self.setup()\n    228 try:\n--&gt; 229     self.construct()\n    230 except EndSceneEarlyException:\n    231     pass\n\nFile &lt;string&gt;:4, in construct(self)\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/graphing/coordinate_systems.py:1896, in Axes.__init__(self, x_range, y_range, x_length, y_length, axis_config, x_axis_config, y_axis_config, tips, **kwargs)\n   1893 else:\n   1894     self.y_axis_config[\"exclude_origin_tick\"] = False\n-&gt; 1896 self.x_axis = self._create_axis(self.x_range, self.x_axis_config, self.x_length)\n   1897 self.y_axis = self._create_axis(self.y_range, self.y_axis_config, self.y_length)\n   1899 # Add as a separate group in case various other\n   1900 # mobjects are added to self, as for example in\n   1901 # NumberPlane below\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/graphing/coordinate_systems.py:1971, in Axes._create_axis(self, range_terms, axis_config, length)\n   1954 \"\"\"Creates an axis and dynamically adjusts its position depending on where 0 is located on the line.\n   1955 \n   1956 Parameters\n   (...)\n   1968     Returns a number line based on ``range_terms``.\n   1969 \"\"\"\n   1970 axis_config[\"length\"] = length\n-&gt; 1971 axis = NumberLine(range_terms, **axis_config)\n   1973 # without the call to _origin_shift, graph does not exist when min &gt; 0 or max &lt; 0\n   1974 # shifts the axis so that 0 is centered\n   1975 axis.shift(-axis.number_to_point(self._origin_shift([axis.x_min, axis.x_max])))\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/graphing/number_line.py:261, in NumberLine.__init__(self, x_range, length, unit_size, include_ticks, tick_size, numbers_with_elongated_ticks, longer_tick_multiple, exclude_origin_tick, rotation, stroke_width, include_tip, tip_width, tip_height, tip_shape, include_numbers, font_size, label_direction, label_constructor, scaling, line_to_number_buff, decimal_number_config, numbers_to_exclude, numbers_to_include, **kwargs)\n    246     self.add_labels(\n    247         dict(\n    248             zip(\n   (...)\n    257         ),\n    258     )\n    260 else:\n--&gt; 261     self.add_numbers(\n    262         x_values=self.numbers_to_include,\n    263         excluding=self.numbers_to_exclude,\n    264         font_size=self.font_size,\n    265     )\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/graphing/number_line.py:533, in NumberLine.add_numbers(self, x_values, excluding, font_size, label_constructor, **kwargs)\n    530     if x in excluding:\n    531         continue\n    532     numbers.add(\n--&gt; 533         self.get_number_mobject(\n    534             x,\n    535             font_size=font_size,\n    536             label_constructor=label_constructor,\n    537             **kwargs,\n    538         )\n    539     )\n    540 self.add(numbers)\n    541 self.numbers = numbers\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/graphing/number_line.py:471, in NumberLine.get_number_mobject(self, x, direction, buff, font_size, label_constructor, **number_config)\n    468 if label_constructor is None:\n    469     label_constructor = self.label_constructor\n--&gt; 471 num_mob = DecimalNumber(\n    472     x, font_size=font_size, mob_class=label_constructor, **number_config\n    473 )\n    475 num_mob.next_to(self.number_to_point(x), direction=direction, buff=buff)\n    476 if x &lt; 0 and self.label_direction[0] == 0:\n    477     # Align without the minus sign\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/numbers.py:135, in DecimalNumber.__init__(self, number, num_decimal_places, mob_class, include_sign, group_with_commas, digit_buff_per_font_unit, show_ellipsis, unit, unit_buff_per_font_unit, include_background_rectangle, edge_to_fix, font_size, stroke_width, fill_opacity, **kwargs)\n    117 self.initial_config = kwargs.copy()\n    118 self.initial_config.update(\n    119     {\n    120         \"num_decimal_places\": num_decimal_places,\n   (...)\n    132     },\n    133 )\n--&gt; 135 self._set_submobjects_from_number(number)\n    136 self.init_colors()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/numbers.py:160, in DecimalNumber._set_submobjects_from_number(self, number)\n    157 self.submobjects = []\n    159 num_string = self._get_num_string(number)\n--&gt; 160 self.add(*(map(self._string_to_mob, num_string)))\n    162 # Add non-numerical bits\n    163 if self.show_ellipsis:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/numbers.py:225, in DecimalNumber._string_to_mob(self, string, mob_class, **kwargs)\n    222     mob_class = self.mob_class\n    224 if string not in string_to_mob_map:\n--&gt; 225     string_to_mob_map[string] = mob_class(string, **kwargs)\n    226 mob = string_to_mob_map[string].copy()\n    227 mob.font_size = self._font_size\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:293, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    280     if self.brace_notation_split_occurred:\n    281         logger.error(\n    282             dedent(\n    283                 \"\"\"\\\n   (...)\n    291             ),\n    292         )\n--&gt; 293     raise compilation_error\n    294 self.set_color_by_tex_to_color_map(self.tex_to_color_map)\n    296 if self.organize_left_to_right:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:272, in MathTex.__init__(self, arg_separator, substrings_to_isolate, tex_to_color_map, tex_environment, *tex_strings, **kwargs)\n    270 self.tex_strings = self._break_up_tex_strings(tex_strings)\n    271 try:\n--&gt; 272     super().__init__(\n    273         self.arg_separator.join(self.tex_strings),\n    274         tex_environment=self.tex_environment,\n    275         tex_template=self.tex_template,\n    276         **kwargs,\n    277     )\n    278     self._break_up_by_substrings()\n    279 except ValueError as compilation_error:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/mobject/text/tex_mobject.py:81, in SingleStringMathTex.__init__(self, tex_string, stroke_width, should_center, height, organize_left_to_right, tex_environment, tex_template, font_size, **kwargs)\n     79 assert isinstance(tex_string, str)\n     80 self.tex_string = tex_string\n---&gt; 81 file_name = tex_to_svg_file(\n     82     self._get_modified_expression(tex_string),\n     83     environment=self.tex_environment,\n     84     tex_template=self.tex_template,\n     85 )\n     86 super().__init__(\n     87     file_name=file_name,\n     88     should_center=should_center,\n   (...)\n     95     **kwargs,\n     96 )\n     97 self.init_colors()\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:63, in tex_to_svg_file(expression, environment, tex_template)\n     60 if svg_file.exists():\n     61     return svg_file\n---&gt; 63 dvi_file = compile_tex(\n     64     tex_file,\n     65     tex_template.tex_compiler,\n     66     tex_template.output_format,\n     67 )\n     68 svg_file = convert_to_svg(dvi_file, tex_template.output_format)\n     69 if not config[\"no_latex_cleanup\"]:\n\nFile ~/mambaforge/envs/pfast/lib/python3.12/site-packages/manim/utils/tex_file_writing.py:213, in compile_tex(tex_file, tex_compiler, output_format)\n    211         log_file = tex_file.with_suffix(\".log\")\n    212         print_all_tex_errors(log_file, tex_compiler, tex_file)\n--&gt; 213         raise ValueError(\n    214             f\"{tex_compiler} error converting to\"\n    215             f\" {output_format[1:]}. See log output above or\"\n    216             f\" the log file: {log_file}\",\n    217         )\n    218 return result\n\nValueError: latex error converting to dvi. See log output above or the log file: media/Tex/ba96de15f98acfc8.log\n\n\n\n\nclass FollowingGraphCamera(MovingCameraScene):\n    def construct(self):\n        self.camera.frame.save_state()\n\n        # create the axes and the curve\n        ax = Axes(x_range=[-1, 10], y_range=[-1, 10])\n        graph = ax.plot(lambda x: np.sin(x), color=BLUE, x_range=[0, 3 * PI])\n\n        # create dots based on the graph\n        moving_dot = Dot(ax.i2gp(graph.t_min, graph), color=ORANGE)\n        dot_1 = Dot(ax.i2gp(graph.t_min, graph))\n        dot_2 = Dot(ax.i2gp(graph.t_max, graph))\n\n        self.add(ax, graph, dot_1, dot_2, moving_dot)\n        self.play(self.camera.frame.animate.scale(0.5).move_to(moving_dot))\n\n        def update_curve(mob):\n            mob.move_to(moving_dot.get_center())\n\n        self.camera.frame.add_updater(update_curve)\n        self.play(MoveAlongPath(moving_dot, graph, rate_func=linear))\n        self.camera.frame.remove_updater(update_curve)\n\n        self.play(Restore(self.camera.frame))\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.\n    \n\n\n\nclass ThreeDCameraRotation(ThreeDScene):\n    def construct(self):\n        axes = ThreeDAxes()\n        circle=Circle()\n        self.set_camera_orientation(phi=75 * DEGREES, theta=30 * DEGREES)\n        self.add(circle,axes)\n        self.begin_ambient_camera_rotation(rate=0.1)\n        self.wait()\n        self.stop_ambient_camera_rotation()\n        self.move_camera(phi=75 * DEGREES, theta=30 * DEGREES)\n        self.wait()\n\nManim Community v0.18.1\n\n\n\n\n                                                                                                                        \n\n\n\n      Your browser does not support the video element.",
    "crumbs": [
      "Blog",
      "Display",
      "Manim"
    ]
  },
  {
    "objectID": "0_pandas.html",
    "href": "0_pandas.html",
    "title": "Pandas",
    "section": "",
    "text": "import pandas as pd\n\n# Create an empty DataFrame\nempty_df = pd.DataFrame()",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#add-column",
    "href": "0_pandas.html#add-column",
    "title": "Pandas",
    "section": "",
    "text": "import pandas as pd\n\n# Create an empty DataFrame\nempty_df = pd.DataFrame()",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#edit-column-name",
    "href": "0_pandas.html#edit-column-name",
    "title": "Pandas",
    "section": "Edit Column name",
    "text": "Edit Column name\ndf_plot.rename(columns={'y': 'final'}, inplace=True)",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#drop-column",
    "href": "0_pandas.html#drop-column",
    "title": "Pandas",
    "section": "Drop Column",
    "text": "Drop Column\ncv_df.drop('cutoff', axis=1, inplace=True)",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#plots",
    "href": "0_pandas.html#plots",
    "title": "Pandas",
    "section": "Plots",
    "text": "Plots\n(\n    wide_df[['y']].plot(title='Production')\n)",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#long-form-to-wide-form",
    "href": "0_pandas.html#long-form-to-wide-form",
    "title": "Pandas",
    "section": "Long form to Wide form",
    "text": "Long form to Wide form\ndef long_form(df_plot):\n    return df_plot.melt('ds', var_name='unique_id', value_name='y')",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#wide-form-to-long-form",
    "href": "0_pandas.html#wide-form-to-long-form",
    "title": "Pandas",
    "section": "Wide form to long form",
    "text": "Wide form to long form\n#|eval: false\nwide_df = result.pivot(index='_time', columns='sensor', values='_value')\n# Reset the index to make 'id' a regular column\nwide_df.reset_index(inplace=True)\n\nwide_df.columns",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#aggregate",
    "href": "0_pandas.html#aggregate",
    "title": "Pandas",
    "section": "Aggregate",
    "text": "Aggregate\n\nto do",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#stats",
    "href": "0_pandas.html#stats",
    "title": "Pandas",
    "section": "Stats",
    "text": "Stats\n\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Load the dataset\nflights = (sns.load_dataset(\"flights\"))\nflights\n\n\n\n\n\n\n\n\nyear\nmonth\npassengers\n\n\n\n\n0\n1949\nJan\n112\n\n\n1\n1949\nFeb\n118\n\n\n2\n1949\nMar\n132\n\n\n3\n1949\nApr\n129\n\n\n4\n1949\nMay\n121\n\n\n...\n...\n...\n...\n\n\n139\n1960\nAug\n606\n\n\n140\n1960\nSep\n508\n\n\n141\n1960\nOct\n461\n\n\n142\n1960\nNov\n390\n\n\n143\n1960\nDec\n432\n\n\n\n\n144 rows × 3 columns\n\n\n\n\nflights.head(), flights.tail()\n\n(   year month  passengers\n 0  1949   Jan         112\n 1  1949   Feb         118\n 2  1949   Mar         132\n 3  1949   Apr         129\n 4  1949   May         121,\n      year month  passengers\n 139  1960   Aug         606\n 140  1960   Sep         508\n 141  1960   Oct         461\n 142  1960   Nov         390\n 143  1960   Dec         432)\n\n\n\nflights.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 144 entries, 0 to 143\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   year        144 non-null    int64   \n 1   month       144 non-null    category\n 2   passengers  144 non-null    int64   \ndtypes: category(1), int64(2)\nmemory usage: 2.9 KB\n\n\n\nflights.describe()\n\n\n\n\n\n\n\n\nyear\npassengers\n\n\n\n\ncount\n144.000000\n144.000000\n\n\nmean\n1954.500000\n280.298611\n\n\nstd\n3.464102\n119.966317\n\n\nmin\n1949.000000\n104.000000\n\n\n25%\n1951.750000\n180.000000\n\n\n50%\n1954.500000\n265.500000\n\n\n75%\n1957.250000\n360.500000\n\n\nmax\n1960.000000\n622.000000\n\n\n\n\n\n\n\n\nflights.describe(include = \"category\")\n\n\n\n\n\n\n\n\nmonth\n\n\n\n\ncount\n144\n\n\nunique\n12\n\n\ntop\nJan\n\n\nfreq\n12\n\n\n\n\n\n\n\n\nflights.year.head(), flights['year'].head(), flights[['year', 'passengers']].head()\n\n(0    1949\n 1    1949\n 2    1949\n 3    1949\n 4    1949\n Name: year, dtype: int64,\n 0    1949\n 1    1949\n 2    1949\n 3    1949\n 4    1949\n Name: year, dtype: int64,\n    year  passengers\n 0  1949         112\n 1  1949         118\n 2  1949         132\n 3  1949         129\n 4  1949         121)\n\n\n\nflights.iloc[1]\n\nyear          1949\nmonth          Feb\npassengers     118\nName: 1, dtype: object\n\n\n\nflights.loc[1, 'year']\n\n1949\n\n\n\n# Convert month names to datetime format with the given year\nflights['date'] = flights.apply(lambda row: pd.to_datetime(f\"{row['year']}-{row['month']}-01\"), axis=1)\nflights.set_index('date', inplace=True)\n\n# Drop redundant columns and rename the passengers column for clarity\nflights.drop(['year', 'month'], axis=1, inplace=True)\nflights.rename(columns={'passengers': 'Passengers'}, inplace=True)\n\n# Plot the data\nflights.plot(title=\"Monthly Air Passengers\", figsize=(12,6))\nplt.show()\n\n\n\n\n\n\n\n\n\ndf = flights\ndf.head()\n\n\n\n\n\n\n\n\nPassengers\n\n\ndate\n\n\n\n\n\n1949-01-01\n112\n\n\n1949-02-01\n118\n\n\n1949-03-01\n132\n\n\n1949-04-01\n129\n\n\n1949-05-01\n121\n\n\n\n\n\n\n\n\ndf.columns\n\nIndex(['Passengers'], dtype='object')\n\n\n\ndf.index\n\nDatetimeIndex(['1949-01-01', '1949-02-01', '1949-03-01', '1949-04-01',\n               '1949-05-01', '1949-06-01', '1949-07-01', '1949-08-01',\n               '1949-09-01', '1949-10-01',\n               ...\n               '1960-03-01', '1960-04-01', '1960-05-01', '1960-06-01',\n               '1960-07-01', '1960-08-01', '1960-09-01', '1960-10-01',\n               '1960-11-01', '1960-12-01'],\n              dtype='datetime64[ns]', name='date', length=144, freq=None)\n\n\n\ndf[\"1960-08-01\":\"1960-12-01\"]\n\n\n\n\n\n\n\n\nPassengers\n\n\ndate\n\n\n\n\n\n1960-08-01\n606\n\n\n1960-09-01\n508\n\n\n1960-10-01\n461\n\n\n1960-11-01\n390\n\n\n1960-12-01\n432\n\n\n\n\n\n\n\n\ndf.Passengers.resample('Y').mean()\n\ndate\n1949-12-31    126.666667\n1950-12-31    139.666667\n1951-12-31    170.166667\n1952-12-31    197.000000\n1953-12-31    225.000000\n1954-12-31    238.916667\n1955-12-31    284.000000\n1956-12-31    328.250000\n1957-12-31    368.416667\n1958-12-31    381.000000\n1959-12-31    428.333333\n1960-12-31    476.166667\nFreq: A-DEC, Name: Passengers, dtype: float64\n\n\n\ndf.Passengers.resample('Y').mean().plot()\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\"Data/aapl_no_dates.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n0\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n1\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n3\n153.90\n155.81\n153.78\n154.45\n26624926\n\n\n4\n155.02\n155.98\n154.48\n155.37\n21069647",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#business-days",
    "href": "0_pandas.html#business-days",
    "title": "Pandas",
    "section": "Business Days",
    "text": "Business Days\n\nrng = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='B')\nrng\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-06',\n               '2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-20', '2016-06-21', '2016-06-22',\n               '2016-06-23', '2016-06-24', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\ndf.set_index(rng, inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-01\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n2016-06-02\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2016-06-03\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-06\n153.90\n155.81\n153.78\n154.45\n26624926\n\n\n2016-06-07\n155.02\n155.98\n154.48\n155.37\n21069647\n\n\n\n\n\n\n\n\ndaily_index = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='D')\ndaily_index\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-04',\n               '2016-06-05', '2016-06-06', '2016-06-07', '2016-06-08',\n               '2016-06-09', '2016-06-10', '2016-06-11', '2016-06-12',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-18', '2016-06-19', '2016-06-20',\n               '2016-06-21', '2016-06-22', '2016-06-23', '2016-06-24',\n               '2016-06-25', '2016-06-26', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='D')\n\n\n\ndaily_index.difference(df.index)\n\nDatetimeIndex(['2016-06-04', '2016-06-05', '2016-06-11', '2016-06-12',\n               '2016-06-18', '2016-06-19', '2016-06-25', '2016-06-26'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\nBenefits of having DatetimeIndex\n\ndf.Close.plot()\n\n\n\n\n\n\n\n\n\ndf[\"2016-06-01\":\"2016-06-10\"].Close.mean()\n\n152.72125\n\n\n\ndf.index\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-06',\n               '2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-20', '2016-06-21', '2016-06-22',\n               '2016-06-23', '2016-06-24', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\ndf.asfreq('D',method='pad').head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-01\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n2016-06-02\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2016-06-03\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-04\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-05\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n\n\n\n\n\n\ndf.asfreq('W',method='pad')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-05\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-12\n145.74\n146.09\n142.51\n145.42\n72307330\n\n\n2016-06-19\n143.66\n146.74\n143.66\n146.34\n32541404\n\n\n2016-06-26\n147.17\n148.28\n145.38\n145.82\n25692361\n\n\n\n\n\n\n\n\n\nGenerating DatetimeIndex with periods argument\n\nrng = pd.date_range('1/1/2011', periods=72, freq='H')\nrng\n\nDatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 01:00:00',\n               '2011-01-01 02:00:00', '2011-01-01 03:00:00',\n               '2011-01-01 04:00:00', '2011-01-01 05:00:00',\n               '2011-01-01 06:00:00', '2011-01-01 07:00:00',\n               '2011-01-01 08:00:00', '2011-01-01 09:00:00',\n               '2011-01-01 10:00:00', '2011-01-01 11:00:00',\n               '2011-01-01 12:00:00', '2011-01-01 13:00:00',\n               '2011-01-01 14:00:00', '2011-01-01 15:00:00',\n               '2011-01-01 16:00:00', '2011-01-01 17:00:00',\n               '2011-01-01 18:00:00', '2011-01-01 19:00:00',\n               '2011-01-01 20:00:00', '2011-01-01 21:00:00',\n               '2011-01-01 22:00:00', '2011-01-01 23:00:00',\n               '2011-01-02 00:00:00', '2011-01-02 01:00:00',\n               '2011-01-02 02:00:00', '2011-01-02 03:00:00',\n               '2011-01-02 04:00:00', '2011-01-02 05:00:00',\n               '2011-01-02 06:00:00', '2011-01-02 07:00:00',\n               '2011-01-02 08:00:00', '2011-01-02 09:00:00',\n               '2011-01-02 10:00:00', '2011-01-02 11:00:00',\n               '2011-01-02 12:00:00', '2011-01-02 13:00:00',\n               '2011-01-02 14:00:00', '2011-01-02 15:00:00',\n               '2011-01-02 16:00:00', '2011-01-02 17:00:00',\n               '2011-01-02 18:00:00', '2011-01-02 19:00:00',\n               '2011-01-02 20:00:00', '2011-01-02 21:00:00',\n               '2011-01-02 22:00:00', '2011-01-02 23:00:00',\n               '2011-01-03 00:00:00', '2011-01-03 01:00:00',\n               '2011-01-03 02:00:00', '2011-01-03 03:00:00',\n               '2011-01-03 04:00:00', '2011-01-03 05:00:00',\n               '2011-01-03 06:00:00', '2011-01-03 07:00:00',\n               '2011-01-03 08:00:00', '2011-01-03 09:00:00',\n               '2011-01-03 10:00:00', '2011-01-03 11:00:00',\n               '2011-01-03 12:00:00', '2011-01-03 13:00:00',\n               '2011-01-03 14:00:00', '2011-01-03 15:00:00',\n               '2011-01-03 16:00:00', '2011-01-03 17:00:00',\n               '2011-01-03 18:00:00', '2011-01-03 19:00:00',\n               '2011-01-03 20:00:00', '2011-01-03 21:00:00',\n               '2011-01-03 22:00:00', '2011-01-03 23:00:00'],\n              dtype='datetime64[ns]', freq='H')\n\n\n\nimport numpy as np\nts = pd.Series(np.random.randint(0,10,len(rng)), index=rng)\nts.head(20)\n\n2011-01-01 00:00:00    4\n2011-01-01 01:00:00    4\n2011-01-01 02:00:00    1\n2011-01-01 03:00:00    8\n2011-01-01 04:00:00    0\n2011-01-01 05:00:00    5\n2011-01-01 06:00:00    7\n2011-01-01 07:00:00    6\n2011-01-01 08:00:00    9\n2011-01-01 09:00:00    4\n2011-01-01 10:00:00    3\n2011-01-01 11:00:00    6\n2011-01-01 12:00:00    5\n2011-01-01 13:00:00    8\n2011-01-01 14:00:00    1\n2011-01-01 15:00:00    8\n2011-01-01 16:00:00    8\n2011-01-01 17:00:00    2\n2011-01-01 18:00:00    0\n2011-01-01 19:00:00    0\nFreq: H, dtype: int64\n\n\n\n\nHolidays\n\nrng = pd.date_range(start=\"7/1/2017\", end=\"7/21/2017\", freq='B')\nrng\n\nDatetimeIndex(['2017-07-03', '2017-07-04', '2017-07-05', '2017-07-06',\n               '2017-07-07', '2017-07-10', '2017-07-11', '2017-07-12',\n               '2017-07-13', '2017-07-14', '2017-07-17', '2017-07-18',\n               '2017-07-19', '2017-07-20', '2017-07-21'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\n\nUsing CustomBusinessDay to generate US holidays calendar frequency\n\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\nfrom pandas.tseries.offsets import CustomBusinessDay\n\nus_cal = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n\nrng = pd.date_range(start=\"7/1/2017\",end=\"7/23/2017\", freq=us_cal)\nrng\n\nDatetimeIndex(['2017-07-03', '2017-07-05', '2017-07-06', '2017-07-07',\n               '2017-07-10', '2017-07-11', '2017-07-12', '2017-07-13',\n               '2017-07-14', '2017-07-17', '2017-07-18', '2017-07-19',\n               '2017-07-20', '2017-07-21'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nAbstractHolidayCalendar\n\nfrom pandas.tseries.holiday import AbstractHolidayCalendar, nearest_workday, Holiday\nclass myCalendar(AbstractHolidayCalendar):\n    rules = [\n        Holiday('My Birth Day', month=4, day=15, observance=nearest_workday),\n    ]\n    \nmy_bday = CustomBusinessDay(calendar=myCalendar())\npd.date_range('4/1/2017','4/30/2017',freq=my_bday)\n\nDatetimeIndex(['2017-04-03', '2017-04-04', '2017-04-05', '2017-04-06',\n               '2017-04-07', '2017-04-10', '2017-04-11', '2017-04-12',\n               '2017-04-13', '2017-04-17', '2017-04-18', '2017-04-19',\n               '2017-04-20', '2017-04-21', '2017-04-24', '2017-04-25',\n               '2017-04-26', '2017-04-27', '2017-04-28'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nCustomBusinessDay\n\negypt_weekdays = \"Sun Mon Tue Wed Thu\"\n\nb = CustomBusinessDay(weekmask=egypt_weekdays)\n\npd.date_range(start=\"7/1/2017\",periods=20,freq=b)\n\nDatetimeIndex(['2017-07-02', '2017-07-03', '2017-07-04', '2017-07-05',\n               '2017-07-06', '2017-07-09', '2017-07-10', '2017-07-11',\n               '2017-07-12', '2017-07-13', '2017-07-16', '2017-07-17',\n               '2017-07-18', '2017-07-19', '2017-07-20', '2017-07-23',\n               '2017-07-24', '2017-07-25', '2017-07-26', '2017-07-27'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\nb = CustomBusinessDay(holidays=['2017-07-04', '2017-07-10'], weekmask=egypt_weekdays)\n\npd.date_range(start=\"7/1/2017\",periods=20,freq=b)\n\nDatetimeIndex(['2017-07-02', '2017-07-03', '2017-07-05', '2017-07-06',\n               '2017-07-09', '2017-07-11', '2017-07-12', '2017-07-13',\n               '2017-07-16', '2017-07-17', '2017-07-18', '2017-07-19',\n               '2017-07-20', '2017-07-23', '2017-07-24', '2017-07-25',\n               '2017-07-26', '2017-07-27', '2017-07-30', '2017-07-31'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nMaths\n\nfrom datetime import datetime\ndt = datetime(2017,7,9)\ndt\n\ndatetime.datetime(2017, 7, 9, 0, 0)\n\n\n\ndt + 1*b\n\nTimestamp('2017-07-11 00:00:00')",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#to-datatime",
    "href": "0_pandas.html#to-datatime",
    "title": "Pandas",
    "section": "To datatime",
    "text": "To datatime\n\nimport pandas as pd\ndates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05','20170105']\npd.to_datetime(dates)\n\nDatetimeIndex(['2017-01-05', '2017-01-05', '2017-01-05', '2017-01-05',\n               '2017-01-05', '2017-01-05'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\ndt = ['2017-01-05 2:30:00 PM', 'Jan 5, 2017 14:30:00', '01/05/2016', '2017.01.05', '2017/01/05','20170105']\npd.to_datetime(dt)\n\nDatetimeIndex(['2017-01-05 14:30:00', '2017-01-05 14:30:00',\n               '2016-01-05 00:00:00', '2017-01-05 00:00:00',\n               '2017-01-05 00:00:00', '2017-01-05 00:00:00'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\nEuropean style dates with day first\n\npd.to_datetime('30-12-2016', dayfirst=True)\n\nTimestamp('2016-12-30 00:00:00')\n\n\n\npd.to_datetime('5-1-2016', dayfirst=True)\n\nTimestamp('2016-01-05 00:00:00')\n\n\n\n\nCustom date time format\n\npd.to_datetime('2017$01$05', format='%Y$%m$%d')\n\nTimestamp('2017-01-05 00:00:00')\n\n\n\npd.to_datetime('2017#01#05', format='%Y#%m#%d')\n\nTimestamp('2017-01-05 00:00:00')\n\n\n\n\nHandling invalid dates\n\npd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='ignore')\n\nIndex(['2017-01-05', 'Jan 6, 2017', 'abc'], dtype='object')\n\n\n\npd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='coerce')\n\nDatetimeIndex(['2017-01-05', '2017-01-06', 'NaT'], dtype='datetime64[ns]', freq=None)",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#epoch",
    "href": "0_pandas.html#epoch",
    "title": "Pandas",
    "section": "Epoch",
    "text": "Epoch\n\ncurrent_epoch = 1501324478\npd.to_datetime(current_epoch, unit='s')\n\nTimestamp('2017-07-29 10:34:38')\n\n\n\npd.to_datetime(current_epoch*1000, unit='ms')\n\nTimestamp('2017-07-29 10:34:38')\n\n\n\nt = pd.to_datetime([current_epoch], unit='s')\nt\n\nDatetimeIndex(['2017-07-29 10:34:38'], dtype='datetime64[ns]', freq=None)\n\n\n\nt.view('int64')\n\narray([1501324478000000000])\n\n\n\nYearly Period\n\nimport pandas as pd\ny = pd.Period('2016')\ny\n\nPeriod('2016', 'A-DEC')\n\n\n\ny.start_time\n\nTimestamp('2016-01-01 00:00:00')\n\n\n\ny.end_time\n\nTimestamp('2016-12-31 23:59:59.999999999')\n\n\n\ny.is_leap_year\n\nTrue\n\n\n\n\nMonthly Period\n\nm = pd.Period('2017-12')\nm\n\nPeriod('2017-12', 'M')\n\n\n\nm.start_time\n\nTimestamp('2017-12-01 00:00:00')\n\n\n\nm.end_time\n\nTimestamp('2017-12-31 23:59:59.999999999')\n\n\n\nm+1\n\nPeriod('2018-01', 'M')\n\n\n\n\nDaily Period\n\nd = pd.Period('2016-02-28', freq='D')\nd\n\nPeriod('2016-02-28', 'D')\n\n\n\nd.start_time\n\nTimestamp('2016-02-28 00:00:00')\n\n\n\nd.end_time\n\nTimestamp('2016-02-28 23:59:59.999999999')\n\n\n\nd+1\n\nPeriod('2016-02-29', 'D')\n\n\n\n\nHourly Period\n\nh = pd.Period('2017-08-15 23:00:00',freq='H')\nh\n\nPeriod('2017-08-15 23:00', 'H')\n\n\n\nh+1\n\nPeriod('2017-08-16 00:00', 'H')\n\n\n\nh+pd.offsets.Hour(1)\n\nPeriod('2017-08-16 00:00', 'H')\n\n\n\n\nQuarterly Period\n\nq1= pd.Period('2017Q1', freq='Q-JAN')\nq1\n\nPeriod('2017Q1', 'Q-JAN')\n\n\n\nq1.start_time\n\nTimestamp('2016-02-01 00:00:00')\n\n\n\nq1.end_time\n\nTimestamp('2016-04-30 23:59:59.999999999')\n\n\n\nq1.asfreq('M',how='start')\n\nPeriod('2016-02', 'M')\n\n\n\nq1.asfreq('M',how='end')\n\nPeriod('2016-04', 'M')\n\n\n\n\nWeekly Period\n\nw = pd.Period('2017-07-05',freq='W')\nw\n\nPeriod('2017-07-03/2017-07-09', 'W-SUN')\n\n\n\nw-1\n\nPeriod('2017-06-26/2017-07-02', 'W-SUN')\n\n\n\nw2 = pd.Period('2017-08-15',freq='W')\nw2\n\nPeriod('2017-08-14/2017-08-20', 'W-SUN')\n\n\n\nw2-w\n\n&lt;6 * Weeks: weekday=6&gt;\n\n\n\n\nPeriodIndex and period_range\n\nr = pd.period_range('2011', '2017', freq='q')\nr\n\nPeriodIndex(['2011Q1', '2011Q2', '2011Q3', '2011Q4', '2012Q1', '2012Q2',\n             '2012Q3', '2012Q4', '2013Q1', '2013Q2', '2013Q3', '2013Q4',\n             '2014Q1', '2014Q2', '2014Q3', '2014Q4', '2015Q1', '2015Q2',\n             '2015Q3', '2015Q4', '2016Q1', '2016Q2', '2016Q3', '2016Q4',\n             '2017Q1'],\n            dtype='period[Q-DEC]')\n\n\n\nr[0].start_time\n\nTimestamp('2011-01-01 00:00:00')\n\n\n\nr[0].end_time\n\nTimestamp('2011-03-31 23:59:59.999999999')\n\n\n\nidx = pd.period_range('2011', '2017', freq='q-jan')\nidx\n\nPeriodIndex(['2011Q4', '2012Q1', '2012Q2', '2012Q3', '2012Q4', '2013Q1',\n             '2013Q2', '2013Q3', '2013Q4', '2014Q1', '2014Q2', '2014Q3',\n             '2014Q4', '2015Q1', '2015Q2', '2015Q3', '2015Q4', '2016Q1',\n             '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2', '2017Q3',\n             '2017Q4'],\n            dtype='period[Q-JAN]')\n\n\n\nr[0].start_time\n\nTimestamp('2011-01-01 00:00:00')\n\n\n\nr[0].end_time\n\nTimestamp('2011-03-31 23:59:59.999999999')\n\n\n\nr = pd.period_range(start='2016-01', periods=10, freq='M')\nr\n\nPeriodIndex(['2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06',\n             '2016-07', '2016-08', '2016-09', '2016-10'],\n            dtype='period[M]')\n\n\n\nimport numpy as np\nps = pd.Series(np.random.randn(len(idx)), idx)\nps\n\n2011Q4   -0.412550\n2012Q1    0.701174\n2012Q2    0.385101\n2012Q3    0.989325\n2012Q4   -0.858848\n2013Q1   -0.137989\n2013Q2    0.410097\n2013Q3    1.391899\n2013Q4    1.414134\n2014Q1   -0.144215\n2014Q2   -0.305327\n2014Q3    0.025925\n2014Q4    0.269103\n2015Q1    1.953641\n2015Q2    1.455620\n2015Q3    0.403967\n2015Q4    1.119294\n2016Q1    0.650177\n2016Q2    1.216127\n2016Q3   -0.784484\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\nps['2016']\n\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\nps['2016':'2017']\n\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\npst = ps.to_timestamp()\npst\n\n2010-11-01   -0.412550\n2011-02-01    0.701174\n2011-05-01    0.385101\n2011-08-01    0.989325\n2011-11-01   -0.858848\n2012-02-01   -0.137989\n2012-05-01    0.410097\n2012-08-01    1.391899\n2012-11-01    1.414134\n2013-02-01   -0.144215\n2013-05-01   -0.305327\n2013-08-01    0.025925\n2013-11-01    0.269103\n2014-02-01    1.953641\n2014-05-01    1.455620\n2014-08-01    0.403967\n2014-11-01    1.119294\n2015-02-01    0.650177\n2015-05-01    1.216127\n2015-08-01   -0.784484\n2015-11-01   -2.146994\n2016-02-01    0.410092\n2016-05-01    1.031284\n2016-08-01    0.681366\n2016-11-01   -1.082856\nFreq: QS-NOV, dtype: float64\n\n\n\npst.index\n\nDatetimeIndex(['2010-11-01', '2011-02-01', '2011-05-01', '2011-08-01',\n               '2011-11-01', '2012-02-01', '2012-05-01', '2012-08-01',\n               '2012-11-01', '2013-02-01', '2013-05-01', '2013-08-01',\n               '2013-11-01', '2014-02-01', '2014-05-01', '2014-08-01',\n               '2014-11-01', '2015-02-01', '2015-05-01', '2015-08-01',\n               '2015-11-01', '2016-02-01', '2016-05-01', '2016-08-01',\n               '2016-11-01'],\n              dtype='datetime64[ns]', freq='QS-NOV')\n\n\n\nps = pst.to_period()\nps\n\n2010Q4   -0.412550\n2011Q1    0.701174\n2011Q2    0.385101\n2011Q3    0.989325\n2011Q4   -0.858848\n2012Q1   -0.137989\n2012Q2    0.410097\n2012Q3    1.391899\n2012Q4    1.414134\n2013Q1   -0.144215\n2013Q2   -0.305327\n2013Q3    0.025925\n2013Q4    0.269103\n2014Q1    1.953641\n2014Q2    1.455620\n2014Q3    0.403967\n2014Q4    1.119294\n2015Q1    0.650177\n2015Q2    1.216127\n2015Q3   -0.784484\n2015Q4   -2.146994\n2016Q1    0.410092\n2016Q2    1.031284\n2016Q3    0.681366\n2016Q4   -1.082856\nFreq: Q-DEC, dtype: float64\n\n\n\nps.index\n\nPeriodIndex(['2010Q4', '2011Q1', '2011Q2', '2011Q3', '2011Q4', '2012Q1',\n             '2012Q2', '2012Q3', '2012Q4', '2013Q1', '2013Q2', '2013Q3',\n             '2013Q4', '2014Q1', '2014Q2', '2014Q3', '2014Q4', '2015Q1',\n             '2015Q2', '2015Q3', '2015Q4', '2016Q1', '2016Q2', '2016Q3',\n             '2016Q4'],\n            dtype='period[Q-DEC]')",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#processing-wal-marts-financials",
    "href": "0_pandas.html#processing-wal-marts-financials",
    "title": "Pandas",
    "section": "Processing Wal Mart’s Financials",
    "text": "Processing Wal Mart’s Financials\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/wmt.csv\")\ndf\n\n\n\n\n\n\n\n\nLine Item\n2017Q1\n2017Q2\n2017Q3\n2017Q4\n2018Q1\n\n\n\n\n0\nRevenue\n115904\n120854\n118179\n130936\n117542\n\n\n1\nExpenses\n86544\n89485\n87484\n97743\n87688\n\n\n2\nProfit\n29360\n31369\n30695\n33193\n29854\n\n\n\n\n\n\n\n\ndf.set_index(\"Line Item\",inplace=True)\ndf = df.T\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\n\n\n\n\n2017Q1\n115904\n86544\n29360\n\n\n2017Q2\n120854\n89485\n31369\n\n\n2017Q3\n118179\n87484\n30695\n\n\n2017Q4\n130936\n97743\n33193\n\n\n2018Q1\n117542\n87688\n29854\n\n\n\n\n\n\n\n\ndf.index\n\nIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1'], dtype='object')\n\n\n\ndf.index = pd.PeriodIndex(df.index, freq=\"Q-JAN\")\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\n\n\n\n\n2017Q1\n115904\n86544\n29360\n\n\n2017Q2\n120854\n89485\n31369\n\n\n2017Q3\n118179\n87484\n30695\n\n\n2017Q4\n130936\n97743\n33193\n\n\n2018Q1\n117542\n87688\n29854\n\n\n\n\n\n\n\n\ndf.index\n\nPeriodIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1'], dtype='period[Q-JAN]')\n\n\n\ndf.index[0].start_time\n\nTimestamp('2016-02-01 00:00:00')\n\n\n\nAdd start date end date columns to dataframe\n\ndf[\"Start Date\"]=df.index.map(lambda x: x.start_time)\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\nStart Date\n\n\n\n\n2017Q1\n115904\n86544\n29360\n2016-02-01\n\n\n2017Q2\n120854\n89485\n31369\n2016-05-01\n\n\n2017Q3\n118179\n87484\n30695\n2016-08-01\n\n\n2017Q4\n130936\n97743\n33193\n2016-11-01\n\n\n2018Q1\n117542\n87688\n29854\n2017-02-01\n\n\n\n\n\n\n\n\ndf[\"End Date\"]=df.index.map(lambda x: x.end_time)\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\nStart Date\nEnd Date\n\n\n\n\n2017Q1\n115904\n86544\n29360\n2016-02-01\n2016-04-30 23:59:59.999999999\n\n\n2017Q2\n120854\n89485\n31369\n2016-05-01\n2016-07-31 23:59:59.999999999\n\n\n2017Q3\n118179\n87484\n30695\n2016-08-01\n2016-10-31 23:59:59.999999999\n\n\n2017Q4\n130936\n97743\n33193\n2016-11-01\n2017-01-31 23:59:59.999999999\n\n\n2018Q1\n117542\n87688\n29854\n2017-02-01\n2017-04-30 23:59:59.999999999",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#timezone-handling",
    "href": "0_pandas.html#timezone-handling",
    "title": "Pandas",
    "section": "Timezone Handling",
    "text": "Timezone Handling\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/msft.csv\", header=1,index_col='Date Time',parse_dates=True)\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 09:00:00\n72.38\n\n\n2017-08-17 09:15:00\n71.00\n\n\n2017-08-17 09:30:00\n71.67\n\n\n2017-08-17 10:00:00\n72.80\n\n\n2017-08-17 10:30:00\n73.00\n\n\n2017-08-17 11:00:00\n72.50\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-17 09:00:00', '2017-08-17 09:15:00',\n               '2017-08-17 09:30:00', '2017-08-17 10:00:00',\n               '2017-08-17 10:30:00', '2017-08-17 11:00:00'],\n              dtype='datetime64[ns]', name='Date Time', freq=None)\n\n\n\ndf.tz_localize(tz='US/Eastern')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 09:00:00\n72.38\n\n\n2017-08-17 09:15:00\n71.00\n\n\n2017-08-17 09:30:00\n71.67\n\n\n2017-08-17 10:00:00\n72.80\n\n\n2017-08-17 10:30:00\n73.00\n\n\n2017-08-17 11:00:00\n72.50\n\n\n\n\n\n\n\n\ndf.index = df.index.tz_localize(tz='US/Eastern')\ndf.index\n\nDatetimeIndex(['2017-08-17 09:00:00-04:00', '2017-08-17 09:15:00-04:00',\n               '2017-08-17 09:30:00-04:00', '2017-08-17 10:00:00-04:00',\n               '2017-08-17 10:30:00-04:00', '2017-08-17 11:00:00-04:00'],\n              dtype='datetime64[ns, US/Eastern]', name='Date Time', freq=None)\n\n\n\nConvert to Berlin time using tz_convert\n\ndf = df.tz_convert('Europe/Berlin')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 15:00:00+02:00\n72.38\n\n\n2017-08-17 15:15:00+02:00\n71.00\n\n\n2017-08-17 15:30:00+02:00\n71.67\n\n\n2017-08-17 16:00:00+02:00\n72.80\n\n\n2017-08-17 16:30:00+02:00\n73.00\n\n\n2017-08-17 17:00:00+02:00\n72.50\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-17 15:00:00+02:00', '2017-08-17 15:15:00+02:00',\n               '2017-08-17 15:30:00+02:00', '2017-08-17 16:00:00+02:00',\n               '2017-08-17 16:30:00+02:00', '2017-08-17 17:00:00+02:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='Date Time', freq=None)\n\n\n\nfrom pytz import all_timezones\nprint (all_timezones)\n\n['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Asmera', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Africa/Douala', 'Africa/El_Aaiun', 'Africa/Freetown', 'Africa/Gaborone', 'Africa/Harare', 'Africa/Johannesburg', 'Africa/Juba', 'Africa/Kampala', 'Africa/Khartoum', 'Africa/Kigali', 'Africa/Kinshasa', 'Africa/Lagos', 'Africa/Libreville', 'Africa/Lome', 'Africa/Luanda', 'Africa/Lubumbashi', 'Africa/Lusaka', 'Africa/Malabo', 'Africa/Maputo', 'Africa/Maseru', 'Africa/Mbabane', 'Africa/Mogadishu', 'Africa/Monrovia', 'Africa/Nairobi', 'Africa/Ndjamena', 'Africa/Niamey', 'Africa/Nouakchott', 'Africa/Ouagadougou', 'Africa/Porto-Novo', 'Africa/Sao_Tome', 'Africa/Timbuktu', 'Africa/Tripoli', 'Africa/Tunis', 'Africa/Windhoek', 'America/Adak', 'America/Anchorage', 'America/Anguilla', 'America/Antigua', 'America/Araguaina', 'America/Argentina/Buenos_Aires', 'America/Argentina/Catamarca', 'America/Argentina/ComodRivadavia', 'America/Argentina/Cordoba', 'America/Argentina/Jujuy', 'America/Argentina/La_Rioja', 'America/Argentina/Mendoza', 'America/Argentina/Rio_Gallegos', 'America/Argentina/Salta', 'America/Argentina/San_Juan', 'America/Argentina/San_Luis', 'America/Argentina/Tucuman', 'America/Argentina/Ushuaia', 'America/Aruba', 'America/Asuncion', 'America/Atikokan', 'America/Atka', 'America/Bahia', 'America/Bahia_Banderas', 'America/Barbados', 'America/Belem', 'America/Belize', 'America/Blanc-Sablon', 'America/Boa_Vista', 'America/Bogota', 'America/Boise', 'America/Buenos_Aires', 'America/Cambridge_Bay', 'America/Campo_Grande', 'America/Cancun', 'America/Caracas', 'America/Catamarca', 'America/Cayenne', 'America/Cayman', 'America/Chicago', 'America/Chihuahua', 'America/Ciudad_Juarez', 'America/Coral_Harbour', 'America/Cordoba', 'America/Costa_Rica', 'America/Creston', 'America/Cuiaba', 'America/Curacao', 'America/Danmarkshavn', 'America/Dawson', 'America/Dawson_Creek', 'America/Denver', 'America/Detroit', 'America/Dominica', 'America/Edmonton', 'America/Eirunepe', 'America/El_Salvador', 'America/Ensenada', 'America/Fort_Nelson', 'America/Fort_Wayne', 'America/Fortaleza', 'America/Glace_Bay', 'America/Godthab', 'America/Goose_Bay', 'America/Grand_Turk', 'America/Grenada', 'America/Guadeloupe', 'America/Guatemala', 'America/Guayaquil', 'America/Guyana', 'America/Halifax', 'America/Havana', 'America/Hermosillo', 'America/Indiana/Indianapolis', 'America/Indiana/Knox', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Tell_City', 'America/Indiana/Vevay', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Indianapolis', 'America/Inuvik', 'America/Iqaluit', 'America/Jamaica', 'America/Jujuy', 'America/Juneau', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Knox_IN', 'America/Kralendijk', 'America/La_Paz', 'America/Lima', 'America/Los_Angeles', 'America/Louisville', 'America/Lower_Princes', 'America/Maceio', 'America/Managua', 'America/Manaus', 'America/Marigot', 'America/Martinique', 'America/Matamoros', 'America/Mazatlan', 'America/Mendoza', 'America/Menominee', 'America/Merida', 'America/Metlakatla', 'America/Mexico_City', 'America/Miquelon', 'America/Moncton', 'America/Monterrey', 'America/Montevideo', 'America/Montreal', 'America/Montserrat', 'America/Nassau', 'America/New_York', 'America/Nipigon', 'America/Nome', 'America/Noronha', 'America/North_Dakota/Beulah', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/Nuuk', 'America/Ojinaga', 'America/Panama', 'America/Pangnirtung', 'America/Paramaribo', 'America/Phoenix', 'America/Port-au-Prince', 'America/Port_of_Spain', 'America/Porto_Acre', 'America/Porto_Velho', 'America/Puerto_Rico', 'America/Punta_Arenas', 'America/Rainy_River', 'America/Rankin_Inlet', 'America/Recife', 'America/Regina', 'America/Resolute', 'America/Rio_Branco', 'America/Rosario', 'America/Santa_Isabel', 'America/Santarem', 'America/Santiago', 'America/Santo_Domingo', 'America/Sao_Paulo', 'America/Scoresbysund', 'America/Shiprock', 'America/Sitka', 'America/St_Barthelemy', 'America/St_Johns', 'America/St_Kitts', 'America/St_Lucia', 'America/St_Thomas', 'America/St_Vincent', 'America/Swift_Current', 'America/Tegucigalpa', 'America/Thule', 'America/Thunder_Bay', 'America/Tijuana', 'America/Toronto', 'America/Tortola', 'America/Vancouver', 'America/Virgin', 'America/Whitehorse', 'America/Winnipeg', 'America/Yakutat', 'America/Yellowknife', 'Antarctica/Casey', 'Antarctica/Davis', 'Antarctica/DumontDUrville', 'Antarctica/Macquarie', 'Antarctica/Mawson', 'Antarctica/McMurdo', 'Antarctica/Palmer', 'Antarctica/Rothera', 'Antarctica/South_Pole', 'Antarctica/Syowa', 'Antarctica/Troll', 'Antarctica/Vostok', 'Arctic/Longyearbyen', 'Asia/Aden', 'Asia/Almaty', 'Asia/Amman', 'Asia/Anadyr', 'Asia/Aqtau', 'Asia/Aqtobe', 'Asia/Ashgabat', 'Asia/Ashkhabad', 'Asia/Atyrau', 'Asia/Baghdad', 'Asia/Bahrain', 'Asia/Baku', 'Asia/Bangkok', 'Asia/Barnaul', 'Asia/Beirut', 'Asia/Bishkek', 'Asia/Brunei', 'Asia/Calcutta', 'Asia/Chita', 'Asia/Choibalsan', 'Asia/Chongqing', 'Asia/Chungking', 'Asia/Colombo', 'Asia/Dacca', 'Asia/Damascus', 'Asia/Dhaka', 'Asia/Dili', 'Asia/Dubai', 'Asia/Dushanbe', 'Asia/Famagusta', 'Asia/Gaza', 'Asia/Harbin', 'Asia/Hebron', 'Asia/Ho_Chi_Minh', 'Asia/Hong_Kong', 'Asia/Hovd', 'Asia/Irkutsk', 'Asia/Istanbul', 'Asia/Jakarta', 'Asia/Jayapura', 'Asia/Jerusalem', 'Asia/Kabul', 'Asia/Kamchatka', 'Asia/Karachi', 'Asia/Kashgar', 'Asia/Kathmandu', 'Asia/Katmandu', 'Asia/Khandyga', 'Asia/Kolkata', 'Asia/Krasnoyarsk', 'Asia/Kuala_Lumpur', 'Asia/Kuching', 'Asia/Kuwait', 'Asia/Macao', 'Asia/Macau', 'Asia/Magadan', 'Asia/Makassar', 'Asia/Manila', 'Asia/Muscat', 'Asia/Nicosia', 'Asia/Novokuznetsk', 'Asia/Novosibirsk', 'Asia/Omsk', 'Asia/Oral', 'Asia/Phnom_Penh', 'Asia/Pontianak', 'Asia/Pyongyang', 'Asia/Qatar', 'Asia/Qostanay', 'Asia/Qyzylorda', 'Asia/Rangoon', 'Asia/Riyadh', 'Asia/Saigon', 'Asia/Sakhalin', 'Asia/Samarkand', 'Asia/Seoul', 'Asia/Shanghai', 'Asia/Singapore', 'Asia/Srednekolymsk', 'Asia/Taipei', 'Asia/Tashkent', 'Asia/Tbilisi', 'Asia/Tehran', 'Asia/Tel_Aviv', 'Asia/Thimbu', 'Asia/Thimphu', 'Asia/Tokyo', 'Asia/Tomsk', 'Asia/Ujung_Pandang', 'Asia/Ulaanbaatar', 'Asia/Ulan_Bator', 'Asia/Urumqi', 'Asia/Ust-Nera', 'Asia/Vientiane', 'Asia/Vladivostok', 'Asia/Yakutsk', 'Asia/Yangon', 'Asia/Yekaterinburg', 'Asia/Yerevan', 'Atlantic/Azores', 'Atlantic/Bermuda', 'Atlantic/Canary', 'Atlantic/Cape_Verde', 'Atlantic/Faeroe', 'Atlantic/Faroe', 'Atlantic/Jan_Mayen', 'Atlantic/Madeira', 'Atlantic/Reykjavik', 'Atlantic/South_Georgia', 'Atlantic/St_Helena', 'Atlantic/Stanley', 'Australia/ACT', 'Australia/Adelaide', 'Australia/Brisbane', 'Australia/Broken_Hill', 'Australia/Canberra', 'Australia/Currie', 'Australia/Darwin', 'Australia/Eucla', 'Australia/Hobart', 'Australia/LHI', 'Australia/Lindeman', 'Australia/Lord_Howe', 'Australia/Melbourne', 'Australia/NSW', 'Australia/North', 'Australia/Perth', 'Australia/Queensland', 'Australia/South', 'Australia/Sydney', 'Australia/Tasmania', 'Australia/Victoria', 'Australia/West', 'Australia/Yancowinna', 'Brazil/Acre', 'Brazil/DeNoronha', 'Brazil/East', 'Brazil/West', 'CET', 'CST6CDT', 'Canada/Atlantic', 'Canada/Central', 'Canada/Eastern', 'Canada/Mountain', 'Canada/Newfoundland', 'Canada/Pacific', 'Canada/Saskatchewan', 'Canada/Yukon', 'Chile/Continental', 'Chile/EasterIsland', 'Cuba', 'EET', 'EST', 'EST5EDT', 'Egypt', 'Eire', 'Etc/GMT', 'Etc/GMT+0', 'Etc/GMT+1', 'Etc/GMT+10', 'Etc/GMT+11', 'Etc/GMT+12', 'Etc/GMT+2', 'Etc/GMT+3', 'Etc/GMT+4', 'Etc/GMT+5', 'Etc/GMT+6', 'Etc/GMT+7', 'Etc/GMT+8', 'Etc/GMT+9', 'Etc/GMT-0', 'Etc/GMT-1', 'Etc/GMT-10', 'Etc/GMT-11', 'Etc/GMT-12', 'Etc/GMT-13', 'Etc/GMT-14', 'Etc/GMT-2', 'Etc/GMT-3', 'Etc/GMT-4', 'Etc/GMT-5', 'Etc/GMT-6', 'Etc/GMT-7', 'Etc/GMT-8', 'Etc/GMT-9', 'Etc/GMT0', 'Etc/Greenwich', 'Etc/UCT', 'Etc/UTC', 'Etc/Universal', 'Etc/Zulu', 'Europe/Amsterdam', 'Europe/Andorra', 'Europe/Astrakhan', 'Europe/Athens', 'Europe/Belfast', 'Europe/Belgrade', 'Europe/Berlin', 'Europe/Bratislava', 'Europe/Brussels', 'Europe/Bucharest', 'Europe/Budapest', 'Europe/Busingen', 'Europe/Chisinau', 'Europe/Copenhagen', 'Europe/Dublin', 'Europe/Gibraltar', 'Europe/Guernsey', 'Europe/Helsinki', 'Europe/Isle_of_Man', 'Europe/Istanbul', 'Europe/Jersey', 'Europe/Kaliningrad', 'Europe/Kiev', 'Europe/Kirov', 'Europe/Kyiv', 'Europe/Lisbon', 'Europe/Ljubljana', 'Europe/London', 'Europe/Luxembourg', 'Europe/Madrid', 'Europe/Malta', 'Europe/Mariehamn', 'Europe/Minsk', 'Europe/Monaco', 'Europe/Moscow', 'Europe/Nicosia', 'Europe/Oslo', 'Europe/Paris', 'Europe/Podgorica', 'Europe/Prague', 'Europe/Riga', 'Europe/Rome', 'Europe/Samara', 'Europe/San_Marino', 'Europe/Sarajevo', 'Europe/Saratov', 'Europe/Simferopol', 'Europe/Skopje', 'Europe/Sofia', 'Europe/Stockholm', 'Europe/Tallinn', 'Europe/Tirane', 'Europe/Tiraspol', 'Europe/Ulyanovsk', 'Europe/Uzhgorod', 'Europe/Vaduz', 'Europe/Vatican', 'Europe/Vienna', 'Europe/Vilnius', 'Europe/Volgograd', 'Europe/Warsaw', 'Europe/Zagreb', 'Europe/Zaporozhye', 'Europe/Zurich', 'GB', 'GB-Eire', 'GMT', 'GMT+0', 'GMT-0', 'GMT0', 'Greenwich', 'HST', 'Hongkong', 'Iceland', 'Indian/Antananarivo', 'Indian/Chagos', 'Indian/Christmas', 'Indian/Cocos', 'Indian/Comoro', 'Indian/Kerguelen', 'Indian/Mahe', 'Indian/Maldives', 'Indian/Mauritius', 'Indian/Mayotte', 'Indian/Reunion', 'Iran', 'Israel', 'Jamaica', 'Japan', 'Kwajalein', 'Libya', 'MET', 'MST', 'MST7MDT', 'Mexico/BajaNorte', 'Mexico/BajaSur', 'Mexico/General', 'NZ', 'NZ-CHAT', 'Navajo', 'PRC', 'PST8PDT', 'Pacific/Apia', 'Pacific/Auckland', 'Pacific/Bougainville', 'Pacific/Chatham', 'Pacific/Chuuk', 'Pacific/Easter', 'Pacific/Efate', 'Pacific/Enderbury', 'Pacific/Fakaofo', 'Pacific/Fiji', 'Pacific/Funafuti', 'Pacific/Galapagos', 'Pacific/Gambier', 'Pacific/Guadalcanal', 'Pacific/Guam', 'Pacific/Honolulu', 'Pacific/Johnston', 'Pacific/Kanton', 'Pacific/Kiritimati', 'Pacific/Kosrae', 'Pacific/Kwajalein', 'Pacific/Majuro', 'Pacific/Marquesas', 'Pacific/Midway', 'Pacific/Nauru', 'Pacific/Niue', 'Pacific/Norfolk', 'Pacific/Noumea', 'Pacific/Pago_Pago', 'Pacific/Palau', 'Pacific/Pitcairn', 'Pacific/Pohnpei', 'Pacific/Ponape', 'Pacific/Port_Moresby', 'Pacific/Rarotonga', 'Pacific/Saipan', 'Pacific/Samoa', 'Pacific/Tahiti', 'Pacific/Tarawa', 'Pacific/Tongatapu', 'Pacific/Truk', 'Pacific/Wake', 'Pacific/Wallis', 'Pacific/Yap', 'Poland', 'Portugal', 'ROC', 'ROK', 'Singapore', 'Turkey', 'UCT', 'US/Alaska', 'US/Aleutian', 'US/Arizona', 'US/Central', 'US/East-Indiana', 'US/Eastern', 'US/Hawaii', 'US/Indiana-Starke', 'US/Michigan', 'US/Mountain', 'US/Pacific', 'US/Samoa', 'UTC', 'Universal', 'W-SU', 'WET', 'Zulu']\n\n\n\n\nConvert to Mumbai time\n\ndf.index = df.index.tz_convert('Asia/Calcutta') # tz database doesn't have any Mumbai timezone but calcutta and mumbai are both in same timezone so we will use that\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 18:30:00+05:30\n72.38\n\n\n2017-08-17 18:45:00+05:30\n71.00\n\n\n2017-08-17 19:00:00+05:30\n71.67\n\n\n2017-08-17 19:30:00+05:30\n72.80\n\n\n2017-08-17 20:00:00+05:30\n73.00\n\n\n2017-08-17 20:30:00+05:30\n72.50\n\n\n\n\n\n\n\n\n\nUsing timezones in date_range\n\n(1) timezone using pytz\n\nlondon = pd.date_range('3/6/2012 00:09:00', periods=10, freq='H',tz='Europe/London')\nlondon\n\nDatetimeIndex(['2012-03-06 00:09:00+00:00', '2012-03-06 01:09:00+00:00',\n               '2012-03-06 02:09:00+00:00', '2012-03-06 03:09:00+00:00',\n               '2012-03-06 04:09:00+00:00', '2012-03-06 05:09:00+00:00',\n               '2012-03-06 06:09:00+00:00', '2012-03-06 07:09:00+00:00',\n               '2012-03-06 08:09:00+00:00', '2012-03-06 09:09:00+00:00'],\n              dtype='datetime64[ns, Europe/London]', freq='H')\n\n\n\n\n(2) timezone using dateutil\n\ntd = pd.date_range('3/6/2012 00:00', periods=10, freq='H',tz='dateutil/Europe/London')\ntd\n\nDatetimeIndex(['2012-03-06 00:00:00+00:00', '2012-03-06 01:00:00+00:00',\n               '2012-03-06 02:00:00+00:00', '2012-03-06 03:00:00+00:00',\n               '2012-03-06 04:00:00+00:00', '2012-03-06 05:00:00+00:00',\n               '2012-03-06 06:00:00+00:00', '2012-03-06 07:00:00+00:00',\n               '2012-03-06 08:00:00+00:00', '2012-03-06 09:00:00+00:00'],\n              dtype='datetime64[ns, tzfile('/usr/share/zoneinfo/Europe/London')]', freq='H')\n\n\n\n\n\nAirthmetic between different timezones\n\nrng = pd.date_range(start=\"2017-08-22 09:00:00\",periods=10, freq='30min')\ns = pd.Series(range(10),index=rng)\ns\n\n2017-08-22 09:00:00    0\n2017-08-22 09:30:00    1\n2017-08-22 10:00:00    2\n2017-08-22 10:30:00    3\n2017-08-22 11:00:00    4\n2017-08-22 11:30:00    5\n2017-08-22 12:00:00    6\n2017-08-22 12:30:00    7\n2017-08-22 13:00:00    8\n2017-08-22 13:30:00    9\nFreq: 30T, dtype: int64\n\n\n\nb = s.tz_localize(tz=\"Europe/Berlin\")\nb\n\n2017-08-22 09:00:00+02:00    0\n2017-08-22 09:30:00+02:00    1\n2017-08-22 10:00:00+02:00    2\n2017-08-22 10:30:00+02:00    3\n2017-08-22 11:00:00+02:00    4\n2017-08-22 11:30:00+02:00    5\n2017-08-22 12:00:00+02:00    6\n2017-08-22 12:30:00+02:00    7\n2017-08-22 13:00:00+02:00    8\n2017-08-22 13:30:00+02:00    9\ndtype: int64\n\n\n\nb.index\n\nDatetimeIndex(['2017-08-22 09:00:00+02:00', '2017-08-22 09:30:00+02:00',\n               '2017-08-22 10:00:00+02:00', '2017-08-22 10:30:00+02:00',\n               '2017-08-22 11:00:00+02:00', '2017-08-22 11:30:00+02:00',\n               '2017-08-22 12:00:00+02:00', '2017-08-22 12:30:00+02:00',\n               '2017-08-22 13:00:00+02:00', '2017-08-22 13:30:00+02:00'],\n              dtype='datetime64[ns, Europe/Berlin]', freq=None)\n\n\n\nm = s.tz_localize(tz=\"Asia/Calcutta\")\nm.index\n\nDatetimeIndex(['2017-08-22 09:00:00+05:30', '2017-08-22 09:30:00+05:30',\n               '2017-08-22 10:00:00+05:30', '2017-08-22 10:30:00+05:30',\n               '2017-08-22 11:00:00+05:30', '2017-08-22 11:30:00+05:30',\n               '2017-08-22 12:00:00+05:30', '2017-08-22 12:30:00+05:30',\n               '2017-08-22 13:00:00+05:30', '2017-08-22 13:30:00+05:30'],\n              dtype='datetime64[ns, Asia/Calcutta]', freq=None)\n\n\n\nm\n\n2017-08-22 09:00:00+05:30    0\n2017-08-22 09:30:00+05:30    1\n2017-08-22 10:00:00+05:30    2\n2017-08-22 10:30:00+05:30    3\n2017-08-22 11:00:00+05:30    4\n2017-08-22 11:30:00+05:30    5\n2017-08-22 12:00:00+05:30    6\n2017-08-22 12:30:00+05:30    7\n2017-08-22 13:00:00+05:30    8\n2017-08-22 13:30:00+05:30    9\ndtype: int64\n\n\n\nb + m\n\n2017-08-22 03:30:00+00:00     NaN\n2017-08-22 04:00:00+00:00     NaN\n2017-08-22 04:30:00+00:00     NaN\n2017-08-22 05:00:00+00:00     NaN\n2017-08-22 05:30:00+00:00     NaN\n2017-08-22 06:00:00+00:00     NaN\n2017-08-22 06:30:00+00:00     NaN\n2017-08-22 07:00:00+00:00     7.0\n2017-08-22 07:30:00+00:00     9.0\n2017-08-22 08:00:00+00:00    11.0\n2017-08-22 08:30:00+00:00     NaN\n2017-08-22 09:00:00+00:00     NaN\n2017-08-22 09:30:00+00:00     NaN\n2017-08-22 10:00:00+00:00     NaN\n2017-08-22 10:30:00+00:00     NaN\n2017-08-22 11:00:00+00:00     NaN\n2017-08-22 11:30:00+00:00     NaN\ndtype: float64",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "0_pandas.html#shifting-and-lagging",
    "href": "0_pandas.html#shifting-and-lagging",
    "title": "Pandas",
    "section": "Shifting and Lagging",
    "text": "Shifting and Lagging\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/fb.csv\",parse_dates=['Date'],index_col='Date')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ndf.shift(1)\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\nNaN\n\n\n2017-08-16\n171.00\n\n\n2017-08-17\n170.00\n\n\n2017-08-18\n166.91\n\n\n2017-08-21\n167.41\n\n\n2017-08-22\n167.78\n\n\n2017-08-23\n169.64\n\n\n2017-08-24\n168.71\n\n\n2017-08-25\n167.74\n\n\n2017-08-28\n166.32\n\n\n\n\n\n\n\n\ndf.shift(-1)\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n170.00\n\n\n2017-08-16\n166.91\n\n\n2017-08-17\n167.41\n\n\n2017-08-18\n167.78\n\n\n2017-08-21\n169.64\n\n\n2017-08-22\n168.71\n\n\n2017-08-23\n167.74\n\n\n2017-08-24\n166.32\n\n\n2017-08-25\n167.24\n\n\n2017-08-28\nNaN\n\n\n\n\n\n\n\n\ndf['Prev Day Price'] = df['Price'].shift(1)\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\n\n\nDate\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\n\n\n2017-08-16\n170.00\n171.00\n\n\n2017-08-17\n166.91\n170.00\n\n\n2017-08-18\n167.41\n166.91\n\n\n2017-08-21\n167.78\n167.41\n\n\n2017-08-22\n169.64\n167.78\n\n\n2017-08-23\n168.71\n169.64\n\n\n2017-08-24\n167.74\n168.71\n\n\n2017-08-25\n166.32\n167.74\n\n\n2017-08-28\n167.24\n166.32\n\n\n\n\n\n\n\n\ndf['Price Change'] = df['Price'] - df['Prev Day Price']\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\nPrice Change\n\n\nDate\n\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\nNaN\n\n\n2017-08-16\n170.00\n171.00\n-1.00\n\n\n2017-08-17\n166.91\n170.00\n-3.09\n\n\n2017-08-18\n167.41\n166.91\n0.50\n\n\n2017-08-21\n167.78\n167.41\n0.37\n\n\n2017-08-22\n169.64\n167.78\n1.86\n\n\n2017-08-23\n168.71\n169.64\n-0.93\n\n\n2017-08-24\n167.74\n168.71\n-0.97\n\n\n2017-08-25\n166.32\n167.74\n-1.42\n\n\n2017-08-28\n167.24\n166.32\n0.92\n\n\n\n\n\n\n\n\ndf['5 day return'] =  (df['Price'] - df['Price'].shift(5))*100/df['Price'].shift(5)\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\nPrice Change\n5 day return\n\n\nDate\n\n\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\nNaN\nNaN\n\n\n2017-08-16\n170.00\n171.00\n-1.00\nNaN\n\n\n2017-08-17\n166.91\n170.00\n-3.09\nNaN\n\n\n2017-08-18\n167.41\n166.91\n0.50\nNaN\n\n\n2017-08-21\n167.78\n167.41\n0.37\nNaN\n\n\n2017-08-22\n169.64\n167.78\n1.86\n-0.795322\n\n\n2017-08-23\n168.71\n169.64\n-0.93\n-0.758824\n\n\n2017-08-24\n167.74\n168.71\n-0.97\n0.497274\n\n\n2017-08-25\n166.32\n167.74\n-1.42\n-0.651096\n\n\n2017-08-28\n167.24\n166.32\n0.92\n-0.321850\n\n\n\n\n\n\n\n\ndf = df[['Price']]\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ntshift\n\ndf.index\n\nDatetimeIndex(['2017-08-15', '2017-08-16', '2017-08-17', '2017-08-18',\n               '2017-08-21', '2017-08-22', '2017-08-23', '2017-08-24',\n               '2017-08-25', '2017-08-28'],\n              dtype='datetime64[ns]', name='Date', freq=None)\n\n\n\ndf.index = pd.date_range(start='2017-08-15',periods=10, freq='B')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-15', '2017-08-16', '2017-08-17', '2017-08-18',\n               '2017-08-21', '2017-08-22', '2017-08-23', '2017-08-24',\n               '2017-08-25', '2017-08-28'],\n              dtype='datetime64[ns]', freq='B')",
    "crumbs": [
      "Blog",
      "Pandas"
    ]
  },
  {
    "objectID": "Environments/direnv.html",
    "href": "Environments/direnv.html",
    "title": "Direnv",
    "section": "",
    "text": "sudo apt-get install direnv",
    "crumbs": [
      "Blog",
      "Environments",
      "Direnv"
    ]
  },
  {
    "objectID": "Environments/direnv.html#install",
    "href": "Environments/direnv.html#install",
    "title": "Direnv",
    "section": "",
    "text": "sudo apt-get install direnv",
    "crumbs": [
      "Blog",
      "Environments",
      "Direnv"
    ]
  },
  {
    "objectID": "Environments/direnv.html#configure-your-shell",
    "href": "Environments/direnv.html#configure-your-shell",
    "title": "Direnv",
    "section": "Configure Your Shell",
    "text": "Configure Your Shell\n\nAdd to bash\n\neval \"$(direnv hook bash)\"\n\nReload bash\n\nsource ~/.bashrc",
    "crumbs": [
      "Blog",
      "Environments",
      "Direnv"
    ]
  },
  {
    "objectID": "Environments/direnv.html#create-a-.envrc-file-in-your-project-directory",
    "href": "Environments/direnv.html#create-a-.envrc-file-in-your-project-directory",
    "title": "Direnv",
    "section": "Create a .envrc File in Your Project Directory",
    "text": "Create a .envrc File in Your Project Directory\n\nNavigate to your project directory and create a .envrc file:\n\ncd /path/to/your/project\necho 'export POETRY_ACTIVE=1' &gt; .envrc\necho 'source \"$(poetry env info --path)/bin/activate\"' &gt;&gt; .envrc\n\nExample .envrc File\n\n# .envrc - Environment configuration for the project\n\n# --- Check if the virtual environment exists ---\nif [ ! -d \".venv\" ]; then\n  echo \"❌ Virtual environment .venv does not exist. Creating...\"\n  uv .venv  # Or any other Python version you prefer\nelse\n  echo \"✔️ Using existing virtual environment.\"\nfi\n\n# --- Activate the virtual environment ---\nsource .venv/bin/activate\n\n# --- Set environment variables ---\nexport PROJECT_HOME=$(pwd)  # Set the project root directory path\n\n# --- Load environment variables from .env file ---\nif [ -f .env ]; then\n  echo \"✔️ Loading environment variables from .env...\"\n  export $(grep -v '^#' .env | xargs -d '\\n')  # This will load non-comment lines from .env file\nelse\n  echo \"⚠️ No .env file found. Skipping environment variable loading.\"\nfi\n\n# --- Custom commands or setup ---\necho \"✔️ Environment setup complete. You are now in the project environment.\"",
    "crumbs": [
      "Blog",
      "Environments",
      "Direnv"
    ]
  },
  {
    "objectID": "Environments/direnv.html#allow-the-.envrc-file",
    "href": "Environments/direnv.html#allow-the-.envrc-file",
    "title": "Direnv",
    "section": "Allow the .envrc File",
    "text": "Allow the .envrc File\ndirenv allow",
    "crumbs": [
      "Blog",
      "Environments",
      "Direnv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html",
    "href": "Environments/pipenv.html",
    "title": "Pipenv",
    "section": "",
    "text": "pip install pipenv",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#installation-of-pipenv",
    "href": "Environments/pipenv.html#installation-of-pipenv",
    "title": "Pipenv",
    "section": "",
    "text": "pip install pipenv",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#create-a-env",
    "href": "Environments/pipenv.html#create-a-env",
    "title": "Pipenv",
    "section": "Create a env",
    "text": "Create a env\npipenv install",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#create-a-env-1",
    "href": "Environments/pipenv.html#create-a-env-1",
    "title": "Pipenv",
    "section": "Create a env",
    "text": "Create a env\npipenv install django",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#remove-an-env",
    "href": "Environments/pipenv.html#remove-an-env",
    "title": "Pipenv",
    "section": "Remove an env",
    "text": "Remove an env\npipenv --rm",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#activate-already-created-pipenv-environment",
    "href": "Environments/pipenv.html#activate-already-created-pipenv-environment",
    "title": "Pipenv",
    "section": "Activate already created pipenv environment",
    "text": "Activate already created pipenv environment\npipenv shell",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#to-deactivate",
    "href": "Environments/pipenv.html#to-deactivate",
    "title": "Pipenv",
    "section": "To Deactivate",
    "text": "To Deactivate\ndeactivate",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/pipenv.html#installuninstall-dependencies",
    "href": "Environments/pipenv.html#installuninstall-dependencies",
    "title": "Pipenv",
    "section": "Install/Uninstall dependencies",
    "text": "Install/Uninstall dependencies\npipenv install django\npipenv uninstall django\n\nInstall dev dependencies\npipenv install nose --dev\n\n\nInstall from requirements.txt\npipenv install -r requirements.txt\n\n\nCheck security vulnerabilities\npipenv check\n\n\nCheck dependency graph\npipenv graph",
    "crumbs": [
      "Blog",
      "Environments",
      "Pipenv"
    ]
  },
  {
    "objectID": "Environments/venv.html",
    "href": "Environments/venv.html",
    "title": "Venv",
    "section": "",
    "text": "Standard Library: venv is part of the Python standard library, so it doesn’t require additional installation.\nLightweight: It provides a minimal and straightforward way to create isolated environments.\nNo Dependency Management: venv focuses solely on environment isolation. You still need to use pip to manage dependencies manually.",
    "crumbs": [
      "Blog",
      "Environments",
      "Venv"
    ]
  },
  {
    "objectID": "Environments/venv.html#create-a-virtual-enviroment",
    "href": "Environments/venv.html#create-a-virtual-enviroment",
    "title": "Venv",
    "section": "Create a Virtual Enviroment",
    "text": "Create a Virtual Enviroment\npython -m venv venv",
    "crumbs": [
      "Blog",
      "Environments",
      "Venv"
    ]
  },
  {
    "objectID": "Environments/venv.html#activate-the-virtual-environment",
    "href": "Environments/venv.html#activate-the-virtual-environment",
    "title": "Venv",
    "section": "Activate the Virtual Environment",
    "text": "Activate the Virtual Environment\nsource myenv/bin/activate",
    "crumbs": [
      "Blog",
      "Environments",
      "Venv"
    ]
  },
  {
    "objectID": "Environments/venv.html#deactivate-the-virtual-enviroment",
    "href": "Environments/venv.html#deactivate-the-virtual-enviroment",
    "title": "Venv",
    "section": "Deactivate the Virtual Enviroment",
    "text": "Deactivate the Virtual Enviroment\ndeactivate",
    "crumbs": [
      "Blog",
      "Environments",
      "Venv"
    ]
  },
  {
    "objectID": "kaggle.html",
    "href": "kaggle.html",
    "title": "Kaggle",
    "section": "",
    "text": "pip list | grep kaggle\n\nkaggle                    1.6.14\nNote: you may need to restart the kernel to use updated packages.\nimport kaggle",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "kaggle.html#list-datasets",
    "href": "kaggle.html#list-datasets",
    "title": "Kaggle",
    "section": "List Datasets",
    "text": "List Datasets\n\nimport kaggle\n\n# List datasets\ndatasets = kaggle.api.dataset_list()\nfor dataset in datasets:\n    print(dataset.ref)\n\nteocalvo/teomewhy-loyalty-system\nshreyanshverma27/online-sales-dataset-popular-marketplace-data\ndamirdizdarevic/uefa-euro-2024-players\nanuchhetry/product-sales\nrabieelkharoua/air-quality-and-health-impact-dataset\nmayankanand2701/tesla-stock-price-dataset\nrabieelkharoua/students-performance-dataset\ninformrohit1/smartphones-dataset\nmuhammadroshaanriaz/e-commerce-trends-a-guide-to-leveraging-dataset\nrashadrmammadov/heart-disease-prediction\nrabieelkharoua/cancer-prediction-dataset\ndarrylljk/worlds-best-universities-qs-rankings-2025\nrabieelkharoua/predict-liver-disease-1700-records-dataset\nprogrammerrdai/ai-computation-and-hardware-trends\nmonisamir/global-salary-analysis\nrabieelkharoua/diabetes-health-dataset-analysis\nmexwell/pizza-sales\nrashadrmammadov/lung-cancer-prediction\nmjdskaggle/2024-population-projections-by-country\nshreyaskeote23/india-population-data",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "kaggle.html#search-for-a-dataset",
    "href": "kaggle.html#search-for-a-dataset",
    "title": "Kaggle",
    "section": "Search for a Dataset",
    "text": "Search for a Dataset\n\n# Search for a specific dataset\ndatasets = kaggle.api.dataset_list(search='titanic')\nfor dataset in datasets:\n    print(dataset.ref)\n\nheptapod/titanic\nbrendan45774/test-file\nazeembootwala/titanic\nyasserh/titanic-dataset\nrahulsah06/titanic\nshubhamgupta012/titanic-dataset\nfossouodonald/titaniccsv\nprkukunoor/TitanicDataset\nhesh97/titanicdataset-traincsv\nibrahimelsayed182/titanic-dataset\npavlofesenko/titanic-extended\njamesleslie/titanic-cleaned-data\nbroaniki/titanic\nzain280/titanic-data-set\nsakshisatre/titanic-dataset\nkittisaks/testtitanic\nabhinavralhan/titanic\nvinicius150987/titanic3\nmahmoudshogaa/titanic-dataset\nashishkumarjayswal/titanic-datasets",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "kaggle.html#download-a-dataset",
    "href": "kaggle.html#download-a-dataset",
    "title": "Kaggle",
    "section": "Download a Dataset",
    "text": "Download a Dataset\n\n# Download the Titanic dataset\nkaggle.api.dataset_download_files('heptapod/titanic', path='Data/Dataset/titanic', unzip=True)\n\nDataset URL: https://www.kaggle.com/datasets/heptapod/titanic",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "kaggle.html#list-competitions",
    "href": "kaggle.html#list-competitions",
    "title": "Kaggle",
    "section": "List competitions",
    "text": "List competitions\n\ncompetitions = kaggle.api.competitions_list()\nfor competition in competitions:\n    print(competition.ref)\n\nhttps://www.kaggle.com/competitions/arc-prize-2024\nhttps://www.kaggle.com/competitions/ai-mathematical-olympiad-prize\nhttps://www.kaggle.com/competitions/lmsys-chatbot-arena\nhttps://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2\nhttps://www.kaggle.com/competitions/leash-BELKA\nhttps://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim\nhttps://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification\nhttps://www.kaggle.com/competitions/llm-20-questions\nhttps://www.kaggle.com/competitions/uspto-explainable-ai\nhttps://www.kaggle.com/competitions/playground-series-s4e6\nhttps://www.kaggle.com/competitions/titanic\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\nhttps://www.kaggle.com/competitions/spaceship-titanic\nhttps://www.kaggle.com/competitions/digit-recognizer\nhttps://www.kaggle.com/competitions/nlp-getting-started\nhttps://www.kaggle.com/competitions/store-sales-time-series-forecasting\nhttps://www.kaggle.com/competitions/connectx\nhttps://www.kaggle.com/competitions/gan-getting-started\nhttps://www.kaggle.com/competitions/tpu-getting-started\nhttps://www.kaggle.com/competitions/contradictory-my-dear-watson",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "kaggle.html#download-competition-data",
    "href": "kaggle.html#download-competition-data",
    "title": "Kaggle",
    "section": "Download competition data",
    "text": "Download competition data\n\nkaggle.api.competition_download_files('titanic', path='Data/Competition/titanic')\n\nTODO:\n\nTitanic\nDigit recognizer\nStore Sales\nCompetition\n\n\nfrom nbdevAuto import functions\n\n\nfunctions.kaggle_competition_download??\n\n\nSignature:\nfunctions.kaggle_competition_download(\n    name: str,\n    folderpath: str = './Data',\n)\nSource:   \ndef kaggle_competition_download(name:str, folderpath:str = './Data'):\n    'download competition files from kaggle'\n    import os\n    import shutil\n    from pathlib import Path\n    \n    iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n    if iskaggle: path = Path(f'../input/{name}')\n    else:\n        path = Path(f'{folderpath}/{name}')\n        if path.exists():print(\"file exists\")\n        else:\n            import zipfile,kaggle\n            kaggle.api.competition_download_cli(competition = name, path = path)\n            zipfile.ZipFile(f'{path}/{name}.zip').extractall(path)\nFile:      ~/miniconda3/envs/pfast/lib/python3.12/site-packages/nbdevAuto/functions.py\nType:      function\n\n\n\n\nfunctions.kaggle_dataset_download?\n\n\nSignature:\nfunctions.kaggle_dataset_download(\n    user: str,\n    name: str,\n    folderpath: str = './Data',\n)\nSource:   \ndef kaggle_dataset_download(user:str,\n                            name:str,\n                            folderpath:str = './Data'):\n    'download competition files from kaggle'\n    import os\n    import shutil\n    from pathlib import Path\n    iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n    if iskaggle: path = Path(f'../input/{name}')\n    else:\n        path = Path(f'{folderpath}/{name}')\n        if path.exists():print(\"file exists\")\n        else:\n            import zipfile,kaggle\n            kaggle.api.dataset_download_files(dataset = f'{user}/{name}', path = path)\n            zipfile.ZipFile(f'{path}/{name}.zip').extractall(path)\nFile:      ~/miniconda3/envs/pfast/lib/python3.12/site-packages/nbdevAuto/functions.py\nType:      function",
    "crumbs": [
      "Blog",
      "Kaggle"
    ]
  },
  {
    "objectID": "marimo.html",
    "href": "marimo.html",
    "title": "Marimo",
    "section": "",
    "text": "Marimo is an open‑source, reactive Python notebook system that reimagines how notebooks should operate:\n\nStored as pure .py files (not JSON .ipynb)\nReactive runtime: changes to code or UI trigger automatic updates to dependent cells\nDesigned for interactive data work with built-in UI widgets, SQL support, and AI tooling (marimo.io, cfp.scipy.org, docs.marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#what-is-marimo",
    "href": "marimo.html#what-is-marimo",
    "title": "Marimo",
    "section": "",
    "text": "Marimo is an open‑source, reactive Python notebook system that reimagines how notebooks should operate:\n\nStored as pure .py files (not JSON .ipynb)\nReactive runtime: changes to code or UI trigger automatic updates to dependent cells\nDesigned for interactive data work with built-in UI widgets, SQL support, and AI tooling (marimo.io, cfp.scipy.org, docs.marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#reaction-architecture",
    "href": "marimo.html#reaction-architecture",
    "title": "Marimo",
    "section": "⚡ Reaction Architecture",
    "text": "⚡ Reaction Architecture\n\nDependency-driven execution: When you run a cell or interact with a widget, Marimo runs downstream cells—or marks them stale if you’re in lazy mode (docs.marimo.io)\nNo hidden state: deleting a cell deletes its variables from memory (docs.marimo.io)\nExecution order is topologically sorted based on variable definitions and references, not cell order on the page (docs.marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#key-features",
    "href": "marimo.html#key-features",
    "title": "Marimo",
    "section": "🛠️ Key Features",
    "text": "🛠️ Key Features\n\n\n\nFeature\nDescription\n\n\n\n\nFile format\n.py (fully git-friendly, diffable, mergeable) (GitHub)\n\n\nInteractivity\nUse UI widgets like sliders, dropdowns, data tables—no callbacks needed (docs.marimo.io, GitHub)\n\n\nSQL-first\nNative SQL cells for querying DuckDB, Postgres, CSVs, dataframes, etc. (PyPI, GitHub)\n\n\nAI-native\nIntegrated AI assistant and optional GitHub Copilot support for code suggestions and LLM generation (marimo.io, docs.marimo.io)\n\n\nReproducibility\nBuilt-in sandboxing and package management; notebooks execute deterministically (Real Python, pretalx.northbaypython.org)\n\n\nDeployment\nServe read-only or interactive notebooks as web apps or export to HTML/WASM via CLI (docs.marimo.io, marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#getting-started-quickstart",
    "href": "marimo.html#getting-started-quickstart",
    "title": "Marimo",
    "section": "⚙️ Getting Started (Quickstart)",
    "text": "⚙️ Getting Started (Quickstart)\npip install marimo\nmarimo tutorial intro\nThen create a new notebook with:\nmarimo edit my_notebook.py\nThis launches an editor in your browser—cells are editable and reactive—no extra server needed (marimo.io, marimo.io).\nYou can also deploy it via:\n\nmarimo run notebook.py (serves as read-only app)\nExport to WASM or static HTML\nRun/test as a normal Python script (GitHub, docs.marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#example-snapshot",
    "href": "marimo.html#example-snapshot",
    "title": "Marimo",
    "section": "🧩 Example Snapshot",
    "text": "🧩 Example Snapshot\nimport marimo as mo\n\nslider = mo.ui.slider(label=\"x\", min=0, max=10, value=2)\nmo.display(mo.md(f\"Slider value: **{slider.value}**\"))\n\n@mo.react\ndef square():\n    return slider.value ** 2\n\nAdjust slider → square() runs automatically\nmo.md(...), mo.ui.slider(...) generate reactive widgets and output (docs.marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#who-uses-marimo",
    "href": "marimo.html#who-uses-marimo",
    "title": "Marimo",
    "section": "👥 Who Uses Marimo?",
    "text": "👥 Who Uses Marimo?\n\nData scientists, analysts, AI engineers\nEducators & students—used at places like Stanford—its interactivity suits teaching math, linear algebra, ML easily (marimo.io, marimo.io)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#marimo-vs.-jupyterlab-summary",
    "href": "marimo.html#marimo-vs.-jupyterlab-summary",
    "title": "Marimo",
    "section": "🔄 Marimo vs. JupyterLab Summary",
    "text": "🔄 Marimo vs. JupyterLab Summary\n\n\n\n\n\n\n\n\nAspect\nMarimo\nJupyterLab\n\n\n\n\nFormat\n.py – plain text, git‑friendly\n.ipynb – JSON, hard to diff\n\n\nExecution\nReactive DAG-based updates, no hidden state\nImperative: manual reruns often necessary\n\n\nWidgets/UI\nNative UI with no callbacks required\nUses ipywidgets with manual wiring\n\n\nDeployment\nCLI-based web apps, WASM exports, script execution\nRequires external tools (Voila, nbconvert, Streamlit)\n\n\nReproducibility\nDeterministic, sandboxed, version-controlled\nProne to hidden state bugs, dependency drift",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#advanced-use-deployment",
    "href": "marimo.html#advanced-use-deployment",
    "title": "Marimo",
    "section": "🚀 Advanced Use & Deployment",
    "text": "🚀 Advanced Use & Deployment\n\nGenerate AI-powered notebooks with marimo new \"task description\"—prompts can produce full notebooks using LLMs (PyPI, marimo.io, GitHub, docs.marimo.io, docs.marimo.io)\nUse molab—a free hosted cloud service to create, run, and share marimo notebooks like Google Colab, complete with RAM and package support (marimo.io)\nDeploy via Docker or behind ASGI servers for production or educational environments (GitHub)",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "marimo.html#final-takeaway",
    "href": "marimo.html#final-takeaway",
    "title": "Marimo",
    "section": "✅ Final Takeaway",
    "text": "✅ Final Takeaway\nMarimo is a modern alternative to JupyterLab, optimized for reproducibility, reactivity, version control, and deployability. It brings the best of notebooks, web apps, and scripting into one cohesive Python-native environment.\nWould you like:\n\nA side-by-side working example in Marimo?\nA notebook shared via molab to explore?\nTutorials for SQL workflows or AI-powered notebooks?\n\nI’m happy to get you started!",
    "crumbs": [
      "Blog",
      "Marimo"
    ]
  },
  {
    "objectID": "numexpr.html",
    "href": "numexpr.html",
    "title": "Numexpr",
    "section": "",
    "text": "NumExpr is a Python library for evaluating numerical expressions faster than pure Python or NumPy.\nIt compiles expressions into bytecode and evaluates them efficiently using vectorized operations and multi-threading.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#what-is-numexpr",
    "href": "numexpr.html#what-is-numexpr",
    "title": "Numexpr",
    "section": "",
    "text": "NumExpr is a Python library for evaluating numerical expressions faster than pure Python or NumPy.\nIt compiles expressions into bytecode and evaluates them efficiently using vectorized operations and multi-threading.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#key-features",
    "href": "numexpr.html#key-features",
    "title": "Numexpr",
    "section": "2. Key Features",
    "text": "2. Key Features\n\nFast Execution:\n\nEvaluates expressions more quickly than NumPy for large arrays by avoiding intermediate arrays.\n\nMultithreading:\n\nUses multiple CPU cores for faster computations.\n\nMemory Efficient:\n\nMinimizes memory usage by not creating temporary arrays for intermediate results.\n\nNumPy Integration:\n\nWorks seamlessly with NumPy arrays.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#installation",
    "href": "numexpr.html#installation",
    "title": "Numexpr",
    "section": "3. Installation",
    "text": "3. Installation\nTo install NumExpr, use pip:\npip install numexpr",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#basic-usage",
    "href": "numexpr.html#basic-usage",
    "title": "Numexpr",
    "section": "4. Basic Usage",
    "text": "4. Basic Usage\nTo evaluate a mathematical expression:\nimport numexpr as ne\n\n# Define a NumPy array\nimport numpy as np\na = np.arange(1e6)\n\n# Evaluate an expression\nresult = ne.evaluate(\"a ** 2 + 3 * a - 5\")\n\nne.evaluate() takes a string expression and evaluates it.\nIt supports standard mathematical operations (+, -, *, /, **) and functions (e.g., sin, cos, log).\n\n\nimport numexpr as ne\n\n# Define a NumPy array\nimport numpy as np\na = np.arange(1e6)\n\n# Evaluate an expression\nresult = ne.evaluate(\"a ** 2 + 3 * a - 5\")\na, result\n\n(array([0.00000e+00, 1.00000e+00, 2.00000e+00, ..., 9.99997e+05,\n        9.99998e+05, 9.99999e+05], shape=(1000000,)),\n array([-5.000000e+00, -1.000000e+00,  5.000000e+00, ...,  9.999970e+11,\n         9.999990e+11,  1.000001e+12], shape=(1000000,)))",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#supported-operations",
    "href": "numexpr.html#supported-operations",
    "title": "Numexpr",
    "section": "5. Supported Operations",
    "text": "5. Supported Operations\n\nA) Arithmetic Operators\n\n\n\nOperator\nDescription\n\n\n\n\n+\nAddition\n\n\n-\nSubtraction\n\n\n*\nMultiplication\n\n\n/\nDivision\n\n\n**\nPower\n\n\n%\nModulus\n\n\n\nExample:\nne.evaluate(\"2 * a + 3\")\n\n\nB) Relational and Logical Operators\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nLess than\n\n\n&gt;\nGreater than\n\n\n&lt;=\nLess than or equal\n\n\n&gt;=\nGreater than or equal\n\n\n==\nEqual\n\n\n!=\nNot equal\n\n\n&\nLogical AND\n\n\n|\nLogical OR\n\n\n\nExample:\nne.evaluate(\"(a &gt; 0.5) & (a &lt; 0.8)\")\n\n\nC) Mathematical Functions\n\n\n\nFunction\nDescription\n\n\n\n\nsin, cos, tan\nTrigonometric functions\n\n\narcsin, arccos, arctan\nInverse trigonometric functions\n\n\nlog, log10, exp\nLogarithm and exponential functions\n\n\nsqrt\nSquare root\n\n\nabs\nAbsolute value\n\n\nwhere\nConditional function\n\n\n\nExample:\nne.evaluate(\"sqrt(a) + log(a)\")",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#multithreading",
    "href": "numexpr.html#multithreading",
    "title": "Numexpr",
    "section": "6. Multithreading",
    "text": "6. Multithreading\nNumExpr automatically uses multiple threads for parallel computation.\n\nAdjusting the Number of Threads\nYou can control the number of threads:\nimport numexpr as ne\n\n# Set the number of threads\nne.set_num_threads(4)\n\n# Get the current thread count\nprint(ne.nthreads)",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#benefits-over-numpy",
    "href": "numexpr.html#benefits-over-numpy",
    "title": "Numexpr",
    "section": "7. Benefits Over NumPy",
    "text": "7. Benefits Over NumPy\n\n\n\n\n\n\n\n\nFeature\nNumPy\nNumExpr\n\n\n\n\nIntermediate Arrays\nCreated\nAvoided\n\n\nPerformance\nSingle-threaded\nMultithreaded\n\n\nMemory Usage\nHigher (temp arrays)\nLower (in-place)\n\n\nSyntax\nStandard Python\nString-based expressions",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#error-handling",
    "href": "numexpr.html#error-handling",
    "title": "Numexpr",
    "section": "8. Error Handling",
    "text": "8. Error Handling\nIf there’s an issue with your expression, NumExpr will raise an error. Always validate your inputs to ensure compatibility.\nExample:\ntry:\n    result = ne.evaluate(\"a ** 2 + invalid_function(a)\")\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#when-to-use-numexpr",
    "href": "numexpr.html#when-to-use-numexpr",
    "title": "Numexpr",
    "section": "9. When to Use NumExpr?",
    "text": "9. When to Use NumExpr?\n\nLarge Datasets: Works best when processing large arrays.\nComplex Expressions: Reduces the overhead of creating temporary arrays.\nPerformance-Critical Applications: Offers significant speed-ups over NumPy for heavy computations.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#benchmarks",
    "href": "numexpr.html#benchmarks",
    "title": "Numexpr",
    "section": "10. Benchmarks",
    "text": "10. Benchmarks\n\nComparing NumPy and NumExpr:\nimport numpy as np\nimport numexpr as ne\nimport time\n\na = np.random.rand(1_000_000)\n\n# Using NumPy\nstart = time.time()\nresult_numpy = a**2 + 3*a - 5\nend = time.time()\nprint(\"NumPy Time:\", end - start)\n\n# Using NumExpr\nstart = time.time()\nresult_numexpr = ne.evaluate(\"a**2 + 3*a - 5\")\nend = time.time()\nprint(\"NumExpr Time:\", end - start)\nOutput (example):\nNumPy Time: 0.015\nNumExpr Time: 0.008",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#limitations",
    "href": "numexpr.html#limitations",
    "title": "Numexpr",
    "section": "11. Limitations",
    "text": "11. Limitations\n\nString-based Syntax:\n\nExpressions must be written as strings, which may feel less natural than Python’s native syntax.\n\nUnsupported Functions:\n\nOnly supports a subset of NumPy functions.\nCustom Python functions cannot be used directly in expressions.\n\nNot for Small Arrays:\n\nOverhead may negate performance benefits for small datasets.\n\nNo GPU Support:\n\nNumExpr is CPU-bound and does not leverage GPUs.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#advanced-usage",
    "href": "numexpr.html#advanced-usage",
    "title": "Numexpr",
    "section": "12. Advanced Usage",
    "text": "12. Advanced Usage\n\nA) Conditional Expressions\nUse where to perform conditional operations:\nne.evaluate(\"where(a &gt; 0.5, a, 0)\")\n\n\nB) Broadcasting\nNumExpr supports broadcasting, similar to NumPy:\nb = np.arange(1, 1e6 + 1)\nne.evaluate(\"a + b\")\n\n\nC) Chained Operations\nYou can chain multiple operations in a single expression:\nne.evaluate(\"(a ** 2 + b) / (a + 1)\")",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#common-use-cases",
    "href": "numexpr.html#common-use-cases",
    "title": "Numexpr",
    "section": "13. Common Use Cases",
    "text": "13. Common Use Cases\n\nFinancial Calculations:\n\nFast evaluation of complex mathematical models.\n\nData Science and Machine Learning:\n\nPreprocessing and transforming large datasets.\n\nSimulations:\n\nEfficiently evaluating mathematical models for physical systems.\n\nScientific Computing:\n\nSpeeding up computationally intensive numerical workflows.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "numexpr.html#alternatives-to-numexpr",
    "href": "numexpr.html#alternatives-to-numexpr",
    "title": "Numexpr",
    "section": "14. Alternatives to NumExpr",
    "text": "14. Alternatives to NumExpr\n\nNumba: Just-In-Time (JIT) compilation for Python, offering similar speed-ups.\nCuPy: GPU-based acceleration for NumPy-like operations.\nSciPy: Offers advanced numerical computing but lacks NumExpr’s speed for expressions.",
    "crumbs": [
      "Blog",
      "Numexpr"
    ]
  },
  {
    "objectID": "datetime.html",
    "href": "datetime.html",
    "title": "Datetime",
    "section": "",
    "text": "import datetime\nThis gives access to various date and time classes:\n- datetime.date → Handles only dates.\n- datetime.time → Handles only times.\n- datetime.datetime → Handles both date and time.\n- datetime.timedelta → Represents time differences.\n- datetime.timezone → Handles time zones (replacement for pytz).",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#importing-the-datetime-module",
    "href": "datetime.html#importing-the-datetime-module",
    "title": "Datetime",
    "section": "",
    "text": "import datetime\nThis gives access to various date and time classes:\n- datetime.date → Handles only dates.\n- datetime.time → Handles only times.\n- datetime.datetime → Handles both date and time.\n- datetime.timedelta → Represents time differences.\n- datetime.timezone → Handles time zones (replacement for pytz).",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#working-with-dates",
    "href": "datetime.html#working-with-dates",
    "title": "Datetime",
    "section": "2. Working with Dates",
    "text": "2. Working with Dates\nThe date class handles year, month, and day.\n\nA) Get Today’s Date\ntoday = datetime.date.today()\nprint(today)  # e.g., 2025-01-31\n\n\nB) Create a Specific Date\nd = datetime.date(2025, 1, 31)\nprint(d)  # 2025-01-31\n\n\nC) Extracting Date Components\nprint(d.year)   # 2025\nprint(d.month)  # 1\nprint(d.day)    # 31\n\n\nD) Formatting a Date\nformatted_date = d.strftime(\"%B %d, %Y\")\nprint(formatted_date)  # January 31, 2025\n\nCommon Date Formats: - %Y-%m-%d → 2025-01-31 - %B %d, %Y → January 31, 2025 - %d/%m/%Y → 31/01/2025",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#working-with-time",
    "href": "datetime.html#working-with-time",
    "title": "Datetime",
    "section": "3. Working with Time",
    "text": "3. Working with Time\nThe time class handles hours, minutes, seconds, and microseconds.\n\nA) Create a Specific Time\nt = datetime.time(14, 30, 45)  # 14:30:45\nprint(t)  # 14:30:45\n\n\nB) Extracting Time Components\nprint(t.hour)   # 14\nprint(tDatetime.minute) # 30\nprint(t.second) # 45\n\n\nC) Formatting Time\nformatted_time = t.strftime(\"%I:%M %p\")  \nprint(formatted_time)  # 02:30 PM (12-hour format)",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#working-with-date-and-time-together",
    "href": "datetime.html#working-with-date-and-time-together",
    "title": "Datetime",
    "section": "4. Working with Date and Time Together",
    "text": "4. Working with Date and Time Together\nThe datetime class represents both date and time.\n\nA) Get the Current Date & Time\nnow = datetime.datetime.now()\nprint(now)  # 2025-01-31 14:30:45.123456\n\n\nB) Create a Specific Date & Time\ndt = datetime.datetime(2025, 1, 31, 14, 30, 45)\nprint(dt)  # 2025-01-31 14:30:45\n\n\nC) Extract Components\nprint(dt.year)    # 2025\nprint(dt.month)   # 1\nprint(dt.day)     # 31\nprint(dt.hour)    # 14\nprint(dt.minute)  # 30\nprint(dt.second)  # 45\n\n\nD) Formatting Date & Time\nformatted_dt = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(formatted_dt)  # 2025-01-31 14:30:45",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#time-differences-with-timedelta",
    "href": "datetime.html#time-differences-with-timedelta",
    "title": "Datetime",
    "section": "5. Time Differences with timedelta",
    "text": "5. Time Differences with timedelta\nA timedelta represents a duration between two datetime objects.\n\nA) Create a timedelta\ndelta = datetime.timedelta(days=5, hours=3, minutes=30)\nprint(delta)  # 5 days, 3:30:00\n\n\nB) Add/Subtract a timedelta\nfuture_date = today + delta\nprint(future_date)  # 2025-02-05\n\npast_date = today - delta\nprint(past_date)  # 2025-01-26\n\n\nC) Difference Between Two Dates\ndate1 = datetime.date(2025, 2, 10)\ndate2 = datetime.date(2025, 1, 31)\n\ndifference = date1 - date2\nprint(difference.days)  # 10",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#handling-time-zones-datetime.timezone",
    "href": "datetime.html#handling-time-zones-datetime.timezone",
    "title": "Datetime",
    "section": "6. Handling Time Zones (datetime.timezone)",
    "text": "6. Handling Time Zones (datetime.timezone)\nInstead of using pytz, Python has built-in timezone support using datetime.timezone.\n\nA) Get UTC Time\nutc_now = datetime.datetime.now(datetime.timezone.utc)\nprint(utc_now)  # 2025-01-31 12:00:00+00:00\n\n\nB) Define a Fixed Offset Time Zone\nTo create a timezone with a fixed UTC offset:\noffset = datetime.timedelta(hours=5, minutes=30)  # UTC+5:30\nist = datetime.timezone(offset, name=\"IST\")\n\ndt = datetime.datetime(2025, 1, 31, 14, 30, tzinfo=ist)\nprint(dt)  # 2025-01-31 14:30:00+05:30\n\n\nC) Convert Between Time Zones\nutc_now = datetime.datetime.now(datetime.timezone.utc)\nist = datetime.timezone(datetime.timedelta(hours=5, minutes=30))  # UTC+5:30\n\nist_now = utc_now.astimezone(ist)\nprint(ist_now)  # Converts to IST timezone",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#parsing-strings-into-datetime-strptime",
    "href": "datetime.html#parsing-strings-into-datetime-strptime",
    "title": "Datetime",
    "section": "7. Parsing Strings into datetime (strptime)",
    "text": "7. Parsing Strings into datetime (strptime)\nConvert a string into a datetime object:\ndate_string = \"31-01-2025 14:30\"\ndt = datetime.datetime.strptime(date_string, \"%d-%m-%Y %H:%M\")\nprint(dt)  # 2025-01-31 14:30:00",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#comparing-dates-times",
    "href": "datetime.html#comparing-dates-times",
    "title": "Datetime",
    "section": "8. Comparing Dates & Times",
    "text": "8. Comparing Dates & Times\nd1 = datetime.date(2025, 1, 31)\nd2 = datetime.date(2025, 2, 1)\n\nprint(d1 &lt; d2)  # True\nprint(d1 == d2)  # False\nFor datetime objects:\ndt1 = datetime.datetime(2025, 1, 31, 12, 0)\ndt2 = datetime.datetime(2025, 1, 31, 14, 0)\n\nprint(dt1 &lt; dt2)  # True",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#generating-timestamps",
    "href": "datetime.html#generating-timestamps",
    "title": "Datetime",
    "section": "9. Generating Timestamps",
    "text": "9. Generating Timestamps\n\nA) Get the Current Unix Timestamp\ntimestamp = datetime.datetime.now().timestamp()\nprint(timestamp)  # e.g., 1738293600.123456\n\n\nB) Convert Timestamp to datetime\ndt_from_timestamp = datetime.datetime.fromtimestamp(1738293600)\nprint(dt_from_timestamp)",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#using-datetime-in-json-serialization",
    "href": "datetime.html#using-datetime-in-json-serialization",
    "title": "Datetime",
    "section": "10. Using datetime in JSON Serialization",
    "text": "10. Using datetime in JSON Serialization\nPython’s datetime is not JSON serializable by default:\nimport json\n\nnow = datetime.datetime.now()\njson.dumps({\"timestamp\": now})  # TypeError: Object of type datetime is not JSON serializable\n\nSolution: Convert to String\njson.dumps({\"timestamp\": now.isoformat()})\n\n\nSolution: Convert to Unix Timestamp\njson.dumps({\"timestamp\": now.timestamp()})",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#summary",
    "href": "datetime.html#summary",
    "title": "Datetime",
    "section": "Summary",
    "text": "Summary\n\n\n\nFeature\nCode Example\n\n\n\n\nGet Today’s Date\ndatetime.date.today()\n\n\nGet Current Time\ndatetime.datetime.now().time()\n\n\nCreate a Date\ndatetime.date(2025, 1, 31)\n\n\nCreate a Time\ndatetime.time(14, 30, 45)\n\n\nGet Date & Time\ndatetime.datetime.now()\n\n\nFormat Date\n.strftime(\"%Y-%m-%d\")\n\n\nConvert String to Date\n.strptime(\"31-01-2025\", \"%d-%m-%Y\")\n\n\nAdd 5 Days\ndate + timedelta(days=5)\n\n\nGet UTC Time\ndatetime.datetime.now(datetime.timezone.utc)\n\n\nConvert Time Zones\n.astimezone(new_timezone)",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "datetime.html#conclusion",
    "href": "datetime.html#conclusion",
    "title": "Datetime",
    "section": "Conclusion",
    "text": "Conclusion\n\ndatetime is Python’s built-in solution for working with dates and times.\ndatetime.timezone (not pytz) provides native timezone handling.\ntimedelta helps add/subtract time.\nString parsing (strptime) and formatting (strftime) are essential for conversions.\nAlways consider time zones when working with global applications.\n\nThis guide covers everything you need to master datetime! 🚀",
    "crumbs": [
      "Blog",
      "Datetime"
    ]
  },
  {
    "objectID": "matplotlib.html",
    "href": "matplotlib.html",
    "title": "Matplotlib",
    "section": "",
    "text": "!pip list | grep matplotlib\n\nmatplotlib                    3.7.2\nmatplotlib-inline             0.1.6",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#setup",
    "href": "matplotlib.html#setup",
    "title": "Matplotlib",
    "section": "Setup",
    "text": "Setup\n\nimport matplotlib.pyplot as plt\n\n\nimport matplotlib\nprint(matplotlib.__version__)\n\n3.7.2",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#basic-plotting",
    "href": "matplotlib.html#basic-plotting",
    "title": "Matplotlib",
    "section": "Basic Plotting",
    "text": "Basic Plotting\n\nplt.plot([1,2,3,4], [1,4,9,16]) #line plot\nplt.scatter([1,2,3,4], [1,5,10,16]) #scatter plot\nplt.bar([1,2,3,4], [1,5,10,16]) #bar plot\n\n\n\n\n\n\n\n\n\nplt.hist([1,2,3,4], [1,5,10,16]) #scatter plot\n\n(array([4., 0., 0.]),\n array([ 1.,  5., 10., 16.]),\n &lt;BarContainer object of 3 artists&gt;)",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#figures-and-axes",
    "href": "matplotlib.html#figures-and-axes",
    "title": "Matplotlib",
    "section": "Figures and Axes",
    "text": "Figures and Axes\n\nfig, ax = plt.subplots()\nax.set_ylim([0,2])\n\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('Title')\n\nText(0.5, 1.0, 'Title')",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#customizing-plots",
    "href": "matplotlib.html#customizing-plots",
    "title": "Matplotlib",
    "section": "Customizing Plots",
    "text": "Customizing Plots\n\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16],\n         linestyle = '--',\n         color = 'r')\nplt.grid(True)\nplt.xlim(0, 5)\nplt.ylim(0, 20)",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#multiple-plots",
    "href": "matplotlib.html#multiple-plots",
    "title": "Matplotlib",
    "section": "Multiple Plots",
    "text": "Multiple Plots\n\nfig, ax = plt.subplots(2, \n                      sharex = True,\n                      sharey = True)\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import Divider\nimport mpl_toolkits.axes_grid1.axes_size as Size\n\nfig = plt.figure(figsize=(5.5, 4))\n\n# the rect parameter will be ignored as we will set axes_locator\nrect = (0.1, 0.1, 0.8, 0.8)\nax = [fig.add_axes(rect, label=\"%d\" % i) for i in range(4)]\n\n\nhoriz = [Size.AxesX(ax[0]), Size.Fixed(.5), Size.AxesX(ax[1])]\nvert = [Size.AxesY(ax[0]), Size.Fixed(.5), Size.AxesY(ax[2])]\n\n# divide the axes rectangle into grid whose size is specified by horiz * vert\ndivider = Divider(fig, rect, horiz, vert, aspect=False)\n\n\nax[0].set_axes_locator(divider.new_locator(nx=0, ny=0))\nax[1].set_axes_locator(divider.new_locator(nx=2, ny=0))\nax[2].set_axes_locator(divider.new_locator(nx=0, ny=2))\nax[3].set_axes_locator(divider.new_locator(nx=2, ny=2))\n\nax[0].set_xlim(0, 2)\nax[1].set_xlim(0, 1)\n\nax[0].set_ylim(0, 1)\nax[2].set_ylim(0, 2)\n\ndivider.set_aspect(1.)\n\nfor ax1 in ax:\n    ax1.tick_params(labelbottom=False, labelleft=False)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nim1 = np.arange(100).reshape((10, 10))\nim2 = im1.T\nim3 = np.flipud(im1)\nim4 = np.fliplr(im2)\n\nfig = plt.figure(figsize=(4., 4.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, [im1, im2, im3, im4]):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n\nplt.show()",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#text-and-annotations",
    "href": "matplotlib.html#text-and-annotations",
    "title": "Matplotlib",
    "section": "Text and Annotations",
    "text": "Text and Annotations\n\nplt.text(0.5, 0.5, 'Hello')\n\nText(0.5, 0.5, 'Hello')\n\n\n\n\n\n\n\n\n\n\narrowprops=dict(facecolor='black', shrink=0.05)\n\nplt.annotate('Hello', xy=(0.5, 0.5),\n             xytext=(0.6, 0.6),\n             arrowprops=arrowprops)\n\nText(0.6, 0.6, 'Hello')",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#saving-figures",
    "href": "matplotlib.html#saving-figures",
    "title": "Matplotlib",
    "section": "Saving Figures",
    "text": "Saving Figures\n\nplt.savefig('Data/test_figure.svg')\n\n&lt;Figure size 640x480 with 0 Axes&gt;",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#animation",
    "href": "matplotlib.html#animation",
    "title": "Matplotlib",
    "section": "Animation",
    "text": "Animation\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib.animation as animation\nfrom matplotlib.patches import ConnectionPatch\nfrom IPython.display import HTML\n\nfig, (axl, axr) = plt.subplots(\n    ncols=2,\n    sharey=True,\n    figsize=(6, 2),\n    gridspec_kw=dict(width_ratios=[1, 3], wspace=0),\n)\naxl.set_aspect(1)\naxr.set_box_aspect(1 / 3)\naxr.yaxis.set_visible(False)\naxr.xaxis.set_ticks([0, np.pi, 2 * np.pi], [\"0\", r\"$\\pi$\", r\"$2\\pi$\"])\n\n# draw circle with initial point in left Axes\nx = np.linspace(0, 2 * np.pi, 50)\naxl.plot(np.cos(x), np.sin(x), \"k\", lw=0.3)\npoint, = axl.plot(0, 0, \"o\")\n\n# draw full curve to set view limits in right Axes\nsine, = axr.plot(x, np.sin(x))\n\n# draw connecting line between both graphs\ncon = ConnectionPatch(\n    (1, 0),\n    (0, 0),\n    \"data\",\n    \"data\",\n    axesA=axl,\n    axesB=axr,\n    color=\"C0\",\n    ls=\"dotted\",\n)\nfig.add_artist(con)\n\n\ndef animate(i):\n    x = np.linspace(0, i, int(i * 25 / np.pi))\n    sine.set_data(x, np.sin(x))\n    x, y = np.cos(i), np.sin(i)\n    point.set_data([x], [y])\n    con.xy1 = x, y\n    con.xy2 = i, y\n    return point, sine, con\n\nplt.close()\n\nani = animation.FuncAnimation(\n    fig,\n    animate,\n    interval=50,\n    blit=False,  # blitting can't be used with Figure artists\n    frames=x,\n    repeat_delay=100,\n)\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib.animation as animation\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\ndef random_walk(num_steps, max_step=0.05):\n    \"\"\"Return a 3D random walk as (num_steps, 3) array.\"\"\"\n    start_pos = np.random.random(3)\n    steps = np.random.uniform(-max_step, max_step, size=(num_steps, 3))\n    walk = start_pos + np.cumsum(steps, axis=0)\n    return walk\n\n\ndef update_lines(num, walks, lines):\n    for line, walk in zip(lines, walks):\n        # NOTE: there is no .set_data() for 3 dim data...\n        line.set_data(walk[:num, :2].T)\n        line.set_3d_properties(walk[:num, 2])\n    return lines\n\n\n# Data: 40 random walks as (num_steps, 3) arrays\nnum_steps = 10\nwalks = [random_walk(num_steps) for index in range(15)]\n\n# Attaching 3D axis to the figure\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\n\n# Create lines initially without data\nlines = [ax.plot([], [], [])[0] for _ in walks]\n\n# Setting the axes properties\nax.set(xlim3d=(0, 1), xlabel='X')\nax.set(ylim3d=(0, 1), ylabel='Y')\nax.set(zlim3d=(0, 1), zlabel='Z')\n\nplt.close()\n\n# Creating the Animation object\nani = animation.FuncAnimation(\n    fig, update_lines, num_steps, fargs=(walks, lines), interval=100)\n\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "matplotlib.html#d-plots",
    "href": "matplotlib.html#d-plots",
    "title": "Matplotlib",
    "section": "3D plots",
    "text": "3D plots\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib import cbook, cm\nfrom matplotlib.colors import LightSource\n\n# Load and format data\ndem = cbook.get_sample_data('jacksboro_fault_dem.npz', np_load = True)\n\nz = dem['elevation']\nnrows, ncols = z.shape\nx = np.linspace(dem['xmin'], dem['xmax'], ncols)\ny = np.linspace(dem['ymin'], dem['ymax'], nrows)\nx, y = np.meshgrid(x, y)\n\nregion = np.s_[5:50, 5:50]\nx, y, z = x[region], y[region], z[region]\n\n# Set up plot\nfig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n\nls = LightSource(270, 45)\n# To use a custom hillshading mode, override the built-in shading and pass\n# in the rgb colors of the shaded surface calculated from \"shade\".\nrgb = ls.shade(z, cmap=cm.gist_earth, vert_exag=0.1, blend_mode='soft')\nsurf = ax.plot_surface(x, y, z, rstride=1, cstride=1, facecolors=rgb,\n                       linewidth=0, antialiased=False, shade=False)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.mplot3d import axes3d\n\nax = plt.figure().add_subplot(projection='3d')\nX, Y, Z = axes3d.get_test_data(0.05)\n\n# Plot the 3D surface\nax.plot_surface(X, Y, Z, edgecolor='royalblue', lw=0.5, rstride=8, cstride=8,\n                alpha=0.3)\n\n# Plot projections of the contours for each dimension.  By choosing offsets\n# that match the appropriate axes limits, the projected contours will sit on\n# the 'walls' of the graph\nax.contourf(X, Y, Z, zdir='z', offset=-100, cmap='coolwarm')\nax.contourf(X, Y, Z, zdir='x', offset=-40, cmap='coolwarm')\nax.contourf(X, Y, Z, zdir='y', offset=40, cmap='coolwarm')\n\nax.set(xlim=(-40, 40), ylim=(-40, 40), zlim=(-100, 100),\n       xlabel='X', ylabel='Y', zlabel='Z')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.collections import PolyCollection\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\ndef polygon_under_graph(x, y):\n    \"\"\"\n    Construct the vertex list which defines the polygon filling the space under\n    the (x, y) line graph. This assumes x is in ascending order.\n    \"\"\"\n    return [(x[0], 0.), *zip(x, y), (x[-1], 0.)]\n\n\nax = plt.figure().add_subplot(projection='3d')\n\nx = np.linspace(0., 10., 31)\nlambdas = range(1, 9)\n\n# verts[i] is a list of (x, y) pairs defining polygon i.\ngamma = np.vectorize(math.gamma)\nverts = [polygon_under_graph(x, l**x * np.exp(-l) / gamma(x + 1))\n         for l in lambdas]\nfacecolors = plt.colormaps['viridis_r'](np.linspace(0, 1, len(verts)))\n\npoly = PolyCollection(verts, facecolors=facecolors, alpha=.7)\nax.add_collection3d(poly, zs=lambdas, zdir='y')\n\nax.set(xlim=(0, 10), ylim=(1, 9), zlim=(0, 0.35),\n       xlabel='x', ylabel=r'$\\lambda$', zlabel='probability')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\n\ncolors = ['r', 'g', 'b', 'y']\nyticks = [3, 2, 1, 0]\nfor c, k in zip(colors, yticks):\n    # Generate the random data for the y=k 'layer'.\n    xs = np.arange(20)\n    ys = np.random.rand(20)\n\n    # You can provide either a single color or an array with the same length as\n    # xs and ys. To demonstrate this, we color the first bar of each set cyan.\n    cs = [c] * len(xs)\n    cs[0] = 'c'\n\n    # Plot the bar graph given by xs and ys on the plane y=k with 80% opacity.\n    ax.bar(xs, ys, zs=k, zdir='y', color=cs, alpha=0.8)\n\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\n\n# On the y-axis let's only label the discrete values that we have data for.\nax.set_yticks(yticks)\n\nplt.show()",
    "crumbs": [
      "Blog",
      "Matplotlib"
    ]
  },
  {
    "objectID": "Environments/uv.html",
    "href": "Environments/uv.html",
    "title": "uv",
    "section": "",
    "text": "Example:\nuv init my_project\n\n\n\nExample:\nuv add flask\n\n\n\nExample:\nuv remove flask\n\n\n\nExample:\nuv sync\n\n\n\nExample:\nuv lock\n\n\n\nExample:\nuv run app.py\n\n\n\nExample:\nuv python install 3.11\n\n\n\nExample:\nuv python use 3.11\n\n\n\nExample:\nuv pip install requests\n\n\n\nExample:\nuv pip uninstall requests",
    "crumbs": [
      "Blog",
      "Environments",
      "uv"
    ]
  },
  {
    "objectID": "Environments/uv.html#key-commands-and-their-usage",
    "href": "Environments/uv.html#key-commands-and-their-usage",
    "title": "uv",
    "section": "",
    "text": "Example:\nuv init my_project\n\n\n\nExample:\nuv add flask\n\n\n\nExample:\nuv remove flask\n\n\n\nExample:\nuv sync\n\n\n\nExample:\nuv lock\n\n\n\nExample:\nuv run app.py\n\n\n\nExample:\nuv python install 3.11\n\n\n\nExample:\nuv python use 3.11\n\n\n\nExample:\nuv pip install requests\n\n\n\nExample:\nuv pip uninstall requests",
    "crumbs": [
      "Blog",
      "Environments",
      "uv"
    ]
  },
  {
    "objectID": "Environments/uv.html#additional-features",
    "href": "Environments/uv.html#additional-features",
    "title": "uv",
    "section": "🧰 Additional Features",
    "text": "🧰 Additional Features\n\nuv tool run &lt;command&gt; Executes a command provided by a Python package without installing it globally.\nuv tool install &lt;tool&gt; Installs a command-line tool provided by a Python package.\nuv venv Creates a virtual environment for the project.\nuv version Displays the current version of uv.\nuv help Provides help and documentation for uv commands.",
    "crumbs": [
      "Blog",
      "Environments",
      "uv"
    ]
  },
  {
    "objectID": "Environments/uv.html#advantages-of-using-uv",
    "href": "Environments/uv.html#advantages-of-using-uv",
    "title": "uv",
    "section": "✅ Advantages of Using uv",
    "text": "✅ Advantages of Using uv\n\nSpeed uv is significantly faster than traditional package managers like pip, offering 10–100x speed improvements for package installation and dependency resolution\nUnified Tooling Combines the functionalities of multiple tools into one, simplifying the development workflow.\nReproducibility Ensures consistent environments with pyproject.toml and uv.lock files.\nPython Version Management Easily switch between Python versions within projects.\nEnvironment Isolation Manages project-specific environments to avoid dependency conflicts.",
    "crumbs": [
      "Blog",
      "Environments",
      "uv"
    ]
  },
  {
    "objectID": "Environments/variables.html",
    "href": "Environments/variables.html",
    "title": "Linux Environment Variables",
    "section": "",
    "text": "Environment variables are key-value pairs that provide information about the system environment to processes. They are inherited by child processes and can influence the execution of commands and applications\nCommon environment variables include:\n\nPATH:Specifies directories to search for executable files\nHOME:Indicates the current user’s home directory\nUSER:Stores the name of the current user\nSHELL:Defines the path to the current user’s shell\nLANG:Sets the system’s locale and language settings",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/variables.html#what-are-environment-variables",
    "href": "Environments/variables.html#what-are-environment-variables",
    "title": "Linux Environment Variables",
    "section": "",
    "text": "Environment variables are key-value pairs that provide information about the system environment to processes. They are inherited by child processes and can influence the execution of commands and applications\nCommon environment variables include:\n\nPATH:Specifies directories to search for executable files\nHOME:Indicates the current user’s home directory\nUSER:Stores the name of the current user\nSHELL:Defines the path to the current user’s shell\nLANG:Sets the system’s locale and language settings",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/variables.html#managing-environment-variables",
    "href": "Environments/variables.html#managing-environment-variables",
    "title": "Linux Environment Variables",
    "section": "🧰 Managing Environment Variables",
    "text": "🧰 Managing Environment Variables\n\n1. Listing Environment Variables\nTo display all environment variable:\nprintenv\n``\n\nOr, to display a specific variabl:\n\n```bash\necho $VARIABLE_NAME\nFor example, to check the PATH variable:\necho $PATH\n\n\n2. Setting Environment Variables Temporarily\nTo set an environment variable for the current session:\nexport VARIABLE_NAME=\"value\"\nFor example:\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk\"\nThis variable will be available until the session end.\n\n\n3. Setting Environment Variables Permanently\nTo make an environment variable persistent across sessions, add it to your shell’s initialization file:\nFor Bash:\n  echo 'export VARIABLE_NAME=\"value\"' &gt;&gt; ~/.bashrc\n  source ~/.bashrc\nFor Zsh:\n  echo 'export VARIABLE_NAME=\"value\"' &gt;&gt; ~/.zshrc\n  source ~/.zshrc\nFor system-wide variables, add them to /etc/environment or create a script in /etc/profile.d/:\necho 'export VARIABLE_NAME=\"value\"' | sudo tee /etc/profile.d/custom_env.sh\nsudo chmod +x /etc/profile.d/custom_env.sh",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/variables.html#best-practices",
    "href": "Environments/variables.html#best-practices",
    "title": "Linux Environment Variables",
    "section": "🧠 Best Practices",
    "text": "🧠 Best Practices\n\n**Use uppercase names*: By convention, environment variable names are uppercase to distinguish them from shell variables.\n**Be cautious with PATH*: When modifying PATH, append directories rather than replacing its value to avoid overwriting existing paths.\n**Secure sensitive data*: Avoid storing sensitive information like passwords directly in environment variables. Use secure methods for handling such data.\n**Document changes*: Keep track of modifications to environment variables, especially system-wide changes, to maintain system integrity.",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/variables.html#troubleshooting",
    "href": "Environments/variables.html#troubleshooting",
    "title": "Linux Environment Variables",
    "section": "🛠 Troubleshooting",
    "text": "🛠 Troubleshooting\n\nVariable not found: Ensure the variable is defined in the correct initialization file and that the file is sourced.\nChanges not reflected: After modifying initialization files, run source ~/.bashrc (or the appropriate file) to apply chances.\nConflicting variables: Check for conflicting definitions in multiple files and resolve them to prevent unexpected behavior.",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/variables.html#additional-resources",
    "href": "Environments/variables.html#additional-resources",
    "title": "Linux Environment Variables",
    "section": "📚 Additional Resources",
    "text": "📚 Additional Resources\n\nHow to List, Set and Manage Linux Environment Variables\nHow to Set Environment Variables in Linux - freeCodeCamp\nManaging Environment Variables in Linux - Baeldung",
    "crumbs": [
      "Blog",
      "Environments",
      "Linux Environment Variables"
    ]
  },
  {
    "objectID": "Environments/conda.html",
    "href": "Environments/conda.html",
    "title": "Conda",
    "section": "",
    "text": "mkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm ~/miniconda3/miniconda.sh",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#install-conda",
    "href": "Environments/conda.html#install-conda",
    "title": "Conda",
    "section": "",
    "text": "mkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm ~/miniconda3/miniconda.sh",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#initialize-conda",
    "href": "Environments/conda.html#initialize-conda",
    "title": "Conda",
    "section": "Initialize Conda",
    "text": "Initialize Conda\n~/miniconda3/bin/conda init bash",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#creating-and-managing-environments",
    "href": "Environments/conda.html#creating-and-managing-environments",
    "title": "Conda",
    "section": "Creating and Managing Environments",
    "text": "Creating and Managing Environments\nconda create --name myenv\n\nExample\n\nconda create --name myenv python=3.8 numpy pandas",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#activating-an-environment",
    "href": "Environments/conda.html#activating-an-environment",
    "title": "Conda",
    "section": "Activating an Environment",
    "text": "Activating an Environment\nconda activate myenv",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#deactivating-an-environment",
    "href": "Environments/conda.html#deactivating-an-environment",
    "title": "Conda",
    "section": "Deactivating an Environment",
    "text": "Deactivating an Environment\nconda deactivate",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#listing-environments",
    "href": "Environments/conda.html#listing-environments",
    "title": "Conda",
    "section": "Listing Environments",
    "text": "Listing Environments\nconda env list",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#installing-and-managing-packages",
    "href": "Environments/conda.html#installing-and-managing-packages",
    "title": "Conda",
    "section": "Installing and Managing Packages",
    "text": "Installing and Managing Packages\nconda install scipy",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#updating-packages",
    "href": "Environments/conda.html#updating-packages",
    "title": "Conda",
    "section": "Updating Packages",
    "text": "Updating Packages\nconda update numpy",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#removing-packages",
    "href": "Environments/conda.html#removing-packages",
    "title": "Conda",
    "section": "Removing Packages",
    "text": "Removing Packages\nconda remove scipy",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#removing-an-environment",
    "href": "Environments/conda.html#removing-an-environment",
    "title": "Conda",
    "section": "Removing an Environment",
    "text": "Removing an Environment\nconda env remove --name myenv",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#searching-for-packages",
    "href": "Environments/conda.html#searching-for-packages",
    "title": "Conda",
    "section": "Searching for Packages",
    "text": "Searching for Packages\nconda search beautifulsoup4",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/conda.html#using-channels",
    "href": "Environments/conda.html#using-channels",
    "title": "Conda",
    "section": "Using Channels",
    "text": "Using Channels\n\nConda channels are locations where packages are stored. By default, Conda uses the defaults channel, but you can add others like conda-forge.\n\n\nAdding a Channel\nconda config --add channels conda-forge\n\n\nInstalling from a Specific Channel\nconda install -c conda-forge opencv\n\n\nListing Conda Channels\nconda config --show channels\n\n!conda config --show channels\n\nchannels:\n  - defaults",
    "crumbs": [
      "Blog",
      "Environments",
      "Conda"
    ]
  },
  {
    "objectID": "Environments/poetry.html",
    "href": "Environments/poetry.html",
    "title": "Poetry",
    "section": "",
    "text": "curl -sSL https://install.python-poetry.org | python3 -\nOr\npip install poetry",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#install-poetry",
    "href": "Environments/poetry.html#install-poetry",
    "title": "Poetry",
    "section": "",
    "text": "curl -sSL https://install.python-poetry.org | python3 -\nOr\npip install poetry",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#config-poetry",
    "href": "Environments/poetry.html#config-poetry",
    "title": "Poetry",
    "section": "Config Poetry",
    "text": "Config Poetry\npoetry config --list\n\n!poetry config --list\n\ncache-dir = \"/home/ben/.cache/pypoetry\"\nexperimental.system-git-client = false\ninstaller.max-workers = null\ninstaller.modern-installation = true\ninstaller.no-binary = null\ninstaller.parallel = true\nkeyring.enabled = true\nsolver.lazy-wheel = true\nvirtualenvs.create = true\nvirtualenvs.in-project = true\nvirtualenvs.options.always-copy = false\nvirtualenvs.options.no-pip = false\nvirtualenvs.options.no-setuptools = false\nvirtualenvs.options.system-site-packages = false\nvirtualenvs.path = \"{cache-dir}/virtualenvs\"  # /home/ben/.cache/pypoetry/virtualenvs\nvirtualenvs.prefer-active-python = false\nvirtualenvs.prompt = \"{project_name}-py{python_version}\"\nwarnings.export = true\n\n\n\n!poetry config virtualenvs.in-project true",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#initallise-poetry",
    "href": "Environments/poetry.html#initallise-poetry",
    "title": "Poetry",
    "section": "Initallise Poetry",
    "text": "Initallise Poetry\npoetry init",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#managing-dependencies",
    "href": "Environments/poetry.html#managing-dependencies",
    "title": "Poetry",
    "section": "Managing Dependencies",
    "text": "Managing Dependencies\npoetry add requests",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#managing-development-dependencies",
    "href": "Environments/poetry.html#managing-development-dependencies",
    "title": "Poetry",
    "section": "Managing Development Dependencies",
    "text": "Managing Development Dependencies\npoetry add --dev pytest",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#updating-dependencies",
    "href": "Environments/poetry.html#updating-dependencies",
    "title": "Poetry",
    "section": "Updating Dependencies",
    "text": "Updating Dependencies\npoetry update",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#managing-virtual-environments",
    "href": "Environments/poetry.html#managing-virtual-environments",
    "title": "Poetry",
    "section": "Managing Virtual Environments",
    "text": "Managing Virtual Environments\npoetry install",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#activating-the-virtual-environment",
    "href": "Environments/poetry.html#activating-the-virtual-environment",
    "title": "Poetry",
    "section": "Activating the Virtual Environment",
    "text": "Activating the Virtual Environment\npoetry shell",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#deactivating-the-virtual-environment",
    "href": "Environments/poetry.html#deactivating-the-virtual-environment",
    "title": "Poetry",
    "section": "Deactivating the Virtual Environment",
    "text": "Deactivating the Virtual Environment\nexit",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#running-scripts-and-commands",
    "href": "Environments/poetry.html#running-scripts-and-commands",
    "title": "Poetry",
    "section": "Running Scripts and Commands",
    "text": "Running Scripts and Commands\n\nYou can run scripts or commands within the Poetry-managed environment without activating it explicitly:\n\npoetry run python my_script.py",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#publishing-packages",
    "href": "Environments/poetry.html#publishing-packages",
    "title": "Poetry",
    "section": "Publishing Packages",
    "text": "Publishing Packages\npoetry build  # Builds the package\npoetry publish  # Publishes the package to PyPI",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "Environments/poetry.html#exporting-to-requirements.txt",
    "href": "Environments/poetry.html#exporting-to-requirements.txt",
    "title": "Poetry",
    "section": "Exporting to requirements.txt",
    "text": "Exporting to requirements.txt\npoetry self add poetry-plugin-export\npoetry export -f requirements.txt -o requirements.txt --without-hashes",
    "crumbs": [
      "Blog",
      "Environments",
      "Poetry"
    ]
  },
  {
    "objectID": "0_pytest.html",
    "href": "0_pytest.html",
    "title": "Pytest",
    "section": "",
    "text": "pytest is a powerful, Pythonic testing framework used to write, run, and organize tests with minimal boilerplate.\n\nSupports unit, integration, and functional testing\nWorks out-of-the-box with Python’s assert\nAutomatically discovers test files and functions",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#what-is-pytest",
    "href": "0_pytest.html#what-is-pytest",
    "title": "Pytest",
    "section": "",
    "text": "pytest is a powerful, Pythonic testing framework used to write, run, and organize tests with minimal boilerplate.\n\nSupports unit, integration, and functional testing\nWorks out-of-the-box with Python’s assert\nAutomatically discovers test files and functions",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#getting-started",
    "href": "0_pytest.html#getting-started",
    "title": "Pytest",
    "section": "🚀 2. Getting Started",
    "text": "🚀 2. Getting Started\n\n📦 Installation\npip install pytest\n\n\n🏃 Running Tests\npytest                # Run all tests\npytest test_file.py   # Run a specific file\npytest -k \"name\"      # Run tests matching \"name\"\n\n\n📄 File & Function Naming Conventions\n\nFiles: test_*.py or *_test.py\nFunctions: test_*",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#writing-basic-tests",
    "href": "0_pytest.html#writing-basic-tests",
    "title": "Pytest",
    "section": "🧪 3. Writing Basic Tests",
    "text": "🧪 3. Writing Basic Tests\ndef add(x, y):\n    return x + y\n\ndef test_add():\n    assert add(2, 3) == 5\n\n✅ Advantages\n\nNo need for classes\nNo need for self.assert* syntax",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#fixtures",
    "href": "0_pytest.html#fixtures",
    "title": "Pytest",
    "section": "⚙️ 4. Fixtures",
    "text": "⚙️ 4. Fixtures\nFixtures manage setup and teardown for tests. You can reuse resources like DBs, clients, configs.\n\nExample:\nimport pytest\n\n@pytest.fixture\ndef sample_data():\n    return {\"x\": 10, \"y\": 20}\n\ndef test_sum(sample_data):\n    assert sample_data[\"x\"] + sample_data[\"y\"] == 30\n\nScope options: function (default), class, module, session",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#parametrization",
    "href": "0_pytest.html#parametrization",
    "title": "Pytest",
    "section": "🎯 5. Parametrization",
    "text": "🎯 5. Parametrization\nWrite a single test function that runs with different inputs:\nimport pytest\n\n@pytest.mark.parametrize(\"a,b,result\", [\n    (1, 1, 2),\n    (2, 3, 5),\n    (5, 5, 10)\n])\ndef test_add(a, b, result):\n    assert a + b == result",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#grouping-with-classes-optional",
    "href": "0_pytest.html#grouping-with-classes-optional",
    "title": "Pytest",
    "section": "🧵 6. Grouping with Classes (Optional)",
    "text": "🧵 6. Grouping with Classes (Optional)\nclass TestMath:\n    def test_add(self):\n        assert 1 + 2 == 3\n\nNo need to inherit from unittest.TestCase",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#plugins-extensions",
    "href": "0_pytest.html#plugins-extensions",
    "title": "Pytest",
    "section": "🔌 7. Plugins & Extensions",
    "text": "🔌 7. Plugins & Extensions\nSome powerful plugins:\n\n\n\nPlugin\nPurpose\n\n\n\n\npytest-django\nDjango testing integration\n\n\npytest-mock\nSimplified mocking\n\n\npytest-cov\nTest coverage reporting\n\n\npytest-xdist\nRun tests in parallel\n\n\npytest-asyncio\nSupport async tests\n\n\npytest-env\nSet env vars during test runs\n\n\npytest-randomly\nRandomize test order\n\n\n\nInstall with:\npip install pytest-cov pytest-mock pytest-django",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#coverage",
    "href": "0_pytest.html#coverage",
    "title": "Pytest",
    "section": "📊 8. Coverage",
    "text": "📊 8. Coverage\npytest --cov=my_module\n\nShows % of code covered by tests\nUse --cov-report=html for an HTML report",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#mocks-patching",
    "href": "0_pytest.html#mocks-patching",
    "title": "Pytest",
    "section": "🧪 9. Mocks & Patching",
    "text": "🧪 9. Mocks & Patching\nUse pytest-mock or unittest.mock:\ndef test_api_call(mocker):\n    mock_request = mocker.patch(\"requests.get\")\n    mock_request.return_value.status_code = 200\n    ...",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#async-testing",
    "href": "0_pytest.html#async-testing",
    "title": "Pytest",
    "section": "🧪 10. Async Testing",
    "text": "🧪 10. Async Testing\nInstall:\npip install pytest-asyncio\nThen:\nimport pytest\nimport asyncio\n\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await some_async_function()\n    assert result == \"done\"",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#advanced-cli-options",
    "href": "0_pytest.html#advanced-cli-options",
    "title": "Pytest",
    "section": "🧪 11. Advanced CLI Options",
    "text": "🧪 11. Advanced CLI Options\npytest -x                  # Stop after first failure\npytest -v                  # Verbose output\npytest --tb=short          # Shorter tracebacks\npytest -n auto             # Parallel test execution (requires `xdist`)",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#test-structure-example",
    "href": "0_pytest.html#test-structure-example",
    "title": "Pytest",
    "section": "📁 12. Test Structure Example",
    "text": "📁 12. Test Structure Example\nmy_project/\n├── app/\n│   └── logic.py\n├── tests/\n│   ├── conftest.py       # shared fixtures\n│   ├── test_logic.py\n│   └── test_api.py",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#conftest.py-centralized-fixtures",
    "href": "0_pytest.html#conftest.py-centralized-fixtures",
    "title": "Pytest",
    "section": "📑 13. conftest.py – Centralized Fixtures",
    "text": "📑 13. conftest.py – Centralized Fixtures\n# tests/conftest.py\nimport pytest\n\n@pytest.fixture\ndef config():\n    return {\"ENV\": \"test\"}\nAuto-discovered across test files in the same directory tree.",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#best-practices",
    "href": "0_pytest.html#best-practices",
    "title": "Pytest",
    "section": "🧪 14. Best Practices",
    "text": "🧪 14. Best Practices\n✅ Use descriptive test function names ✅ Keep tests fast, isolated, and repeatable ✅ Avoid hardcoding test data – use fixtures and parametrization ✅ Use pytest-cov to ensure meaningful coverage ✅ Run in CI pipelines (GitHub Actions, GitLab, etc.) ✅ Structure tests like your app structure",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#cicd-integration",
    "href": "0_pytest.html#cicd-integration",
    "title": "Pytest",
    "section": "🧰 15. CI/CD Integration",
    "text": "🧰 15. CI/CD Integration\n# GitHub Actions example\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.11\n      - run: pip install -r requirements.txt\n      - run: pytest --cov=my_app",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#bonus-debugging-tips",
    "href": "0_pytest.html#bonus-debugging-tips",
    "title": "Pytest",
    "section": "🧠 Bonus: Debugging Tips",
    "text": "🧠 Bonus: Debugging Tips\n\npytest --pdb: drop into debugger on failure\npytest -s: allow print() output\npdb.set_trace() inside your test or app logic",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "0_pytest.html#example-test-case-with-fixture-parametrize-mock",
    "href": "0_pytest.html#example-test-case-with-fixture-parametrize-mock",
    "title": "Pytest",
    "section": "🧠 Example: Test Case with Fixture + Parametrize + Mock",
    "text": "🧠 Example: Test Case with Fixture + Parametrize + Mock\nimport pytest\n\n@pytest.fixture\ndef sample_user():\n    return {\"name\": \"Ben\", \"role\": \"engineer\"}\n\n@pytest.mark.parametrize(\"role\", [\"admin\", \"guest\"])\ndef test_user_roles(sample_user, role):\n    sample_user[\"role\"] = role\n    assert sample_user[\"role\"] in [\"admin\", \"guest\"]",
    "crumbs": [
      "Blog",
      "Pytest"
    ]
  },
  {
    "objectID": "Display/mermaid.html",
    "href": "Display/mermaid.html",
    "title": "Mermaid",
    "section": "",
    "text": "from IPython.display import display, Markdown\n\ndisplay(Markdown('''\n```mermaid\ngraph TD\n    A[Start] --&gt; B{Is it?}\n    B --&gt;|Yes| C[Do something]\n    B --&gt;|No| D[Do something else]\n    C --&gt; E[End]\n    D --&gt; E[End]\n\n'''))\n\ngraph TD\n    A[Start] --&gt; B{Is it?}\n    B --&gt;|Yes| C[Do something]\n    B --&gt;|No| D[Do something else]\n    C --&gt; E[End]\n    D --&gt; E[End]\n\n\n:::\n:::\n\n\n#### 2. Sequence Diagram\n\n```mermaid\nsequenceDiagram\n    participant Alice\n    participant Bob\n    Alice-&gt;&gt;Bob: Hello Bob, how are you?\n    Bob--&gt;&gt;Alice: I am good thanks!\n    Alice-&gt;&gt;Bob: Are you going to the party?\n    Bob--&gt;&gt;Alice: Yes, see you there!\n\n#### 3. Class Diagram\n\n```mermaid\nclassDiagram\n    Animal &lt;|-- Duck\n    Animal &lt;|-- Fish\n    Animal &lt;|-- Zebra\n    Animal : +int age\n    Animal : +String gender\n    Animal: +isMammal()\n    Animal: +mate()\n    class Duck{\n      +String beakColor\n      +swim()\n      +quack()\n    }\n    class Fish{\n      -int sizeInFeet\n      -canEat()\n    }\n    class Zebra{\n      +bool is_wild\n      +run()\n    }\n\n#### 4. Gantt Chart\n\n```mermaid\ngantt\n    title A Gantt Diagram\n    dateFormat  YYYY-MM-DD\n    section Section\n    A task           :a1, 2024-01-01, 30d\n    Another task     :after a1  , 20d\n    section Another\n    Task in sec      :2024-01-12  , 12d\n    another task     : 24d\n\n## Running Mermaid Diagrams\n\n::: {#607edd8b-6aac-480e-8650-8a6ae5af9877 .cell}\n``` {.python .cell-code code-fold=\"true\"}\nfrom IPython.display import display, HTML\n\nmermaid_code = \"\"\"\ngraph TD\n    A[Start] --&gt; B{Is it?}\n    B --&gt;|Yes| C[Do something]\n    B --&gt;|No| D[Do something else]\n    C --&gt; E[End]\n    D --&gt; E[End]\n\"\"\"\n\ndisplay(HTML(f\"\"\"\n&lt;div class=\"mermaid\"&gt;\n  {mermaid_code}\n&lt;/div&gt;\n&lt;script type=\"module\"&gt;\n  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@9/dist/mermaid.esm.min.mjs';\n  mermaid.initialize({{ startOnLoad: true }});\n&lt;/script&gt;\n\"\"\"))\n\n\n\n  \ngraph TD\n    A[Start] --&gt; B{Is it?}\n    B --&gt;|Yes| C[Do something]\n    B --&gt;|No| D[Do something else]\n    C --&gt; E[End]\n    D --&gt; E[End]\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Display",
      "Mermaid"
    ]
  },
  {
    "objectID": "Display/graphviz.html",
    "href": "Display/graphviz.html",
    "title": "Graphviz",
    "section": "",
    "text": "from graphviz import Digraph\n\nfrom nbdevAuto.functions import graph",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/graphviz.html#customizing-nodes-and-edges",
    "href": "Display/graphviz.html#customizing-nodes-and-edges",
    "title": "Graphviz",
    "section": "Customizing Nodes and Edges",
    "text": "Customizing Nodes and Edges\n\ndot = graph()\n\ndot.node('A', 'Start', shape='ellipse', color='red')\ndot.node('B', 'End', shape='box', color='blue')\ndot.edge('A', 'B', 'Transition', color='green')\n\ndot\n\n\n\n\n\n\n\n\n\nCreating Subgraphs\n\n\nCode\ndot = graph()\n\nwith dot.subgraph(name='cluster_0') as c:\n    c.node('A', 'Node A')\n    c.node('B', 'Node B')\n    c.edge('A', 'B')\n    c.attr(label='Subgraph 1')\n\nwith dot.subgraph(name='cluster_1') as c:\n    c.node('C', 'Node C')\n    c.node('D', 'Node D')\n    c.edge('C', 'D')\n    c.attr(label='Subgraph 2')\n\ndot.edge('A', 'C')\n\ndot\n\n\n\n\n\n\n\n\n\n\n\nDirected Acyclic Graph (DAG)\n\n\nCode\ndag = graph()\n\ndag.node('1', 'Step 1')\ndag.node('2', 'Step 2')\ndag.node('3', 'Step 3')\ndag.edge('1', '2')\ndag.edge('2', '3')\n\ndag\n\n\n\n\n\n\n\n\n\n\n\nGraph with Attributes:\n\n\nCode\nfrom graphviz import Digraph\n\ndot = graph()\n\ndot.attr('node', shape='circle')\ndot.node('A')\ndot.node('B')\ndot.node('C')\ndot.node('D')\n\ndot.edge('A', 'B')\ndot.edge('A', 'C')\ndot.edge('B', 'D')\ndot.edge('C', 'D')\n\ndot.attr(label='Graph with Attributes', fontsize='20')\ndot",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/graphviz.html#flowchart",
    "href": "Display/graphviz.html#flowchart",
    "title": "Graphviz",
    "section": "Flowchart",
    "text": "Flowchart\n\n\nCode\nflowchart = graph()\nflowchart.graph_attr.update(style='rounded,filled',\n                               rankdir='TB',\n                           )\nflowchart.node('Start', 'Start', shape='ellipse', style='filled', color='lightgrey')\nflowchart.node('A', 'Action A', shape='box')\nflowchart.node('B', 'Action B', shape='box')\nflowchart.node('C', 'Action C', shape='diamond')\nflowchart.node('End', 'End', shape='ellipse', style='filled', color='lightgrey')\n\nflowchart.edge('Start', 'A')\nflowchart.edge('A', 'B')\nflowchart.edge('B', 'C')\nflowchart.edge('C', 'End')\n\nflowchart",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/graphviz.html#tree-diagram",
    "href": "Display/graphviz.html#tree-diagram",
    "title": "Graphviz",
    "section": "Tree Diagram",
    "text": "Tree Diagram\n\n\nCode\nfrom graphviz import Digraph\n\ntree = graph()\ntree.graph_attr.update(style='rounded,filled',\n                               rankdir='TB',\n                           )\ntree.node('A', 'Root')\ntree.node('B', 'Child B')\ntree.node('C', 'Child C')\ntree.node('D', 'Child D')\ntree.node('E', 'Child E')\n\ntree.edge('A', 'B')\ntree.edge('A', 'C')\ntree.edge('B', 'D')\ntree.edge('B', 'E')\n\ntree",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/graphviz.html#cnn",
    "href": "Display/graphviz.html#cnn",
    "title": "Graphviz",
    "section": "CNN",
    "text": "CNN\n\n\nCode\ndot = graph(comment='CNN Architecture')\n\n# Define nodes\ndot.node('I', 'Input Layer\\n(32x32x3)')\ndot.node('C1', 'Conv Layer 1\\n(28x28x32)')\ndot.node('P1', 'Pooling Layer 1\\n(14x14x32)')\ndot.node('C2', 'Conv Layer 2\\n(10x10x64)')\ndot.node('P2', 'Pooling Layer 2\\n(5x5x64)')\ndot.node('F', 'Fully Connected Layer\\n(1024)')\ndot.node('O', 'Output Layer\\n(10)')\n\n# Define edges\ndot.edge('I', 'C1', label='Conv\\n(5x5, 32)')\ndot.edge('C1', 'P1', label='MaxPool\\n(2x2)')\ndot.edge('P1', 'C2', label='Conv\\n(5x5, 64)')\ndot.edge('C2', 'P2', label='MaxPool\\n(2x2)')\ndot.edge('P2', 'F', label='Flatten')\ndot.edge('F', 'O', label='Dense')\n\n# Render the graph\ndot",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/graphviz.html#advanced",
    "href": "Display/graphviz.html#advanced",
    "title": "Graphviz",
    "section": "Advanced",
    "text": "Advanced\n\n\nCode\nblack = '#000000'\n\ng = graph('A', filename='Data/plan', engine = 'dot')\n    \nwith g.subgraph(name='clusterBusiness') as v:\n    v.attr(label='Business/Marketing/Finance', shape = 'doublecircle', fillcolor=g.primary, fontcolor=g.fifth)\n    v.attr('node', shape = 'box', fillcolor=g.secondary, fontcolor=g.fifth, penwidth = '0')\n    v.node('Drone', 'Drone')\n    v.node('Laser', 'Laser')\n\n    \nwith g.subgraph(name='clusterIntern') as b:\n    b.attr(label='Intership', shape = 'doublecircle', fillcolor=g.primary, fontcolor=g.fifth)\n    b.attr('node', shape = 'box', fillcolor=g.secondary, fontcolor=g.fifth)\n    b.node('phisaver', 'Phisaver')\n    \n\ng.node('Project',\n        '''&lt;&lt;TABLE BORDER=\"0\" CELLBORDER=\"0\" CELLSPACING=\"10\" CELLPADDING=\"10\" STYLE = \"rounded\"&gt;\n          &lt;TR&gt;&lt;TD PORT=\"f\" BORDER=\"0\" STYLE = \"rounded\" WIDTH=\"100\" &gt;Project&lt;/TD&gt;&lt;/TR&gt;\n          &lt;TR&gt;&lt;TD PORT=\"InfoAI\" STYLE = \"rounded\" BGCOLOR=\"#fcbf49\" &gt;Information AI&lt;/TD&gt;&lt;/TR&gt;\n          &lt;TR&gt;&lt;TD PORT=\"3D\" STYLE = \"rounded\" BGCOLOR=\"#fcbf49\" &gt;3D vision- modeling AI&lt;/TD&gt;&lt;/TR&gt;\n          &lt;TR&gt;&lt;TD PORT=\"stocks\" STYLE = \"rounded\" BGCOLOR=\"#fcbf49\" &gt;Trading Algo&lt;/TD&gt;&lt;/TR&gt;\n        &lt;/TABLE&gt;&gt;''',\n        fillcolor=g.primary,\n        penwidth = '0')\n\n\ng.edge('FASTAI:e', 'Thesis:w')\ng.edge('Thesis:e', 'Project:3D:w')\n\n\ng.edge('phisaver:e', 'Flutter:w')\ng.edge('phisaver:e', 'Forecasting:w')\ng.edge('phisaver:e', 'ML:w')\n\ng.edge('Forecasting:e', 'Project:stocks:w')\ng.edge('Flutter:e', 'Project:3D:w')\ng.edge('Flutter:e', 'Thesis:w')\n\ng.edge('ML:e', 'Project:w')\n\n\ng.edge('Laser:e','Project:w')\ng.edge('Laser:e', 'Manufacturer:w')\n\ng.edge('Drone:e','Project:w')\ng.edge('Drone:e', 'Drone:w')\ng.edge('Drone:e', 'Manufacturer:w')\n\n\n\ng.render(format='svg', cleanup=False)\n\n\ng",
    "crumbs": [
      "Blog",
      "Display",
      "Graphviz"
    ]
  },
  {
    "objectID": "Display/bokeh.html",
    "href": "Display/bokeh.html",
    "title": "Bokeh",
    "section": "",
    "text": "pip install bokeh\npip list | grep bokeh\n\nbokeh                     3.6.3\nNote: you may need to restart the kernel to use updated packages.",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#initialize-bokeh-for-notebook",
    "href": "Display/bokeh.html#initialize-bokeh-for-notebook",
    "title": "Bokeh",
    "section": "Initialize bokeh for Notebook",
    "text": "Initialize bokeh for Notebook\n\nfrom bokeh.io import output_notebook\n\n\noutput_notebook()\n\n    \n    \n        \n        Loading BokehJS ...",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#simple-line-graph",
    "href": "Display/bokeh.html#simple-line-graph",
    "title": "Bokeh",
    "section": "Simple line graph",
    "text": "Simple line graph\n\nfrom bokeh.plotting import figure, show\n\n# prepare some data\nx = [1, 2, 3, 4, 5]\ny = [6, 7, 2, 4, 5]\n\n# create a new plot with a title and axis labels\np = figure(title=\"Simple line example\", x_axis_label='x', y_axis_label='y')\n\n\n# add a line renderer with legend and line thickness to the plot\np.line(x, y, legend_label=\"Temp.\", line_width=2)\n\n# show the results\nshow(p)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#multiple-line-graphs",
    "href": "Display/bokeh.html#multiple-line-graphs",
    "title": "Bokeh",
    "section": "Multiple Line graphs",
    "text": "Multiple Line graphs\n\nfrom bokeh.plotting import figure, show\n\n# prepare some data\nx = [1, 2, 3, 4, 5]\ny1 = [6, 7, 2, 4, 5]\ny2 = [2, 3, 4, 5, 6]\ny3 = [4, 5, 5, 7, 2]\n\n# create a new plot with a title and axis labels\np = figure(title=\"Multiple line example\", x_axis_label=\"x\", y_axis_label=\"y\")\n\n# add multiple renderers\np.line(x, y1, legend_label=\"Temp.\", color=\"blue\", line_width=2)\np.line(x, y2, legend_label=\"Rate\", color=\"red\", line_width=2)\np.line(x, y3, legend_label=\"Objects\", color=\"green\", line_width=2)\n\n# show the results\nshow(p)\n\n\n  \n\n\n\n\n\n\nfrom bokeh.plotting import figure, output_file, save\n\n# prepare some data\nx = [1, 2, 3, 4, 5]\ny = [4, 5, 5, 7, 2]\n\n# set output to static HTML file\noutput_file(filename=\"custom_filename.html\", title=\"Static HTML file\")\n\n# create a new plot with a specific size\np = figure(sizing_mode=\"stretch_width\", max_width=500, height=250)\n\n# add a scatter renderer\np.scatter(x, y, fill_color=\"red\", size=15)\n\n# save the results to a file\nsave(p)\n\n'/home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/MLtools/nbs/custom_filename.html'",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#multiple-types",
    "href": "Display/bokeh.html#multiple-types",
    "title": "Bokeh",
    "section": "Multiple types",
    "text": "Multiple types\n\nfrom bokeh.plotting import figure, show\n\n# prepare some data\nx = [1, 2, 3, 4, 5]\ny1 = [6, 7, 2, 4, 5]\ny2 = [2, 3, 4, 5, 6]\ny3 = [4, 5, 5, 7, 2]\n\n# create a new plot with a title and axis labels\np = figure(title=\"Multiple glyphs example\", x_axis_label=\"x\", y_axis_label=\"y\")\n\n# add multiple renderers\np.line(x, y1, legend_label=\"Temp.\", color=\"blue\", line_width=2)\np.vbar(x=x, top=y2, legend_label=\"Rate\", width=0.5, bottom=0, color=\"red\")\np.scatter(x, y3, legend_label=\"Objects\", color=\"yellow\", size=12)\n\n# show the results\nshow(p)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#legends-text-and-annotations",
    "href": "Display/bokeh.html#legends-text-and-annotations",
    "title": "Bokeh",
    "section": "Legends, text and annotations",
    "text": "Legends, text and annotations\n\nimport random\nfrom bokeh.io import curdoc\nfrom bokeh.models import BoxAnnotation\nfrom bokeh.plotting import figure, show\n# apply theme to current document\ncurdoc().theme = \"dark_minimal\"\n\n# generate some data (1-50 for x, random values for y)\nx = list(range(0, 51))\ny = random.sample(range(0, 100), 51)\n\n# create new plot\np = figure(title=\"Box annotation example\")\n\n# add line renderer\nline = p.line(x, y, line_color=\"#000000\", line_width=2)\n\n# add box annotations\nlow_box = BoxAnnotation(top=20, fill_alpha=0.2, fill_color=\"#F0E442\")\nmid_box = BoxAnnotation(bottom=20, top=80, fill_alpha=0.2, fill_color=\"#009E73\")\nhigh_box = BoxAnnotation(bottom=80, fill_alpha=0.2, fill_color=\"#F0E442\")\n\n# add boxes to existing figure\np.add_layout(low_box)\np.add_layout(mid_box)\np.add_layout(high_box)\n\n# show the results\nshow(p)\n\n\n  \n\n\n\n\n\n\nimport random\nfrom datetime import datetime, timedelta\n\nfrom bokeh.models import DatetimeTickFormatter, NumeralTickFormatter\nfrom bokeh.plotting import figure, show\n\n# generate list of dates (today's date in subsequent weeks)\ndates = [(datetime.now() + timedelta(day * 7)) for day in range(0, 26)]\n\n# generate 25 random data points\ny = random.sample(range(0, 100), 26)\n\n# create new plot\np = figure(\n    title=\"datetime axis example\",\n    x_axis_type=\"datetime\",\n    sizing_mode=\"stretch_width\",\n    max_width=500,\n    height=250,\n)\n\n# add renderers\np.scatter(dates, y, size=8)\np.line(dates, y, color=\"navy\", line_width=1)\n\n# format axes ticks\np.yaxis[0].formatter = NumeralTickFormatter(format=\"$0.00\")\np.xaxis[0].formatter = DatetimeTickFormatter(months=\"%b %Y\")\n\n# show the results\nshow(p)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#vectorizing-colors-and-sizes",
    "href": "Display/bokeh.html#vectorizing-colors-and-sizes",
    "title": "Bokeh",
    "section": "Vectorizing colors and sizes",
    "text": "Vectorizing colors and sizes\n\nimport numpy as np\n\nfrom bokeh.plotting import figure, show\n\n# generate some data\nN = 1000\nx = np.random.random(size=N) * 100\ny = np.random.random(size=N) * 100\n\n# generate radii and colors based on data\nradii = y / 100 * 2\ncolors = [f\"#{255:02x}{int((value * 255) / 100):02x}{255:02x}\" for value in y]\n\n# create a new plot with a specific size\np = figure(\n    title=\"Vectorized colors and radii example\",\n    sizing_mode=\"stretch_width\",\n    max_width=500,\n    height=250,\n)\n\n# add circle renderer\np.circle(\n    x,\n    y,\n    radius=radii,\n    fill_color=colors,\n    fill_alpha=0.6,\n    line_color=\"lightgrey\",\n)\n\n# show the results\nshow(p)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#combining-plots",
    "href": "Display/bokeh.html#combining-plots",
    "title": "Bokeh",
    "section": "Combining plots",
    "text": "Combining plots\n\nfrom bokeh.layouts import row\nfrom bokeh.plotting import figure, show\n\n# prepare some data\nx = list(range(11))\ny0 = x\ny1 = [10 - i for i in x]\ny2 = [abs(i - 5) for i in x]\n\n# create three plots with one renderer each\ns1 = figure(width=250, height=250, background_fill_color=\"#fafafa\")\ns1.scatter(x, y0, marker=\"circle\", size=12, color=\"#53777a\", alpha=0.8)\n\ns2 = figure(width=250, height=250, background_fill_color=\"#fafafa\")\ns2.scatter(x, y1, marker=\"triangle\", size=12, color=\"#c02942\", alpha=0.8)\n\ns3 = figure(width=250, height=250, background_fill_color=\"#fafafa\")\ns3.scatter(x, y2, marker=\"square\", size=12, color=\"#d95b43\", alpha=0.8)\n\n# put the results in a row that automatically adjusts\n# to the browser window's width\nshow(row(children=[s1, s2, s3], sizing_mode=\"scale_width\"))",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#using-widgets",
    "href": "Display/bokeh.html#using-widgets",
    "title": "Bokeh",
    "section": "Using widgets",
    "text": "Using widgets\n\nfrom bokeh.layouts import layout\nfrom bokeh.models import Div, RangeSlider, Spinner\nfrom bokeh.plotting import figure, show\n\n# prepare some data\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\ny = [4, 5, 5, 7, 2, 6, 4, 9, 1, 3]\n\n# create plot with circle glyphs\np = figure(x_range=(1, 9), width=500, height=250)\npoints = p.scatter(x=x, y=y, size=30, fill_color=\"#21a7df\")\n\n# set up textarea (div)\ndiv = Div(\n    text=\"\"\"\n          &lt;p&gt;Select the circle's size using this control element:&lt;/p&gt;\n          \"\"\",\n    width=200,\n    height=30,\n)\n\n# set up spinner\nspinner = Spinner(\n    title=\"Circle size\",\n    low=0,\n    high=60,\n    step=5,\n    value=points.glyph.size,\n    width=200,\n)\nspinner.js_link(\"value\", points.glyph, \"size\")\n\n# set up RangeSlider\nrange_slider = RangeSlider(\n    title=\"Adjust x-axis range\",\n    start=0,\n    end=10,\n    step=1,\n    value=(p.x_range.start, p.x_range.end),\n)\nrange_slider.js_link(\"value\", p.x_range, \"start\", attr_selector=0)\nrange_slider.js_link(\"value\", p.x_range, \"end\", attr_selector=1)\n\n# create layout\nlayout = layout(\n    [\n        [div, spinner],\n        [range_slider],\n        [p],\n    ],\n)\n\n# show result\nshow(layout)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "Display/bokeh.html#example",
    "href": "Display/bokeh.html#example",
    "title": "Bokeh",
    "section": "Example",
    "text": "Example\n\nfrom math import pi\n\nimport pandas as pd\n\nfrom bokeh.palettes import Category20c\nfrom bokeh.plotting import figure, show\nfrom bokeh.transform import cumsum\n\nx = {\n    'United States': 157,\n    'United Kingdom': 93,\n    'Japan': 89,\n    'China': 63,\n    'Germany': 44,\n    'India': 42,\n    'Italy': 40,\n    'Australia': 35,\n    'Brazil': 32,\n    'France': 31,\n    'Taiwan': 31,\n    'Spain': 29,\n}\n\ndata = pd.Series(x).reset_index(name='value').rename(columns={'index': 'country'})\ndata['angle'] = data['value']/data['value'].sum() * 2*pi\ndata['color'] = Category20c[len(x)]\n\np = figure(height=350, title=\"Pie Chart\", toolbar_location=None,\n           tools=\"hover\", tooltips=\"@country: @value\", x_range=(-0.5, 1.0))\n\np.wedge(x=0, y=1, radius=0.4,\n        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n        line_color=\"white\", fill_color='color', legend_field='country', source=data)\n\np.axis.axis_label = None\np.axis.visible = False\np.grid.grid_line_color = None\n\nshow(p)\n\n\n  \n\n\n\n\n\n\nimport bokeh\n\n\nbokeh.sampledata.download()\n\nUsing data directory: /home/ben/.bokeh/data\nSkipping 'CGM.csv' (checksum match)\nSkipping 'US_Counties.zip' (checksum match)\nSkipping 'us_cities.json' (checksum match)\nSkipping 'unemployment09.csv' (checksum match)\nSkipping 'AAPL.csv' (checksum match)\nSkipping 'FB.csv' (checksum match)\nSkipping 'GOOG.csv' (checksum match)\nSkipping 'IBM.csv' (checksum match)\nSkipping 'MSFT.csv' (checksum match)\nSkipping 'WPP2012_SA_DB03_POPULATION_QUINQUENNIAL.zip' (checksum match)\nSkipping 'gapminder_fertility.csv' (checksum match)\nSkipping 'gapminder_population.csv' (checksum match)\nSkipping 'gapminder_life_expectancy.csv' (checksum match)\nSkipping 'gapminder_regions.csv' (checksum match)\nSkipping 'world_cities.zip' (checksum match)\nSkipping 'airports.json' (checksum match)\nSkipping 'movies.db.zip' (checksum match)\nSkipping 'airports.csv' (checksum match)\nSkipping 'routes.csv' (checksum match)\nSkipping 'haarcascade_frontalface_default.xml' (checksum match)\nSkipping 'SampleSuperstore.csv.zip' (checksum match)\nSkipping 'emissions.csv' (checksum match)\nSkipping 'titanic_all.csv' (checksum match)\n\n\n\nimport pandas as pd\n\nfrom bokeh.palettes import Spectral4\nfrom bokeh.plotting import figure, show\nfrom bokeh.sampledata.stocks import AAPL, GOOG, IBM, MSFT\n\np = figure(width=800, height=250, x_axis_type=\"datetime\")\np.title.text = 'Click on legend entries to hide the corresponding lines'\n\nfor data, name, color in zip([AAPL, IBM, MSFT, GOOG], [\"AAPL\", \"IBM\", \"MSFT\", \"GOOG\"], Spectral4):\n    df = pd.DataFrame(data)\n    df['date'] = pd.to_datetime(df['date'])\n    p.line(df['date'], df['close'], line_width=2, color=color, alpha=0.8, legend_label=name)\n\np.legend.location = \"top_left\"\np.legend.click_policy=\"mute\"\n\nshow(p)",
    "crumbs": [
      "Blog",
      "Display",
      "Bokeh"
    ]
  },
  {
    "objectID": "numpy.html",
    "href": "numpy.html",
    "title": "Numpy",
    "section": "",
    "text": "!pip list | grep numpy\n\nnumpy                         1.23.5\n\n\n\nimport numpy as np",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#import-numpy",
    "href": "numpy.html#import-numpy",
    "title": "Numpy",
    "section": "",
    "text": "!pip list | grep numpy\n\nnumpy                         1.23.5\n\n\n\nimport numpy as np",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#creating-numpy-arrays",
    "href": "numpy.html#creating-numpy-arrays",
    "title": "Numpy",
    "section": "Creating Numpy Arrays",
    "text": "Creating Numpy Arrays\n\nPython sequences to NumPy Arrays\n\na1D = np.array([1, 2, 3, 4])\n\na2D = np.array([[1, 2], [3, 4]])\n\na3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\na1D, a2D, a3D\n\n(array([1, 2, 3, 4]),\n array([[1, 2],\n        [3, 4]]),\n array([[[1, 2],\n         [3, 4]],\n \n        [[5, 6],\n         [7, 8]]]))\n\n\n\na = np.array([127, 128, 129], dtype=np.int8)\na\n\narray([ 127, -128, -127], dtype=int8)\n\n\n\n\nIntrinsic NumPy array creation functions\n\nnp.arange(10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\nnp.arange(2, 10, dtype=float)\n\narray([2., 3., 4., 5., 6., 7., 8., 9.])\n\n\n\nnp.arange(2, 3, 0.1)\n\narray([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9])\n\n\n\nnp.linspace(1., 4., 6)\n\narray([1. , 1.6, 2.2, 2.8, 3.4, 4. ])\n\n\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.eye(3, 5)\n\narray([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\nnp.diag([1, 2, 3])\n\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])\n\n\n\nnp.diag([1, 2, 3], 1)\n\narray([[0, 1, 0, 0],\n       [0, 0, 2, 0],\n       [0, 0, 0, 3],\n       [0, 0, 0, 0]])\n\n\n\nnp.vander(np.linspace(0, 2, 5), 3)\n\narray([[0.  , 0.  , 1.  ],\n       [0.25, 0.5 , 1.  ],\n       [1.  , 1.  , 1.  ],\n       [2.25, 1.5 , 1.  ],\n       [4.  , 2.  , 1.  ]])\n\n\n\nnp.zeros((2, 3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((2, 3, 2))\n\narray([[[1., 1.],\n        [1., 1.],\n        [1., 1.]],\n\n       [[1., 1.],\n        [1., 1.],\n        [1., 1.]]])\n\n\n\nfrom numpy.random import default_rng\ndefault_rng(42).random((2,3))\n\narray([[0.77395605, 0.43887844, 0.85859792],\n       [0.69736803, 0.09417735, 0.97562235]])\n\n\n\nnp.indices((3,3))\n\narray([[[0, 0, 0],\n        [1, 1, 1],\n        [2, 2, 2]],\n\n       [[0, 1, 2],\n        [0, 1, 2],\n        [0, 1, 2]]])\n\n\n\n\nReplicating, joining, or mutating existing arrays\n\na = np.array([1, 2, 3, 4, 5, 6])\n\nb = a[:2]\n\nb += 1\n\nprint('a =', a, '; b =', b)\n\na = [2 3 3 4 5 6] ; b = [2 3]\n\n\n\na = np.array([1, 2, 3, 4])\n\nb = a[:2].copy()\n\nb += 1\n\nprint('a = ', a, 'b = ', b)\n\na =  [1 2 3 4] b =  [2 3]\n\n\n\nA = np.ones((2, 2))\n\nB = np.eye(2, 2)\n\nC = np.zeros((2, 2))\n\nD = np.diag((-3, -4))\n\nnp.block([[A, B], [C, D]])\n\narray([[ 1.,  1.,  1.,  0.],\n       [ 1.,  1.,  0.,  1.],\n       [ 0.,  0., -3.,  0.],\n       [ 0.,  0.,  0., -4.]])",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#indexing",
    "href": "numpy.html#indexing",
    "title": "Numpy",
    "section": "Indexing",
    "text": "Indexing\n\nBasic indexing\n\nx = np.arange(10)\nx,x[2]\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 2)\n\n\n\nx[-2]\n\n8\n\n\n\nx.shape = (2, 5)  # now x is 2-dimensional\n\nx, x[1, 3]\n\n(array([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]]),\n 8)\n\n\n\nx[0], x[0][2]\n\n(array([0, 1, 2, 3, 4]), 2)\n\n\n\nSlicing and striding\n\nx = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nx[1:7:2]\n\narray([1, 3, 5])\n\n\n\nx[-2:10]\n\narray([8, 9])\n\n\n\nx[-3:3:-1]\n\narray([7, 6, 5, 4])\n\n\n\nx[5:]\n\narray([5, 6, 7, 8, 9])\n\n\n\nx = np.array([[[1],[2],[3]], [[4],[5],[6]]])\n\nx.shape, x[1:2]\n\n((2, 3, 1),\n array([[[4],\n         [5],\n         [6]]]))\n\n\n\n\nDimensional indexing tools\n\nx[..., 0]\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nx[:, :, 0]\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nx[:, np.newaxis, :, :].shape\n\n(2, 1, 3, 1)\n\n\n\nx[:, None, :, :].shape\n\n(2, 1, 3, 1)\n\n\n\nx = np.arange(5)\nx\n\narray([0, 1, 2, 3, 4])\n\n\n\nx[:, np.newaxis] + x[np.newaxis, :]\n\narray([[0, 1, 2, 3, 4],\n       [1, 2, 3, 4, 5],\n       [2, 3, 4, 5, 6],\n       [3, 4, 5, 6, 7],\n       [4, 5, 6, 7, 8]])\n\n\n\n\n\nAdvanced indexing\n\nx = np.arange(10, 1, -1)\n\n\nx[np.array([3, 3, 1, 8])]\n\narray([7, 7, 9, 2])\n\n\n\nx = np.array([[1, 2], [3, 4], [5, 6]])\n\n\ny = np.arange(35).reshape(5, 7)\n\ny\n\narray([[ 0,  1,  2,  3,  4,  5,  6],\n       [ 7,  8,  9, 10, 11, 12, 13],\n       [14, 15, 16, 17, 18, 19, 20],\n       [21, 22, 23, 24, 25, 26, 27],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\ny[np.array([0, 2, 4]), np.array([0, 1, 2])]\n\narray([ 0, 15, 30])\n\n\n\ny[np.array([0, 2, 4]), 1]\n\narray([ 1, 15, 29])\n\n\n\ny[np.array([0, 2, 4])]\n\narray([[ 0,  1,  2,  3,  4,  5,  6],\n       [14, 15, 16, 17, 18, 19, 20],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\nx = np.array([[1, 2], [3, 4], [5, 6]])\n\nx[[0, 1, 2], [0, 1, 0]]\n\narray([1, 4, 5])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nrows = np.array([[0, 0],\n\n                 [3, 3]], dtype=np.intp)\n\ncolumns = np.array([[0, 2],\n\n                    [0, 2]], dtype=np.intp)\n\nx[rows, columns]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nrows = np.array([0, 3], dtype=np.intp)\n\ncolumns = np.array([0, 2], dtype=np.intp)\n\nrows[:, np.newaxis]\n\narray([[0],\n       [3]])\n\n\n\nx[rows[:, np.newaxis], columns]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nx[np.ix_(rows, columns)]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nx = np.array([[1., 2.], [np.nan, 3.], [np.nan, np.nan]])\n\nx[~np.isnan(x)]\n\narray([1., 2., 3.])\n\n\n\nx = np.array([1., -1., -2., 3])\n\nx[x &lt; 0] += 20\n\nx\n\narray([ 1., 19., 18.,  3.])\n\n\n\nx = np.arange(35).reshape(5, 7)\n\nb = x &gt; 20\nb\n\narray([[False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [ True,  True,  True,  True,  True,  True,  True],\n       [ True,  True,  True,  True,  True,  True,  True]])\n\n\n\nb[:, 5]\n\narray([False, False, False,  True,  True])\n\n\n\nx[b[:, 5]]\n\narray([[21, 22, 23, 24, 25, 26, 27],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nrows = (x.sum(-1) % 2) == 0\n\nrows\n\narray([False,  True, False,  True])\n\n\n\ncolumns = [0, 2]\n\nx[np.ix_(rows, columns)]\n\narray([[ 3,  5],\n       [ 9, 11]])\n\n\n\nrows = rows.nonzero()[0]\n\nx[rows[:, np.newaxis], columns]\n\narray([[ 3,  5],\n       [ 9, 11]])\n\n\n\nx = np.arange(30).reshape(2, 3, 5)\n\nx\n\narray([[[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14]],\n\n       [[15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24],\n        [25, 26, 27, 28, 29]]])\n\n\n\nb = np.array([[True, True, False], [False, True, True]])\n\nx[b]\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [20, 21, 22, 23, 24],\n       [25, 26, 27, 28, 29]])\n\n\n\ny = np.arange(35).reshape(5,7)\n\ny[np.array([0, 2, 4]), 1:3]\n\narray([[ 1,  2],\n       [15, 16],\n       [29, 30]])\n\n\n\ny[:, 1:3][np.array([0, 2, 4]), :]\n\narray([[ 1,  2],\n       [15, 16],\n       [29, 30]])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nx[1:2, 1:3]\n\narray([[4, 5]])\n\n\n\nx[1:2, [1, 2]]\n\narray([[4, 5]])\n\n\n\nx = np.arange(35).reshape(5, 7)\n\nb = x &gt; 20\n\nb\n\narray([[False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [ True,  True,  True,  True,  True,  True,  True],\n       [ True,  True,  True,  True,  True,  True,  True]])\n\n\n\nx[b[:, 5], 1:3]\n\narray([[22, 23],\n       [29, 30]])\n\n\n\n\nField Access\n\nx = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\nx\n\narray([[(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]),\n        (0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])],\n       [(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]),\n        (0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])]],\n      dtype=[('a', '&lt;i4'), ('b', '&lt;f8', (3, 3))])\n\n\n\nx['a'].shape, x['b'].shape\n\n((2, 2), (2, 2, 3, 3))\n\n\n\nx['a'].dtype, x['b'].dtype\n\n(dtype('int32'), dtype('float64'))\n\n\n\n\nAssigning values to indexed arrays\n\nx = np.arange(10)\n\nx[2:7] = 1\n\n\nx[2:7] = np.arange(5)\n\n\nx[1] = 1.2\n\nx[1]\n\n1\n\n\n\nx = np.arange(0, 50, 10)\nx\n\narray([ 0, 10, 20, 30, 40])\n\n\n\nx[np.array([1, 1, 3, 1])] += 1\n\nx\n\narray([ 0, 11, 20, 31, 40])\n\n\n\n\nDealing with variable numbers of indices within programs\n\nz = np.arange(81).reshape(3, 3, 3, 3)\n\nindices = (1, 1, 1, 1)\n\nz[indices]\n\n40\n\n\n\nindices = (1, 1, 1, slice(0, 2))  # same as [1, 1, 1, 0:2]\n\nz[indices]\n\narray([39, 40])\n\n\n\nindices = (1, Ellipsis, 1)  # same as [1, ..., 1]\n\nz[indices]\n\narray([[28, 31, 34],\n       [37, 40, 43],\n       [46, 49, 52]])\n\n\n\nz[[1, 1, 1, 1]]  # produces a large array\n\narray([[[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]]])\n\n\n\nz[(1, 1, 1, 1)]  # returns a single value\n\n40",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#io-with-numpy",
    "href": "numpy.html#io-with-numpy",
    "title": "Numpy",
    "section": "I/O with Numpy",
    "text": "I/O with Numpy\n\nSplitting the lines into columns\n\nimport numpy as np\n\nfrom io import StringIO\n\n\ndata = u\"1, 2, 3\\n4, 5, 6\"\n\nnp.genfromtxt(StringIO(data), delimiter=\",\")\n\narray([[1., 2., 3.],\n       [4., 5., 6.]])\n\n\n\ndata = u\"  1  2  3\\n  4  5 67\\n890123  4\"\n\nnp.genfromtxt(StringIO(data), delimiter=3)\n\narray([[  1.,   2.,   3.],\n       [  4.,   5.,  67.],\n       [890., 123.,   4.]])\n\n\n\ndata = u\"123456789\\n   4  7 9\\n   4567 9\"\n\nnp.genfromtxt(StringIO(data), delimiter=(4, 3, 2))\n\narray([[1234.,  567.,   89.],\n       [   4.,    7.,    9.],\n       [   4.,  567.,    9.]])\n\n\n\ndata = u\"1, abc , 2\\n 3, xxx, 4\"\n\n# Without autostrip\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\")\n\narray([['1', ' abc ', ' 2'],\n       ['3', ' xxx', ' 4']], dtype='&lt;U5')\n\n\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\", autostrip=True)\n\narray([['1', 'abc', '2'],\n       ['3', 'xxx', '4']], dtype='&lt;U5')\n\n\n\ndata = u\"\"\"#\n\n# Skip me !\n\n# Skip me too !\n\n1, 2\n\n3, 4\n\n5, 6 #This is the third line of the data\n\n7, 8\n\n# And here comes the last line\n\n9, 0\n\n\"\"\"\n\nnp.genfromtxt(StringIO(data), comments=\"#\", delimiter=\",\")\n\narray([[1., 2.],\n       [3., 4.],\n       [5., 6.],\n       [7., 8.],\n       [9., 0.]])\n\n\n\n\nSkipping lines and choosing columns\n\ndata = u\"\\n\".join(str(i) for i in range(10))\n\nnp.genfromtxt(StringIO(data),)\n\narray([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n\n\n\nnp.genfromtxt(StringIO(data),\n              skip_header=3, skip_footer=5)\n\narray([3., 4.])\n\n\n\ndata = u\"1 2 3\\n4 5 6\"\n\nnp.genfromtxt(StringIO(data), usecols=(0, -1))\n\narray([[1., 3.],\n       [4., 6.]])\n\n\n\ndata = u\"1 2 3\\n4 5 6\"\n\nnp.genfromtxt(StringIO(data),\n              names=\"a, b, c\", usecols=(\"a\", \"c\"))\n\narray([(1., 3.), (4., 6.)], dtype=[('a', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\nnp.genfromtxt(StringIO(data),\n              names=\"a, b, c\", usecols=(\"a, c\"))\n\narray([(1., 3.), (4., 6.)], dtype=[('a', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\n\nChoosing the data type\nThe main way to control how the sequences of strings we have read from the file are converted to other types is to set the dtype argument. Acceptable values for this argument are:\n\na single type, such as dtype=float. The output will be 2D with the given dtype, unless a name has been associated with each column with the use of the names argument (see below). Note that dtype=float is the default for genfromtxt.\na sequence of types, such as dtype=(int, float, float).\na comma-separated string, such as dtype=“i4,f8,|U3”.\na dictionary with two keys ‘names’ and ‘formats’.\na sequence of tuples (name, type), such as dtype=[(‘A’, int), (‘B’, float)].\nan existing numpy.dtype object.\nthe special value None. In that case, the type of the columns will be determined from the data itself (see below).\n\nIn all the cases but the first one, the output will be a 1D array with a structured dtype. This dtype has as many fields as items in the sequence. The field names are defined with the names keyword.\nWhen dtype=None, the type of each column is determined iteratively from its data. We start by checking whether a string can be converted to a boolean (that is, if the string matches true or false in lower cases); then whether it can be converted to an integer, then to a float, then to a complex and eventually to a string.\nThe option dtype=None is provided for convenience. However, it is significantly slower than setting the dtype explicitly.\n\n\nSetting the names\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\na = np.genfromtxt(data, dtype=[(_, int) for _ in \"abc\"])\na\n\narray([(1, 2, 3), (4, 5, 6)],\n      dtype=[('a', '&lt;i8'), ('b', '&lt;i8'), ('c', '&lt;i8')])\n\n\n\na['a']\n\narray([1, 4])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, names=\"A, B, C\")\n\narray([(1., 2., 3.), (4., 5., 6.)],\n      dtype=[('A', '&lt;f8'), ('B', '&lt;f8'), ('C', '&lt;f8')])\n\n\n\ndata = StringIO(\"So it goes\\n#a b c\\n1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, skip_header=1, names=True)\n\narray([(1., 2., 3.), (4., 5., 6.)],\n      dtype=[('a', '&lt;f8'), ('b', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nndtype=[('a',int), ('b', float), ('c', int)]\n\nnames = [\"A\", \"B\", \"C\"]\n\nnp.genfromtxt(data, names=names, dtype=ndtype)\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('A', '&lt;i8'), ('B', '&lt;f8'), ('C', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int))\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8'), ('f2', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int), names=\"a\")\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('a', '&lt;i8'), ('f0', '&lt;f8'), ('f1', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int), defaultfmt=\"var_%02i\")\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('var_00', '&lt;i8'), ('var_01', '&lt;f8'), ('var_02', '&lt;i8')])\n\n\n\n\nTweaking the conversion\n\nconvertfunc = lambda x: float(x.strip(b\"%\"))/100.\n\ndata = u\"1, 2.3%, 45.\\n6, 78.9%, 0\"\n\nnames = (\"i\", \"p\", \"n\")\n\n# General case .....\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names)\n\narray([(1., nan, 45.), (6., nan,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\n# Converted case ...\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n              converters={1: convertfunc})\n\narray([(1., 0.023, 45.), (6., 0.789,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\n# Using a name for the converter ...\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n              converters={\"p\": convertfunc})\n\narray([(1., 0.023, 45.), (6., 0.789,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\ndata = u\"1, , 3\\n 4, 5, 6\"\n\nconvert = lambda x: float(x.strip() or -999)\n\nnp.genfromtxt(StringIO(data), delimiter=\",\",\n\n              converters={1: convert})\n\narray([[   1., -999.,    3.],\n       [   4.,    5.,    6.]])\n\n\n\ndata = u\"N/A, 2, 3\\n4, ,???\"\n\nkwargs = dict(delimiter=\",\",\n\n              dtype=int,\n\n              names=\"a,b,c\",\n\n              missing_values={0:\"N/A\", 'b':\" \", 2:\"???\"},\n\n              filling_values={0:0, 'b':0, 2:-999})\n\nnp.genfromtxt(StringIO(data), **kwargs)\n\narray([(0, 2,    3), (4, 0, -999)],\n      dtype=[('a', '&lt;i8'), ('b', '&lt;i8'), ('c', '&lt;i8')])",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#data-types",
    "href": "numpy.html#data-types",
    "title": "Numpy",
    "section": "Data types",
    "text": "Data types\n\nArray types and conversions between types\n\n\n\n\n\n\n\n\nNumpy type\nC type\nDescription\n\n\n\n\nnumpy.bool_\nbool\nBoolean (True or False) stored as a byte\n\n\nnumpy.byte\nsigned char\nPlatform-defined\n\n\nnumpy.ubyte\nunsigned char\nPlatform-defined\n\n\nnumpy.short\nshort\nPlatform-defined\n\n\nnumpy.ushort\nunsigned short\nPlatform-defined\n\n\nnumpy.intc\nint\nPlatform-defined\n\n\nnumpy.uintc\nunsigned int\nPlatform-defined\n\n\nnumpy.int_\nlong\nPlatform-defined\n\n\nnumpy.uint\nunsigned long\nPlatform-defined\n\n\nnumpy.longlong\nlong long\nPlatform-defined\n\n\nnumpy.ulonglong\nunsigned long long\nPlatform-defined\n\n\nnumpy.half / numpy.float16\n\nHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\n\n\nnumpy.single\nfloat\nPlatform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa\n\n\nnumpy.double\ndouble\nPlatform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa.\n\n\nnumpy.longdouble\nlong double\nPlatform-defined extended-precision float\n\n\nnumpy.csingle\nfloat complex\nComplex number, represented by two single-precision floats (real and imaginary components)\n\n\nnumpy.cdouble\ndouble complex\nComplex number, represented by two double-precision floats (real and imaginary components).\n\n\nnumpy.clongdouble\nlong double complex\nComplex number, represented by two extended-precision floats (real and imaginary components).\n\n\n\n\nx = np.float32(1.0)\n\nx\n\n1.0\n\n\n\ny = np.int_([1,2,4])\n\ny\n\narray([1, 2, 4])\n\n\n\nz = np.arange(3, dtype=np.uint8)\n\nz\n\narray([0, 1, 2], dtype=uint8)\n\n\n\nnp.array([1, 2, 3], dtype='f')\n\narray([1., 2., 3.], dtype=float32)\n\n\n\nz.astype(float)\n\narray([0., 1., 2.])\n\n\n\nnp.int8(z)\n\narray([0, 1, 2], dtype=int8)\n\n\n\nz.dtype\n\ndtype('uint8')\n\n\n\nd = np.dtype(int)\n\nd\n\ndtype('int64')\n\n\n\nnp.issubdtype(d, np.integer)\n\nTrue\n\n\n\nnp.issubdtype(d, np.floating)\n\nFalse\n\n\n\nnp.power(100, 8, dtype=np.int64)\n\n10000000000000000\n\n\n\nnp.power(100, 8, dtype=np.int32)\n\n1874919424\n\n\n\nnp.iinfo(int) # Bounds of the default integer on this system.\n\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n\n\n\nnp.iinfo(np.int32) # Bounds of a 32-bit integer\n\niinfo(min=-2147483648, max=2147483647, dtype=int32)\n\n\n\nnp.iinfo(np.int64) # Bounds of a 64-bit integer\n\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n\n\n\nnp.power(100, 100, dtype=np.int64) # Incorrect even with 64-bit int\n\n0\n\n\n\nnp.power(100, 100, dtype=np.float64)\n\n1e+200",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#broadcastable-arrays",
    "href": "numpy.html#broadcastable-arrays",
    "title": "Numpy",
    "section": "Broadcastable arrays",
    "text": "Broadcastable arrays\n\na = np.array([1.0, 2.0, 3.0])\n\nb = np.array([2.0, 2.0, 2.0])\n\na * b\n\narray([2., 4., 6.])\n\n\n\na = np.array([1.0, 2.0, 3.0])\n\nb = 2.0\n\na * b\n\narray([2., 4., 6.])\n\n\n\na = np.array([[ 0.0,  0.0,  0.0],\n\n              [10.0, 10.0, 10.0],\n\n              [20.0, 20.0, 20.0],\n\n              [30.0, 30.0, 30.0]])\n\nb = np.array([1.0, 2.0, 3.0])\n\na + b\n\narray([[ 1.,  2.,  3.],\n       [11., 12., 13.],\n       [21., 22., 23.],\n       [31., 32., 33.]])\n\n\n\na = np.array([0.0, 10.0, 20.0, 30.0])\n\nb = np.array([1.0, 2.0, 3.0])\n\na[:, np.newaxis] + b\n\narray([[ 1.,  2.,  3.],\n       [11., 12., 13.],\n       [21., 22., 23.],\n       [31., 32., 33.]])\n\n\n\nfrom numpy import array, argmin, sqrt, sum\nobservation = array([111.0, 188.0])\n\ncodes = array([[102.0, 203.0],\n\n               [132.0, 193.0],\n\n               [45.0, 155.0],\n\n               [57.0, 173.0]])\n\ndiff = codes - observation    # the broadcast happens here\n\ndist = sqrt(sum(diff**2,axis=-1))\n\nargmin(dist)\n\n0",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#copies-and-views",
    "href": "numpy.html#copies-and-views",
    "title": "Numpy",
    "section": "Copies and views",
    "text": "Copies and views\n\nIndexing operations\n\nx = np.arange(10)\n\nx\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\ny = x[1:3]  # creates a view\n\ny\n\narray([1, 2])\n\n\n\nx[1:3] = [10, 11]\nx\n\narray([ 0, 10, 11,  3,  4,  5,  6,  7,  8,  9])\n\n\n\ny\n\narray([10, 11])\n\n\n\nx = np.arange(9).reshape(3, 3)\nx\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny = x[[1, 2]]\ny\n\narray([[3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny.base is None\n\nTrue\n\n\n\nx[[1, 2]] = [[10, 11, 12], [13, 14, 15]]\nx\n\narray([[ 0,  1,  2],\n       [10, 11, 12],\n       [13, 14, 15]])\n\n\n\ny\n\narray([[3, 4, 5],\n       [6, 7, 8]])\n\n\n\nx = np.ones((2, 3))\n\ny = x.T  # makes the array non-contiguous\n\ny\n\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.]])\n\n\n\nHow to tell if the array is a view or a copy\n\nx = np.arange(9)\n\nx\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n\n\ny = x.reshape(3, 3)\n\ny\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny.base  # .reshape() creates a view\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n\n\nz = y[[2, 1]]\nz\n\narray([[6, 7, 8],\n       [3, 4, 5]])\n\n\n\nz.base is None  # advanced indexing creates a copy\n\nTrue",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#structured-arrays",
    "href": "numpy.html#structured-arrays",
    "title": "Numpy",
    "section": "Structured arrays",
    "text": "Structured arrays\n\nx = np.array([('Rex', 9, 81.0), ('Fido', 3, 27.0)],\n             dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])\nx\n\narray([('Rex', 9, 81.), ('Fido', 3, 27.)],\n      dtype=[('name', '&lt;U10'), ('age', '&lt;i4'), ('weight', '&lt;f4')])\n\n\n\nx[1]\n\n('Fido', 3, 27.)\n\n\n\nx['age']\n\narray([9, 3], dtype=int32)\n\n\n\nx['age'] = 5\n\n\nx\n\narray([('Rex', 5, 81.), ('Fido', 5, 27.)],\n      dtype=[('name', '&lt;U10'), ('age', '&lt;i4'), ('weight', '&lt;f4')])\n\n\n\nnp.dtype([('x', 'f4'), ('y', np.float32), ('z', 'f4', (2, 2))])\n\ndtype([('x', '&lt;f4'), ('y', '&lt;f4'), ('z', '&lt;f4', (2, 2))])\n\n\n\nnp.dtype([('x', 'f4'), ('', 'i4'), ('z', 'i8')])\n\ndtype([('x', '&lt;f4'), ('f1', '&lt;i4'), ('z', '&lt;i8')])\n\n\n\nnp.dtype('i8, f4, S3')\n\ndtype([('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', 'S3')])\n\n\n\nnp.dtype('3int8, float32, (2, 3)float64')\n\ndtype([('f0', 'i1', (3,)), ('f1', '&lt;f4'), ('f2', '&lt;f8', (2, 3))])\n\n\n\nnp.dtype({'names': ['col1', 'col2'], 'formats': ['i4', 'f4']})\n\ndtype([('col1', '&lt;i4'), ('col2', '&lt;f4')])\n\n\n\nnp.dtype({'names': ['col1', 'col2'],\n          'formats': ['i4', 'f4'],\n          'offsets': [0, 4],\n          'itemsize': 12})\n\ndtype({'names': ['col1', 'col2'], 'formats': ['&lt;i4', '&lt;f4'], 'offsets': [0, 4], 'itemsize': 12})\n\n\n\nnp.dtype({'col1': ('i1', 0), 'col2': ('f4', 1)})\n\ndtype([('col1', 'i1'), ('col2', '&lt;f4')])\n\n\n\nManipulating and Displaying Structured Datatypes\n\nd = np.dtype([('x', 'i8'), ('y', 'f4')])\n\nd.names\n\n('x', 'y')\n\n\n\nd['x']\n\ndtype('int64')\n\n\n\nd.fields\n\nmappingproxy({'x': (dtype('int64'), 0), 'y': (dtype('float32'), 8)})\n\n\n\ndef print_offsets(d):\n\n    print(\"offsets:\", [d.fields[name][1] for name in d.names])\n\n    print(\"itemsize:\", d.itemsize)\n\n\nprint_offsets(np.dtype('u1, u1, i4, u1, i8, u2'))\n\noffsets: [0, 1, 2, 6, 7, 15]\nitemsize: 17\n\n\n\nprint_offsets(np.dtype('u1, u1, i4, u1, i8, u2', align=True))\n\noffsets: [0, 1, 4, 8, 16, 24]\nitemsize: 32\n\n\n\nnp.dtype([(('my title', 'name'), 'f4')])\n\ndtype([(('my title', 'name'), '&lt;f4')])\n\n\n\nnp.dtype({'name': ('i4', 0, 'my title')})\n\ndtype([(('my title', 'name'), '&lt;i4')])\n\n\n\nfor name in d.names:\n    print(d.fields[name][:2])\n\n(dtype('int64'), 0)\n(dtype('float32'), 8)\n\n\n\n\nIndexing and Assignment to Structured arrays\n\nx = np.array([(1, 2, 3), (4, 5, 6)], dtype='i8, f4, f8')\nx\n\narray([(1, 2., 3.), (4, 5., 6.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '&lt;f8')])\n\n\n\nx[1] = (7, 8, 9)\n\n\nx\n\narray([(1, 2., 3.), (7, 8., 9.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '&lt;f8')])\n\n\n\nx = np.zeros(2, dtype='i8, f4, ?, S1')\nx[:] = 3\nx\n\narray([(3, 3.,  True, b'3'), (3, 3.,  True, b'3')],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '?'), ('f3', 'S1')])\n\n\n\nx[:] = np.arange(2)\nx\n\narray([(0, 0., False, b'0'), (1, 1.,  True, b'1')],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '?'), ('f3', 'S1')])\n\n\n\na = np.zeros(3, dtype=[('a', 'i8'), ('b', 'f4'), ('c', 'S3')])\nb = np.ones(3, dtype=[('x', 'f4'), ('y', 'S3'), ('z', 'O')])\nb[:] = a\nb\n\narray([(0., b'0.0', b''), (0., b'0.0', b''), (0., b'0.0', b'')],\n      dtype=[('x', '&lt;f4'), ('y', 'S3'), ('z', 'O')])\n\n\n\nx = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\n\nx['foo']\n\narray([1, 3])\n\n\n\nx['foo'] = 10\n\nx\n\narray([(10, 2.), (10, 4.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\ny = x['bar']\n\ny[:] = 11\n\nx\n\narray([(10, 11.), (10, 11.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\ny.dtype, y.shape, y.strides\n\n(dtype('float32'), (2,), (12,))\n\n\n\nx = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\n\nx['a'].shape\n\n(2, 2)\n\n\n\nx['b'].shape\n\n(2, 2, 3, 3)\n\n\n\na = np.zeros(3, dtype=[('a', 'i4'), ('b', 'i4'), ('c', 'f4')])\n\na[['a', 'c']]\n\narray([(0, 0.), (0, 0.), (0, 0.)],\n      dtype={'names': ['a', 'c'], 'formats': ['&lt;i4', '&lt;f4'], 'offsets': [0, 8], 'itemsize': 12})\n\n\n\nfrom numpy.lib.recfunctions import repack_fields\n\nrepack_fields(a[['a', 'c']]).view('i8')  # supported in 1.16\n\narray([0, 0, 0])\n\n\n\nb = np.zeros(3, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])\n\nb[['x', 'z']].view('f4')\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n\n\n\nfrom numpy.lib.recfunctions import structured_to_unstructured\n\nstructured_to_unstructured(b[['x', 'z']])\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32)\n\n\n\na[['a', 'c']] = (2, 3)\n\na\n\narray([(2, 0, 3.), (2, 0, 3.), (2, 0, 3.)],\n      dtype=[('a', '&lt;i4'), ('b', '&lt;i4'), ('c', '&lt;f4')])\n\n\n\na[['a', 'c']] = a[['c', 'a']]\n\n\nx = np.array([(1, 2., 3.)], dtype='i, f, f')\n\nscalar = x[0]\n\nscalar\n\n(1, 2., 3.)\n\n\n\ntype(scalar)\n\nnumpy.void\n\n\n\nx = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\ns = x[0]\ns['bar'] = 100\nx\n\narray([(1, 100.), (3,   4.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\nscalar = np.array([(1, 2., 3.)], dtype='i, f, f')[0]\nscalar[0]\n\n1\n\n\n\nscalar[1] = 4\n\n\nscalar.item(), type(scalar.item())\n\n((1, 4.0, 3.0), tuple)\n\n\n\nStructure Comparison and Promotiona\n\na = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])\n\nb = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])\n\na == b\n\narray([ True, False])\n\n\n\na = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])\n\nb = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])\n\na == b\n\narray([ True, False])\n\n\n\nb = np.array([(1.0, 1), (2.5, 2)], dtype=[(\"a\", \"f4\"), (\"b\", \"i4\")])\n\na == b\n\narray([ True, False])\n\n\n\nnp.result_type(np.dtype(\"i,&gt;i\"))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')])\n\n\n\nnp.result_type(np.dtype(\"i,&gt;i\"), np.dtype(\"i,i\"))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')])\n\n\n\ndt = np.dtype(\"i1,V3,i4,V1\")[[\"f0\", \"f2\"]]\ndt\n\ndtype({'names': ['f0', 'f2'], 'formats': ['i1', '&lt;i4'], 'offsets': [0, 4], 'itemsize': 9})\n\n\n\nnp.result_type(dt)\n\ndtype([('f0', 'i1'), ('f2', '&lt;i4')])\n\n\n\ndt = np.dtype(\"i1,V3,i4,V1\", align=True)[[\"f0\", \"f2\"]]\n\ndt\n\ndtype({'names': ['f0', 'f2'], 'formats': ['i1', '&lt;i4'], 'offsets': [0, 4], 'itemsize': 12}, align=True)\n\n\n\nnp.result_type(dt)\n\ndtype([('f0', 'i1'), ('f2', '&lt;i4')], align=True)\n\n\n\nnp.result_type(dt).isalignedstruct\n\nTrue\n\n\n\nnp.result_type(np.dtype(\"i,i\"), np.dtype(\"i,i\", align=True))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')], align=True)\n\n\n\n\nRecord Arrays\n\nrecordarr = np.rec.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n                   dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'S10')])\n\n\nrecordarr.bar\n\narray([2., 3.], dtype=float32)\n\n\n\nrecordarr[1:2]\n\nrec.array([(2, 3., b'World')],\n          dtype=[('foo', '&lt;i4'), ('bar', '&lt;f4'), ('baz', 'S10')])\n\n\n\nrecordarr[1:2].foo\n\narray([2], dtype=int32)\n\n\n\nrecordarr.foo[1:2]\n\narray([2], dtype=int32)\n\n\n\nrecordarr[1].baz\n\nb'World'\n\n\n\narr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n            dtype=[('foo', 'i4'), ('bar', 'f4'), ('baz', 'S10')])\n\n\nrecordarr = np.rec.array(arr)\n\n\narr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n               dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'a10')])\n\n\nrecordarr = arr.view(dtype=np.dtype((np.record, arr.dtype)),\n\n                     type=np.recarray)\n\n\nrecordarr = arr.view(np.recarray)\n\nrecordarr.dtype\n\ndtype((numpy.record, [('foo', '&lt;i4'), ('bar', '&lt;f4'), ('baz', 'S10')]))\n\n\n\narr2 = recordarr.view(recordarr.dtype.fields or recordarr.dtype, np.ndarray)\n\n\nrecordarr = np.rec.array([('Hello', (1, 2)), (\"World\", (3, 4))],\n\n                dtype=[('foo', 'S6'),('bar', [('A', int), ('B', int)])])\n\n\ntype(recordarr.foo)\n\nnumpy.ndarray\n\n\n\ntype(recordarr.bar)\n\nnumpy.recarray\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nb = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)],\n\n             dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')])\n\n\nrfn.apply_along_fields(np.mean, b)\n\narray([ 2.66666667,  5.33333333,  8.66666667, 11.        ])\n\n\n\nrfn.apply_along_fields(np.mean, b[['x', 'z']])\n\narray([ 3. ,  5.5,  9. , 11. ])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, (2, 3.0)), (4, (5, 6.0))],\n\n  dtype=[('a', np.int64), ('b', [('ba', np.double), ('bb', np.int64)])])\n\n\nrfn.drop_fields(a, 'a')\n\narray([((2., 3),), ((5., 6),)],\n      dtype=[('b', [('ba', '&lt;f8'), ('bb', '&lt;i8')])])\n\n\n\nrfn.drop_fields(a, 'ba')\n\narray([(1, (3,)), (4, (6,))], dtype=[('a', '&lt;i8'), ('b', [('bb', '&lt;i8')])])\n\n\n\nrfn.drop_fields(a, ['ba', 'bb'])\n\narray([(1,), (4,)], dtype=[('a', '&lt;i8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype = [('a', int)]\n\na = np.ma.array([1, 1, 1, 2, 2, 3, 3],\n\n        mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype)\n\n\nrfn.find_duplicates(a, ignoremask=True, return_index=True)\n\n(masked_array(data=[(1,), (1,), (2,), (2,)],\n              mask=[(False,), (False,), (False,), (False,)],\n        fill_value=(999999,),\n             dtype=[('a', '&lt;i8')]),\n array([0, 1, 3, 4]))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype = np.dtype([('a', '&lt;i4'), ('b', [('ba', '&lt;f8'), ('bb', '&lt;i4')])])\n\nrfn.flatten_descr(ndtype)\n\n(('a', dtype('int32')), ('ba', dtype('float64')), ('bb', dtype('int32')))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype =  np.dtype([('A', int),\n\n                    ('B', [('BA', int),\n\n                           ('BB', [('BBA', int), ('BBB', int)])])])\n\nrfn.get_fieldstructure(ndtype)\n\n{'A': [],\n 'B': [],\n 'BA': ['B'],\n 'BB': ['B'],\n 'BBA': ['B', 'BB'],\n 'BBB': ['B', 'BB']}\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.get_names(np.empty((1,), dtype=[('A', int)]).dtype)\n\n('A',)\n\n\n\nrfn.get_names(np.empty((1,), dtype=[('A',int), ('B', float)]).dtype)\n\n('A', 'B')\n\n\n\nadtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])\n\nrfn.get_names(adtype)\n\n('a', ('b', ('ba', 'bb')))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.get_names_flat(np.empty((1,), dtype=[('A', int)]).dtype) is None\n\nFalse\n\n\n\nrfn.get_names_flat(np.empty((1,), dtype=[('A',int), ('B', str)]).dtype)\n\n('A', 'B')\n\n\n\nadtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])\n\nrfn.get_names_flat(adtype)\n\n('a', 'b', 'ba', 'bb')\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.merge_arrays((np.array([1, 2]), np.array([10., 20., 30.])))\n\narray([( 1, 10.), ( 2, 20.), (-1, 30.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nrfn.merge_arrays((np.array([1, 2], dtype=np.int64),\n\n        np.array([10., 20., 30.])), usemask=False)\n\narray([( 1, 10.), ( 2, 20.), (-1, 30.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nrfn.merge_arrays((np.array([1, 2]).view([('a', np.int64)]),\n\n              np.array([10., 20., 30.])),\n\n             usemask=False, asrecarray=True)\n\nrec.array([( 1, 10.), ( 2, 20.), (-1, 30.)],\n          dtype=[('a', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, 10.), (2, 20.)], dtype=[('A', np.int64), ('B', np.float64)])\n\nb = np.zeros((3,), dtype=a.dtype)\n\nrfn.recursive_fill_fields(a, b)\n\narray([(1, 10.), (2, 20.), (0,  0.)], dtype=[('A', '&lt;i8'), ('B', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, (2, [3.0, 30.])), (4, (5, [6.0, 60.]))],\n\n  dtype=[('a', int),('b', [('ba', float), ('bb', (float, 2))])])\n\n\nrfn.rename_fields(a, {'a':'A', 'bb':'BB'})\n\narray([(1, (2., [ 3., 30.])), (4, (5., [ 6., 60.]))],\n      dtype=[('A', '&lt;i8'), ('b', [('ba', '&lt;f8'), ('BB', '&lt;f8', (2,))])])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\ndef print_offsets(d):\n\n    print(\"offsets:\", [d.fields[name][1] for name in d.names])\n\n    print(\"itemsize:\", d.itemsize)\n\n\ndt = np.dtype('u1, &lt;i8, &lt;f8', align=True)\n\ndt\n\ndtype([('f0', 'u1'), ('f1', '&lt;i8'), ('f2', '&lt;f8')], align=True)\n\n\n\nprint_offsets(dt)\n\noffsets: [0, 8, 16]\nitemsize: 24\n\n\n\npacked_dt = rfn.repack_fields(dt)\n\npacked_dt\n\ndtype([('f0', 'u1'), ('f1', '&lt;i8'), ('f2', '&lt;f8')])\n\n\n\nprint_offsets(packed_dt)\n\noffsets: [0, 1, 9]\nitemsize: 17\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.ones(4, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')])\n\nrfn.require_fields(a, [('b', 'f4'), ('c', 'u1')])\n\narray([(1., 1), (1., 1), (1., 1), (1., 1)],\n      dtype=[('b', '&lt;f4'), ('c', 'u1')])\n\n\n\nrfn.require_fields(a, [('b', 'f4'), ('newf', 'u1')])\n\narray([(1., 0), (1., 0), (1., 0), (1., 0)],\n      dtype=[('b', '&lt;f4'), ('newf', 'u1')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nx = np.array([1, 2,])\n\nrfn.stack_arrays(x) is x\n\nTrue\n\n\n\nz = np.array([('A', 1), ('B', 2)], dtype=[('A', '|S3'), ('B', float)])\n\nzz = np.array([('a', 10., 100.), ('b', 20., 200.), ('c', 30., 300.)],\n\n  dtype=[('A', '|S3'), ('B', np.double), ('C', np.double)])\n\ntest = rfn.stack_arrays((z,zz))\n\ntest\n\nmasked_array(data=[(b'A', 1.0, --), (b'B', 2.0, --), (b'a', 10.0, 100.0),\n                   (b'b', 20.0, 200.0), (b'c', 30.0, 300.0)],\n             mask=[(False, False,  True), (False, False,  True),\n                   (False, False, False), (False, False, False),\n                   (False, False, False)],\n       fill_value=(b'N/A', 1.e+20, 1.e+20),\n            dtype=[('A', 'S3'), ('B', '&lt;f8'), ('C', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.zeros(4, dtype=[('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)])\n\na\n\narray([(0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.]),\n       (0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.])],\n      dtype=[('a', '&lt;i4'), ('b', [('f0', '&lt;f4'), ('f1', '&lt;u2')]), ('c', '&lt;f4', (2,))])\n\n\n\nrfn.structured_to_unstructured(a)\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n\n\n\nb = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)],\n\n             dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')])\n\n\nnp.mean(rfn.structured_to_unstructured(b[['x', 'z']]), axis=-1)\n\narray([ 3. ,  5.5,  9. , 11. ])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\ndt = np.dtype([('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)])\n\na = np.arange(20).reshape((4,5))\n\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19]])\n\n\n\nrfn.unstructured_to_structured(a, dt)\n\narray([( 0, ( 1.,  2), [ 3.,  4.]), ( 5, ( 6.,  7), [ 8.,  9.]),\n       (10, (11., 12), [13., 14.]), (15, (16., 17), [18., 19.])],\n      dtype=[('a', '&lt;i4'), ('b', [('f0', '&lt;f4'), ('f1', '&lt;u2')]), ('c', '&lt;f4', (2,))])",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#universal-functions",
    "href": "numpy.html#universal-functions",
    "title": "Numpy",
    "section": "Universal functions",
    "text": "Universal functions\n\nnp.array([0,2,3,4]) + np.array([1,1,-1,2])\n\narray([1, 3, 2, 6])\n\n\n\nx = np.arange(9).reshape(3,3)\n\nx\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\nnp.add.reduce(x, 1)\n\narray([ 3, 12, 21])\n\n\n\nnp.add.reduce(x, (0, 1))\n\n36\n\n\n\nx.dtype\n\ndtype('int64')\n\n\n\nnp.multiply.reduce(x, dtype=float)\n\narray([ 0., 28., 80.])\n\n\n\ny = np.zeros(3, dtype=int)\n\ny\n\narray([0, 0, 0])\n\n\n\nnp.multiply.reduce(x, dtype=float, out=y)\n\narray([ 0, 28, 80])\n\n\n\nmark = {False: ' -', True: ' Y'}\n\ndef print_table(ntypes):\n\n    print('X ' + ' '.join(ntypes))\n\n    for row in ntypes:\n\n        print(row, end='')\n\n        for col in ntypes:\n\n            print(mark[np.can_cast(row, col)], end='')\n\n        print()\n\n\nprint_table(np.typecodes['All'])\n\nX ? b h i l q p B H I L Q P e f d g F D G S U V O M m\n? Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\nb - Y Y Y Y Y Y - - - - - - Y Y Y Y Y Y Y Y Y Y Y - Y\nh - - Y Y Y Y Y - - - - - - - Y Y Y Y Y Y Y Y Y Y - Y\ni - - - Y Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nl - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nq - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\np - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nB - - Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\nH - - - Y Y Y Y - Y Y Y Y Y - Y Y Y Y Y Y Y Y Y Y - Y\nI - - - - Y Y Y - - Y Y Y Y - - Y Y - Y Y Y Y Y Y - Y\nL - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\nQ - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\nP - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\ne - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y Y - -\nf - - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y - -\nd - - - - - - - - - - - - - - - Y Y - Y Y Y Y Y Y - -\ng - - - - - - - - - - - - - - - - Y - - Y Y Y Y Y - -\nF - - - - - - - - - - - - - - - - - Y Y Y Y Y Y Y - -\nD - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y - -\nG - - - - - - - - - - - - - - - - - - - Y Y Y Y Y - -\nS - - - - - - - - - - - - - - - - - - - - Y Y Y Y - -\nU - - - - - - - - - - - - - - - - - - - - - Y Y Y - -\nV - - - - - - - - - - - - - - - - - - - - - - Y Y - -\nO - - - - - - - - - - - - - - - - - - - - - - - Y - -\nM - - - - - - - - - - - - - - - - - - - - - - Y Y Y -\nm - - - - - - - - - - - - - - - - - - - - - - Y Y - Y",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "numpy.html#np.fft",
    "href": "numpy.html#np.fft",
    "title": "Numpy",
    "section": "np.fft",
    "text": "np.fft\n\nimport matplotlib.pyplot as plt\n\nt = np.arange(256)\n\nsp = np.fft.fft(np.sin(t))\n\nfreq = np.fft.fftfreq(t.shape[-1])\n\nplt.plot(freq, sp.real, freq, sp.imag)\n\n\n\n\n\n\n\n\n\nplt.show()\n\n\nimport matplotlib.pyplot as plt\n\nt = np.arange(400)\n\nn = np.zeros((400,), dtype=complex)\n\nn[40:60] = np.exp(1j*np.random.uniform(0, 2*np.pi, (20,)))\n\ns = np.fft.ifft(n)\n\nplt.plot(t, s.real, label='real')\n\n\n\n\n\n\n\n\n\nplt.plot(t, s.imag, '--', label='imaginary')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\na = np.mgrid[:5, :5][0]\n\nnp.fft.fft2(a)\n\narray([[ 50.  +0.j        ,   0.  +0.j        ,   0.  +0.j        ,\n          0.  +0.j        ,   0.  +0.j        ],\n       [-12.5+17.20477401j,   0.  +0.j        ,   0.  +0.j        ,\n          0.  +0.j        ,   0.  +0.j        ],\n       [-12.5 +4.0614962j ,   0.  +0.j        ,   0.  +0.j        ,\n          0.  +0.j        ,   0.  +0.j        ],\n       [-12.5 -4.0614962j ,   0.  +0.j        ,   0.  +0.j        ,\n          0.  +0.j        ,   0.  +0.j        ],\n       [-12.5-17.20477401j,   0.  +0.j        ,   0.  +0.j        ,\n          0.  +0.j        ,   0.  +0.j        ]])\n\n\n\na = 4 * np.eye(4)\n\nnp.fft.ifft2(a)\n\narray([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n       [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n       [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n       [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n\n\n\nimport matplotlib.pyplot as plt\n\n[X, Y] = np.meshgrid(2 * np.pi * np.arange(200) / 12,\n\n                     2 * np.pi * np.arange(200) / 34)\n\nS = np.sin(X) + np.cos(Y) + np.random.uniform(0, 1, X.shape)\n\nFS = np.fft.fftn(S)\n\nplt.imshow(np.log(np.abs(np.fft.fftshift(FS))**2))\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nn = np.zeros((200,200), dtype=complex)\n\nn[60:80, 20:40] = np.exp(1j*np.random.uniform(0, 2*np.pi, (20, 20)))\n\nim = np.fft.ifftn(n).real\n\nplt.imshow(im)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nnp.fft.fft([0, 1, 0, 0])\n\nnp.fft.rfft([0, 1, 0, 0])\n\narray([ 1.+0.j,  0.-1.j, -1.+0.j])\n\n\n\nnp.fft.ifft([1, -1j, -1, 1j])\n\nnp.fft.irfft([1, -1j, -1])\n\narray([0., 1., 0., 0.])\n\n\n\na = np.mgrid[:5, :5][0]\n\nnp.fft.rfft2(a)\n\narray([[ 50.  +0.j        ,   0.  +0.j        ,   0.  +0.j        ],\n       [-12.5+17.20477401j,   0.  +0.j        ,   0.  +0.j        ],\n       [-12.5 +4.0614962j ,   0.  +0.j        ,   0.  +0.j        ],\n       [-12.5 -4.0614962j ,   0.  +0.j        ,   0.  +0.j        ],\n       [-12.5-17.20477401j,   0.  +0.j        ,   0.  +0.j        ]])\n\n\n\na = np.mgrid[:5, :5][0]\n\nA = np.fft.rfft2(a)\n\nnp.fft.irfft2(A, s=a.shape)\n\narray([[0., 0., 0., 0., 0.],\n       [1., 1., 1., 1., 1.],\n       [2., 2., 2., 2., 2.],\n       [3., 3., 3., 3., 3.],\n       [4., 4., 4., 4., 4.]])\n\n\n\na = np.ones((2, 2, 2))\n\nnp.fft.rfftn(a)\n\narray([[[8.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j]],\n\n       [[0.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j]]])\n\n\n\nnp.fft.rfftn(a, axes=(2, 0))\n\narray([[[4.+0.j, 0.+0.j],\n        [4.+0.j, 0.+0.j]],\n\n       [[0.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j]]])\n\n\n\na = np.zeros((3, 2, 2))\n\na[0, 0, 0] = 3 * 2 * 2\n\nnp.fft.irfftn(a)\n\narray([[[1., 1.],\n        [1., 1.]],\n\n       [[1., 1.],\n        [1., 1.]],\n\n       [[1., 1.],\n        [1., 1.]]])\n\n\n\nsignal = np.array([1, 2, 3, 4, 3, 2])\n\nnp.fft.fft(signal)\n\narray([15.+0.j, -4.+0.j,  0.+0.j, -1.+0.j,  0.+0.j, -4.+0.j])\n\n\n\nnp.fft.hfft(signal[:4]) # Input first half of signal\n\narray([15., -4.,  0., -1.,  0., -4.])\n\n\n\nnp.fft.hfft(signal, 6)  # Input entire signal and truncate\n\narray([15., -4.,  0., -1.,  0., -4.])\n\n\n\nsignal = np.array([[1, 1.j], [-1.j, 2]])\n\nnp.conj(signal.T) - signal   # check Hermitian symmetry\n\narray([[ 0.-0.j, -0.+0.j],\n       [ 0.+0.j,  0.-0.j]])\n\n\n\nfreq_spectrum = np.fft.hfft(signal)\n\nfreq_spectrum\n\narray([[ 1.,  1.],\n       [ 2., -2.]])\n\n\n\nspectrum = np.array([ 15, -4, 0, -1, 0, -4])\n\nnp.fft.ifft(spectrum)\n\narray([1.+0.j, 2.+0.j, 3.+0.j, 4.+0.j, 3.+0.j, 2.+0.j])\n\n\n\nnp.fft.ihfft(spectrum)\n\narray([1.-0.00000000e+00j, 2.-3.70074342e-17j, 3.-3.70074342e-17j,\n       4.-0.00000000e+00j])\n\n\n\nsignal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float)\n\nfourier = np.fft.fft(signal)\n\nn = signal.size\n\ntimestep = 0.1\n\nfreq = np.fft.fftfreq(n, d=timestep)\n\nfreq\n\narray([ 0.  ,  1.25,  2.5 ,  3.75, -5.  , -3.75, -2.5 , -1.25])\n\n\n\nsignal = np.array([-2, 8, 6, 4, 1, 0, 3, 5, -3, 4], dtype=float)\n\nfourier = np.fft.rfft(signal)\n\nn = signal.size\n\nsample_rate = 100\n\nfreq = np.fft.fftfreq(n, d=1./sample_rate)\n\nfreq\n\narray([  0.,  10.,  20.,  30.,  40., -50., -40., -30., -20., -10.])\n\n\n\nfreq = np.fft.rfftfreq(n, d=1./sample_rate)\n\nfreq\n\narray([ 0., 10., 20., 30., 40., 50.])\n\n\n\nfreqs = np.fft.fftfreq(10, 0.1)\n\nfreqs\n\narray([ 0.,  1.,  2.,  3.,  4., -5., -4., -3., -2., -1.])\n\n\n\nnp.fft.fftshift(freqs)\n\narray([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n\n\n\nfreqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)\n\nfreqs\n\narray([[ 0.,  1.,  2.],\n       [ 3.,  4., -4.],\n       [-3., -2., -1.]])\n\n\n\nnp.fft.fftshift(freqs, axes=(1,))\n\narray([[ 2.,  0.,  1.],\n       [-4.,  3.,  4.],\n       [-1., -3., -2.]])\n\n\n\nfreqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)\n\nfreqs\n\narray([[ 0.,  1.,  2.],\n       [ 3.,  4., -4.],\n       [-3., -2., -1.]])\n\n\n\nnp.fft.ifftshift(np.fft.fftshift(freqs))\n\narray([[ 0.,  1.,  2.],\n       [ 3.,  4., -4.],\n       [-3., -2., -1.]])",
    "crumbs": [
      "Blog",
      "Numpy"
    ]
  },
  {
    "objectID": "dataclasses.html",
    "href": "dataclasses.html",
    "title": "Dataclass",
    "section": "",
    "text": "A dataclass is a Python class that is designed to store data without the need to write repetitive methods like constructors and comparison operators.\nBenefits: - Reduced Boilerplate: Automatically generates methods like __init__, __repr__, __eq__, etc. - Readability: Makes code more readable and concise, focusing on the data attributes. - Comparison Support: Automatically supports comparisons (==, !=, &lt;, &gt;, etc.). - Mutability: By default, the attributes in a dataclass are mutable, but you can set it to be immutable (frozen).",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#what-is-a-dataclass",
    "href": "dataclasses.html#what-is-a-dataclass",
    "title": "Dataclass",
    "section": "",
    "text": "A dataclass is a Python class that is designed to store data without the need to write repetitive methods like constructors and comparison operators.\nBenefits: - Reduced Boilerplate: Automatically generates methods like __init__, __repr__, __eq__, etc. - Readability: Makes code more readable and concise, focusing on the data attributes. - Comparison Support: Automatically supports comparisons (==, !=, &lt;, &gt;, etc.). - Mutability: By default, the attributes in a dataclass are mutable, but you can set it to be immutable (frozen).",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#creating-a-dataclass",
    "href": "dataclasses.html#creating-a-dataclass",
    "title": "Dataclass",
    "section": "2. Creating a dataclass",
    "text": "2. Creating a dataclass\n\nSyntax:\nTo define a dataclass, simply decorate a class with @dataclass from the dataclasses module.\nfrom dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\n\nExplanation:\n\n@dataclass: The decorator that tells Python to generate special methods for this class.\nAttributes: Define attributes (like name and age) just as you would for a regular class. These are the data that the class will hold.\n\n\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\n\n??dataclass\n\n\nSignature:\ndataclass(\n    cls=None,\n    /,\n    *,\n    init=True,\n    repr=True,\n    eq=True,\n    order=False,\n    unsafe_hash=False,\n    frozen=False,\n    match_args=True,\n    kw_only=False,\n    slots=False,\n    weakref_slot=False,\n)\nSource:   \ndef dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False,\n              unsafe_hash=False, frozen=False, match_args=True,\n              kw_only=False, slots=False, weakref_slot=False):\n    \"\"\"Add dunder methods based on the fields defined in the class.\n    Examines PEP 526 __annotations__ to determine fields.\n    If init is true, an __init__() method is added to the class. If repr\n    is true, a __repr__() method is added. If order is true, rich\n    comparison dunder methods are added. If unsafe_hash is true, a\n    __hash__() method is added. If frozen is true, fields may not be\n    assigned to after instance creation. If match_args is true, the\n    __match_args__ tuple is added. If kw_only is true, then by default\n    all fields are keyword-only. If slots is true, a new class with a\n    __slots__ attribute is returned.\n    \"\"\"\n    def wrap(cls):\n        return _process_class(cls, init, repr, eq, order, unsafe_hash,\n                              frozen, match_args, kw_only, slots,\n                              weakref_slot)\n    # See if we're being called as @dataclass or @dataclass().\n    if cls is None:\n        # We're called with parens.\n        return wrap\n    # We're called as @dataclass without parens.\n    return wrap(cls)\nFile:      ~/miniconda/envs/fast/lib/python3.12/dataclasses.py\nType:      function",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#automatic-method-generation",
    "href": "dataclasses.html#automatic-method-generation",
    "title": "Dataclass",
    "section": "3. Automatic Method Generation",
    "text": "3. Automatic Method Generation\nWhen you define a dataclass, Python automatically generates several special methods for you:\n\n1. __init__() (Constructor)\nperson = Person(name=\"John\", age=25)\nPython generates a constructor that initializes the fields automatically.\n\n\n2. __repr__() (Representation)\nprint(person)\nOutputs something like:\nPerson(name='John', age=25)\nThis makes the object easy to print and inspect.\n\n\n3. __eq__() (Equality Comparison)\nperson1 = Person(name=\"John\", age=25)\nperson2 = Person(name=\"John\", age=25)\nprint(person1 == person2)  # True\nThe class will have a method to compare two objects for equality.\n\n\n4. __hash__() (Hashing)\nBy default, a dataclass will generate a __hash__() method if all of its attributes are immutable. This makes it usable in sets or as keys in dictionaries.\n\n\n5. __lt__(), __le__(), __gt__(), __ge__() (Ordering)\nIf you specify order=True in the decorator, Python will automatically add comparison operators for &lt;, &lt;=, &gt;, and &gt;=.\n@dataclass(order=True)\nclass Person:\n    name: str\n    age: int\n\nperson1 = Person(name=\"John\", age=25)\nperson2 = Person(name=\"Jane\", age=30)\nprint(person1 &lt; person2)  # True, because 25 &lt; 30",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#mutable-vs-immutable-data",
    "href": "dataclasses.html#mutable-vs-immutable-data",
    "title": "Dataclass",
    "section": "4. Mutable vs Immutable Data",
    "text": "4. Mutable vs Immutable Data\nBy default, dataclass creates mutable objects. If you want to make a dataclass immutable, you can set frozen=True.\n@dataclass(frozen=True)\nclass Person:\n    name: str\n    age: int\nNow, trying to modify the attributes will raise an error:\nperson = Person(name=\"John\", age=25)\nperson.age = 30  # Raises dataclasses.FrozenInstanceError",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#default-values-and-default-factories",
    "href": "dataclasses.html#default-values-and-default-factories",
    "title": "Dataclass",
    "section": "5. Default Values and Default Factories",
    "text": "5. Default Values and Default Factories\n\nDefault Values\nYou can assign default values to attributes in a dataclass.\n@dataclass\nclass Person:\n    name: str\n    age: int = 30  # Default value\n\n\nDefault Factory for Mutable Default Values\nIf you need a mutable default value (e.g., a list), you should use field(default_factory=...) to avoid shared mutable default values across instances.\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass Person:\n    name: str\n    hobbies: list = field(default_factory=list)\n\nperson1 = Person(name=\"John\")\nperson1.hobbies.append(\"Reading\")\nprint(person1.hobbies)  # ['Reading']\n\nperson2 = Person(name=\"Jane\")\nprint(person2.hobbies)  # [] (separate list)",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#dataclass-fields-and-field",
    "href": "dataclasses.html#dataclass-fields-and-field",
    "title": "Dataclass",
    "section": "6. dataclass Fields and field()",
    "text": "6. dataclass Fields and field()\nThe field() function allows fine-grained control over the attributes of a dataclass:\n\ndefault: Assigns a default value (works for basic types).\ndefault_factory: Assigns a factory function to provide a default value for mutable types (e.g., list, dict).\nrepr: Controls whether the field is included in the __repr__ method.\ncompare: Controls whether the field is included in comparisons.\ninit: Determines whether the field is included in the __init__() method.\nhash: Specifies whether the field should be included in the __hash__ method.\n\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass Person:\n    name: str\n    age: int = field(default=30, repr=False)\n    hobbies: list = field(default_factory=list)\n\nperson = Person(name=\"Alice\")\nprint(person)  # Will not print age in the representation due to repr=False",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#methods-in-a-dataclass",
    "href": "dataclasses.html#methods-in-a-dataclass",
    "title": "Dataclass",
    "section": "7. Methods in a dataclass",
    "text": "7. Methods in a dataclass\nJust like regular classes, dataclasses can have methods. You can define methods within the class, and they will function just like methods in normal classes.\n@dataclass\nclass Person:\n    name: str\n    age: int\n    \n    def greet(self):\n        print(f\"Hello, my name is {self.name} and I am {self.age} years old.\")\n        \nperson = Person(name=\"Alice\", age=30)\nperson.greet()  # Output: Hello, my name is Alice and I am 30 years old.",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#using-dataclass-with-inheritance",
    "href": "dataclasses.html#using-dataclass-with-inheritance",
    "title": "Dataclass",
    "section": "8. Using dataclass with Inheritance",
    "text": "8. Using dataclass with Inheritance\nYou can also use inheritance with dataclass, just like any regular Python class.\n@dataclass\nclass Person:\n    name: str\n    age: int\n\n@dataclass\nclass Employee(Person):\n    job_title: str\n\nemployee = Employee(name=\"Alice\", age=30, job_title=\"Developer\")\nprint(employee)  # Person(name='Alice', age=30, job_title='Developer')",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#dataclass-in-practice",
    "href": "dataclasses.html#dataclass-in-practice",
    "title": "Dataclass",
    "section": "9. dataclass in Practice",
    "text": "9. dataclass in Practice\nDataclasses are especially useful when you want to structure and organize data, such as when you’re dealing with:\n\nRepresenting business entities (like Person, Product, etc.)\nData transfer objects (DTOs)\nWorking with structured data in APIs\nImplementing configuration models\nWorking with databases (e.g., ORM mapping)\n\nExample: Using dataclass for a simple address book:\n@dataclass\nclass Contact:\n    name: str\n    phone: str\n    email: str\n\nclass AddressBook:\n    def __init__(self):\n        self.contacts = []\n    \n    def add_contact(self, contact: Contact):\n        self.contacts.append(contact)\n    \n    def get_all_contacts(self):\n        return self.contacts\n\n# Usage\naddress_book = AddressBook()\ncontact1 = Contact(name=\"John\", phone=\"123-456\", email=\"john@example.com\")\naddress_book.add_contact(contact1)\nprint(address_book.get_all_contacts())  # [Contact(name='John', phone='123-456', email='john@example.com')]",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#best-practices-for-dataclass",
    "href": "dataclasses.html#best-practices-for-dataclass",
    "title": "Dataclass",
    "section": "10. Best Practices for dataclass",
    "text": "10. Best Practices for dataclass\n\nImmutable by default: If your data doesn’t need to change, consider making the dataclass immutable by using frozen=True.\nUse field(default_factory=...) for mutable fields: This avoids shared references between instances.\nLimit inheritance: While inheritance is supported, keep in mind that inheritance can complicate the dataclass logic if you don’t carefully manage field definitions.",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "dataclasses.html#conclusion",
    "href": "dataclasses.html#conclusion",
    "title": "Dataclass",
    "section": "Conclusion",
    "text": "Conclusion\nThe dataclass decorator is an incredibly useful feature in Python for simplifying the creation and management of classes that are primarily designed to hold data. With automatic generation of common methods like __init__, __repr__, __eq__, and more, it minimizes boilerplate code, improves code readability, and enhances productivity. It is commonly used for data transfer objects (DTOs), configurations, and simple models, making it an essential tool for Python developers.",
    "crumbs": [
      "Blog",
      "Dataclass"
    ]
  },
  {
    "objectID": "tqdm.html",
    "href": "tqdm.html",
    "title": "tqdm",
    "section": "",
    "text": "!pip list | grep tqdm\n\ntqdm                      4.66.4\nfrom tqdm import tqdm       # &lt;-- yes\nfrom time import sleep\nfrom tqdm import trange\nfor i in tqdm(range(100)):  # &lt;-- magic\n    sleep(0.01)\n\n100%|██████████████████████████████| 100/100 [00:01&lt;00:00, 96.61it/s]\nfor i in trange(100, desc=\"hello\", unit=\"epoch\"):\n    sleep(0.01)\n\nhello: 100%|████████████████████| 100/100 [00:01&lt;00:00, 95.96epoch/s]\nwith tqdm(total=100) as pbar:\n    for i in range(10):\n        sleep(0.1)\n        pbar.update(10)\n\n100%|██████████████████████████████| 100/100 [00:01&lt;00:00, 98.61it/s]\npbar = tqdm(total=100)\nfor i in range(10):\n    sleep(0.1)\n    pbar.update(10)\npbar.close()\n\n100%|██████████████████████████████| 100/100 [00:01&lt;00:00, 98.64it/s]",
    "crumbs": [
      "Blog",
      "tqdm"
    ]
  },
  {
    "objectID": "tqdm.html#using-with-map",
    "href": "tqdm.html#using-with-map",
    "title": "tqdm",
    "section": "Using with map",
    "text": "Using with map\n\nfrom tqdm import tqdm\nimport time\n\ndef process_item(item):\n    time.sleep(0.01)\n    return item * 2\n\nresults = list(tqdm(map(process_item, range(100)), total=len(range(100))))\n\n100%|██████████████████████████████| 100/100 [00:01&lt;00:00, 95.96it/s]",
    "crumbs": [
      "Blog",
      "tqdm"
    ]
  },
  {
    "objectID": "tqdm.html#using-with-nested-loops",
    "href": "tqdm.html#using-with-nested-loops",
    "title": "tqdm",
    "section": "Using with Nested Loops",
    "text": "Using with Nested Loops\n\nfrom tqdm.notebook import tqdm\nimport time\n\nfor i in tqdm(range(5), desc='Outer loop'):\n    for j in tqdm(range(100), desc='Inner loop', leave=False):\n        time.sleep(0.01)  # Simulate some work being done",
    "crumbs": [
      "Blog",
      "tqdm"
    ]
  },
  {
    "objectID": "tqdm.html#using-with-mulitprocessing",
    "href": "tqdm.html#using-with-mulitprocessing",
    "title": "tqdm",
    "section": "Using with Mulitprocessing",
    "text": "Using with Mulitprocessing\n\nfrom multiprocessing import Pool\nfrom tqdm import tqdm\nimport time\n\ndef process_item(item):\n    time.sleep(0.1)  # Simulate some work being done\n    return item * 2\n\nitems = range(100)\n\n# Create a Pool with progress bar\nwith Pool(processes=4) as pool:\n    results = list(tqdm(pool.imap(process_item, items), total=len(items)))\n\n100%|██████████████████████████████| 100/100 [00:02&lt;00:00, 39.69it/s]",
    "crumbs": [
      "Blog",
      "tqdm"
    ]
  },
  {
    "objectID": "tqdm.html#using-with-function",
    "href": "tqdm.html#using-with-function",
    "title": "tqdm",
    "section": "Using with Function",
    "text": "Using with Function\n\nfrom tqdm.notebook import tqdm\nimport time\n\ndef callback(pbar):\n    # Simulate work\n    pbar.update(1)\n\ndef inner_loop(new_bar):\n    for i in range(total):\n        time.sleep(0.01)\n        new_bar.update(1)\n    new_bar.close()\n        \n\ntotal = 10\npbar = tqdm(total=total)\n\n\nfor i in range(total):\n    new_bar = tqdm(total=total, leave=False)\n    inner_loop(new_bar)\n    callback(pbar)\n\npbar.close()",
    "crumbs": [
      "Blog",
      "tqdm"
    ]
  },
  {
    "objectID": "ruff.html",
    "href": "ruff.html",
    "title": "Ruff",
    "section": "",
    "text": "Purpose: Ruff is a Python linter designed to enforce style guides and find potential bugs in your code.\nPerformance: Written in Rust, Ruff is extremely fast and can lint large codebases quickly.\nFeatures: Combines functionality from multiple tools like flake8, pylint, mypy, and isort into one package.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#what-is-ruff",
    "href": "ruff.html#what-is-ruff",
    "title": "Ruff",
    "section": "",
    "text": "Purpose: Ruff is a Python linter designed to enforce style guides and find potential bugs in your code.\nPerformance: Written in Rust, Ruff is extremely fast and can lint large codebases quickly.\nFeatures: Combines functionality from multiple tools like flake8, pylint, mypy, and isort into one package.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#key-features",
    "href": "ruff.html#key-features",
    "title": "Ruff",
    "section": "2. Key Features",
    "text": "2. Key Features\n\nSpeed: Ruff is significantly faster than traditional Python linters due to its Rust implementation.\nAll-in-One: Supports rules from:\n\nflake8 (and many of its plugins)\nisort (import sorting)\npylint (selected rules)\nmypy (type-related linting)\n\nAuto-fixes: Ruff can automatically fix some linting issues.\nHighly Configurable: You can customize rules, exclude files, and more.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#installation",
    "href": "ruff.html#installation",
    "title": "Ruff",
    "section": "3. Installation",
    "text": "3. Installation\nInstall Ruff using pip:\npip install ruff\nAlternatively, install Ruff via pipx for isolated environments:\npipx install ruff",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#basic-usage",
    "href": "ruff.html#basic-usage",
    "title": "Ruff",
    "section": "4. Basic Usage",
    "text": "4. Basic Usage\nRun Ruff on your project directory:\nruff .\n\nCommon Commands:\n\nCheck for Issues:\nruff check .\nAuto-Fix Issues:\nruff check . --fix\nSpecify Files:\nruff path/to/file.py\nExclude Files or Directories:\nruff check . --exclude path/to/exclude",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#configuration",
    "href": "ruff.html#configuration",
    "title": "Ruff",
    "section": "5. Configuration",
    "text": "5. Configuration\nRuff can be configured using a pyproject.toml or .ruff.toml file in your project root. Example configuration:\n\npyproject.toml\n[tool.ruff]\nselect = [\"E\", \"F\", \"W\"]  # Enable specific linting rules\nignore = [\"W503\"]         # Ignore specific rules\nexclude = [\"migrations\", \"__init__.py\"]\nline-length = 88          # Set maximum line length\nfixable = [\"F401\", \"E501\"] # Rules that Ruff is allowed to fix\n\n\n.ruff.toml\nIf you prefer a standalone file:\n[tool.ruff]\nselect = [\"E\", \"F\", \"I\"]\nexclude = [\"migrations\"]\nline-length = 88",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#rules",
    "href": "ruff.html#rules",
    "title": "Ruff",
    "section": "6. Rules",
    "text": "6. Rules\nRuff supports a wide range of rules, including those from common tools:\n\nSupported Plugins:\n\nflake8 Rules:\n\nF (pyflakes)\nE/W (pep8)\nC90 (McCabe complexity)\n\nisort Rules:\n\nAutomatically sort and organize imports.\n\npylint Rules:\n\nIncludes rules like unused imports, variable naming, etc.\n\nmypy Rules:\n\nLinting based on type annotations.\n\n\nFor a full list of supported rules, refer to the official Ruff rules documentation.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#integrating-ruff-into-your-workflow",
    "href": "ruff.html#integrating-ruff-into-your-workflow",
    "title": "Ruff",
    "section": "7. Integrating Ruff into Your Workflow",
    "text": "7. Integrating Ruff into Your Workflow\n\na. Pre-commit Hooks\n\nInstall pre-commit:\npip install pre-commit\nAdd Ruff to your .pre-commit-config.yaml:\nrepos:\n  - repo: https://github.com/charliermarsh/ruff-pre-commit\n    rev: v0.0.289  # Use the latest version\n    hooks:\n      - id: ruff\n        args: [\"--fix\"]  # Optional: Auto-fix issues\nInstall the pre-commit hooks:\npre-commit install\n\nNow, Ruff will run automatically before every commit.\n\n\nb. CI/CD Integration\n\nGitHub Actions Example:\nname: Lint Code with Ruff\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.9\n      - name: Install Ruff\n        run: pip install ruff\n      - name: Run Ruff\n        run: ruff check .\n\n\n\nc. IDE Integration\n\nVS Code:\n\nInstall the Python extension.\nConfigure the Python linter in settings.json:\n\"python.linting.enabled\": true,\n\"python.linting.ruffEnabled\": true,\n\"python.linting.ruffPath\": \"ruff\",  // Path to the Ruff executable\n\"editor.codeActionsOnSave\": {\n    \"source.organizeImports\": true\n}\n\nPyCharm:\n\nInstall Ruff globally or in your virtual environment.\nConfigure a File Watcher for Ruff:\n\nGo to File &gt; Settings &gt; Tools &gt; File Watchers.\nAdd a new File Watcher for Ruff.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#comparing-ruff-to-other-tools",
    "href": "ruff.html#comparing-ruff-to-other-tools",
    "title": "Ruff",
    "section": "8. Comparing Ruff to Other Tools",
    "text": "8. Comparing Ruff to Other Tools\n\nAdvantages\n\nSpeed: Faster than Python-based linters like flake8 or pylint.\nMulti-tool Functionality: Combines features from multiple tools.\nAuto-fixing: Handles both linting and some formatting issues.\n\n\n\nDisadvantages\n\nRule Overlap: May conflict with Black, especially on formatting rules.\nLimited Plugins: Ruff doesn’t support every plugin that flake8 does (e.g., flake8-docstrings).",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#combining-ruff-with-other-tools",
    "href": "ruff.html#combining-ruff-with-other-tools",
    "title": "Ruff",
    "section": "9. Combining Ruff with Other Tools",
    "text": "9. Combining Ruff with Other Tools\n\nWith Black\n\nUse Black for formatting and Ruff for linting.\nConfigure Ruff to ignore Black’s formatting rules:\n[tool.ruff]\nselect = [\"F\", \"E\"]\nline-length = 88\n\n\n\nWith isort\n\nRuff includes import sorting rules similar to isort. Disable isort separately or rely on Ruff’s functionality.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ruff.html#faq",
    "href": "ruff.html#faq",
    "title": "Ruff",
    "section": "10. FAQ",
    "text": "10. FAQ\n\nQ1: Does Ruff replace Black?\nRuff can handle some formatting tasks, but it doesn’t fully replace Black. Use Ruff for linting and Black for formatting.\n\n\nQ2: Can Ruff work with type checking?\nYes, Ruff supports some type-related checks via mypy-like rules.\n\n\nQ3: How do I exclude specific directories or files?\nUse the --exclude flag or add exclusions in pyproject.toml.\n\n\nSummary of Commands\n\n\n\nCommand\nDescription\n\n\n\n\nruff .\nLint all files in the directory.\n\n\nruff check .\nCheck for issues without fixing.\n\n\nruff check . --fix\nFix issues automatically.\n\n\nruff --config pyproject.toml\nUse a specific config file.",
    "crumbs": [
      "Blog",
      "Ruff"
    ]
  },
  {
    "objectID": "ipywidget.html",
    "href": "ipywidget.html",
    "title": "Ipywidget",
    "section": "",
    "text": "!pip list | grep ipywidget\n\nipywidgets                8.1.3\nimport ipywidgets as widgets\nfrom ipywidgets import IntSlider\nfrom ipywidgets.embed import embed_minimal_html\n\nslider = IntSlider(value=40)\nembed_minimal_html('export.html', views=[slider], title='Widgets export')\nfrom IPython.display import IFrame\n\n# Specify the path to your HTML file\nhtml_file_path = 'export.html'\n\n# Display the HTML file in the notebook\nIFrame(src=html_file_path, width='100%', height=600)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#numeric-widgets",
    "href": "ipywidget.html#numeric-widgets",
    "title": "Ipywidget",
    "section": "Numeric widgets",
    "text": "Numeric widgets\nThere are many widgets distributed with ipywidgets that are designed to display numeric values. Widgets exist for displaying integers and floats, both bounded and unbounded. The integer widgets share a similar naming scheme to their floating point counterparts. By replacing Float with Int in the widget name, you can find the Integer equivalent.\n\nIntSlider\n\nThe slider is displayed with a specified, initial value. Lower and upper bounds are defined by min and max, and the value can be incremented according to the step parameter.\nThe slider’s label is defined by description parameter\nThe slider’s orientation is either ‘horizontal’ (default) or ‘vertical’\nreadout displays the current value of the slider next to it. The options are True (default) or False\n\nreadout_format specifies the format function used to represent slider value. The default is ‘.2f’\n\n\n\nwidgets.IntSlider(\n    value=7,\n    min=0,\n    max=10,\n    step=1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='d'\n)\n\n\n\n\n\n\nFloatSlider\n\nwidgets.FloatSlider(\n    value=7.5,\n    min=0,\n    max=10.0,\n    step=0.1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\n\n\n\nAn example of sliders displayed vertically.\n\nwidgets.FloatSlider(\n    value=7.5,\n    min=0,\n    max=10.0,\n    step=0.1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='vertical',\n    readout=True,\n    readout_format='.1f',\n)\n\n\n\n\n\n\nFloatLogSlider\nThe FloatLogSlider has a log scale, which makes it easy to have a slider that covers a wide range of positive magnitudes. The min and max refer to the minimum and maximum exponents of the base, and the value refers to the actual value of the slider.\n\nwidgets.FloatLogSlider(\n    value=10,\n    base=10,\n    min=-10, # max exponent of base\n    max=10, # min exponent of base\n    step=0.2, # exponent step\n    description='Log Slider'\n)\n\n\n\n\n\n\nIntRangeSlider\n\nwidgets.IntRangeSlider(\n    value=[5, 7],\n    min=0,\n    max=10,\n    step=1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='d',\n)\n\n\n\n\n\n\nFloatRangeSlider\n\nwidgets.FloatRangeSlider(\n    value=[5, 7.5],\n    min=0,\n    max=10.0,\n    step=0.1,\n    description='Test:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\n\n\n\n\n\nIntProgress\n\nwidgets.IntProgress(\n    value=7,\n    min=0,\n    max=10,\n    description='Loading:',\n    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n    style={'bar_color': 'maroon'},\n    orientation='horizontal'\n)\n\n\n\n\n\n\nFloatProgress\n\nwidgets.FloatProgress(\n    value=7.5,\n    min=0,\n    max=10.0,\n    description='Loading:',\n    bar_style='info',\n    style={'bar_color': '#ffff00'},\n    orientation='horizontal'\n)\n\n\n\n\nThe numerical text boxes that impose some limit on the data (range, integer-only) impose that restriction when the user presses enter.\n\n\nBoundedIntText\n\nwidgets.BoundedIntText(\n    value=7,\n    min=0,\n    max=10,\n    step=1,\n    description='Text:',\n    disabled=False\n)\n\n\n\n\n\n\nBoundedFloatText\n\nwidgets.BoundedFloatText(\n    value=7.5,\n    min=0,\n    max=10.0,\n    step=0.1,\n    description='Text:',\n    disabled=False\n)\n\n\n\n\n\n\nIntText\n\nwidgets.IntText(\n    value=7,\n    description='Any:',\n    disabled=False\n)\n\n\n\n\n\n\nFloatText\n\nwidgets.FloatText(\n    value=7.5,\n    description='Any:',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#boolean-widgets",
    "href": "ipywidget.html#boolean-widgets",
    "title": "Ipywidget",
    "section": "Boolean widgets",
    "text": "Boolean widgets\nThere are three widgets that are designed to display a boolean value.\n\nToggleButton\n\nwidgets.ToggleButton(\n    value=False,\n    description='Click me',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    tooltip='Description',\n    icon='check' # (FontAwesome names without the `fa-` prefix)\n)\n\n\n\n\n\n\nCheckbox\n\nvalue specifies the value of the checkbox\nindent parameter places an indented checkbox, aligned with other controls. Options are True (default) or False\n\n\nwidgets.Checkbox(\n    value=False,\n    description='Check me',\n    disabled=False,\n    indent=False\n)\n\n\n\n\n\n\nValid\nThe valid widget provides a read-only indicator.\n\nwidgets.Valid(\n    value=False,\n    description='Valid!',\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#selection-widgets",
    "href": "ipywidget.html#selection-widgets",
    "title": "Ipywidget",
    "section": "Selection widgets",
    "text": "Selection widgets\nThere are several widgets that can be used to display single selection lists, and two that can be used to select multiple values. All inherit from the same base class. You can specify the enumeration of selectable options by passing a list (options are either (label, value) pairs, or simply values for which the labels are derived by calling str).\n\nDropdown\n\nwidgets.Dropdown(\n    options=['1', '2', '3'],\n    value='2',\n    description='Number:',\n    disabled=False,\n)\n\n\n\n\nThe following is also valid, displaying the words 'One', 'Two', 'Three' as the dropdown choices but returning the values 1, 2, 3.\n\nwidgets.Dropdown(\n    options=[('One', 1), ('Two', 2), ('Three', 3)],\n    value=2,\n    description='Number:',\n)\n\n\n\n\n\n\nRadioButtons\n\nwidgets.RadioButtons(\n    options=['pepperoni', 'pineapple', 'anchovies'],\n#    value='pineapple', # Defaults to 'pineapple'\n#    layout={'width': 'max-content'}, # If the items' names are long\n    description='Pizza topping:',\n    disabled=False\n)\n\n\n\n\n\nWith dynamic layout and very long labels\n\nwidgets.Box(\n    [\n        widgets.Label(value='Pizza topping with a very long label:'), \n        widgets.RadioButtons(\n            options=[\n                'pepperoni', \n                'pineapple', \n                'anchovies', \n                'and the long name that will fit fine and the long name that will fit fine and the long name that will fit fine '\n            ],\n            layout={'width': 'max-content'}\n        )\n    ]\n)\n\n\n\n\n\n\n\nSelect\n\nwidgets.Select(\n    options=['Linux', 'Windows', 'macOS'],\n    value='macOS',\n    # rows=10,\n    description='OS:',\n    disabled=False\n)\n\n\n\n\n\n\nSelectionSlider\n\nwidgets.SelectionSlider(\n    options=['scrambled', 'sunny side up', 'poached', 'over easy'],\n    value='sunny side up',\n    description='I like my eggs ...',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True\n)\n\n\n\n\n\n\nSelectionRangeSlider\nThe value, index, and label keys are 2-tuples of the min and max values selected. The options must be nonempty.\n\nimport datetime\ndates = [datetime.date(2015, i, 1) for i in range(1, 13)]\noptions = [(i.strftime('%b'), i) for i in dates]\nwidgets.SelectionRangeSlider(\n    options=options,\n    index=(0, 11),\n    description='Months (2015)',\n    disabled=False\n)\n\n\n\n\n\n\nToggleButtons\n\nwidgets.ToggleButtons(\n    options=['Slow', 'Regular', 'Fast'],\n    description='Speed:',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n#     icons=['check'] * 3\n)\n\n\n\n\n\n\nSelectMultiple\nMultiple values can be selected with shift and/or ctrl (or command) pressed and mouse clicks or arrow keys.\n\nwidgets.SelectMultiple(\n    options=['Apples', 'Oranges', 'Pears'],\n    value=['Oranges'],\n    #rows=10,\n    description='Fruits',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#string-widgets",
    "href": "ipywidget.html#string-widgets",
    "title": "Ipywidget",
    "section": "String widgets",
    "text": "String widgets\nThere are several widgets that can be used to display a string value. The Text, Textarea, and Combobox widgets accept input. The HTML and HTMLMath widgets display a string as HTML (HTMLMath also renders math). The Label widget can be used to construct a custom control label.\n\nText\n\nwidgets.Text(\n    value='Hello World',\n    placeholder='Type something',\n    description='String:',\n    disabled=False   \n)\n\n\n\n\n\n\nTextarea\n\nwidgets.Textarea(\n    value='Hello World',\n    placeholder='Type something',\n    description='String:',\n    disabled=False\n)\n\n\n\n\n\n\nCombobox\n\nwidgets.Combobox(\n    # value='John',\n    placeholder='Choose Someone',\n    options=['Paul', 'John', 'George', 'Ringo'],\n    description='Combobox:',\n    ensure_option=True,\n    disabled=False\n)\n\n\n\n\n\n\nPassword\nThe Password widget hides user input on the screen. This widget is not a secure way to collect sensitive information because:\n\nThe contents of the Password widget are transmitted unencrypted.\nIf the widget state is saved in the notebook the contents of the Password widget is stored as plain text.\n\n\nwidgets.Password(\n    value='password',\n    placeholder='Enter password',\n    description='Password:',\n    disabled=False\n)\n\n\n\n\n\n\nLabel\nThe Label widget is useful if you need to build a custom description next to a control using similar styling to the built-in control descriptions.\n\nwidgets.HBox([widgets.Label(value=\"The $m$ in $E=mc^2$:\"), widgets.FloatSlider()])\n\n\n\n\n\n\nHTML\n\nwidgets.HTML(\n    value=\"Hello &lt;b&gt;World&lt;/b&gt;\",\n    placeholder='Some HTML',\n    description='Some HTML',\n)\n\n\n\n\n\n\nHTML Math\n\nwidgets.HTMLMath(\n    value=r\"Some math and &lt;i&gt;HTML&lt;/i&gt;: \\(x^2\\) and $$\\frac{x+1}{x-1}$$\",\n    placeholder='Some HTML',\n    description='Some HTML',\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#image",
    "href": "ipywidget.html#image",
    "title": "Ipywidget",
    "section": "Image",
    "text": "Image\n\nfile = open(\"bird.jpg\", \"rb\")\nimage = file.read()\nwidgets.Image(\n    value=image,\n    format='png',\n    width=300,\n    height=400,\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#button",
    "href": "ipywidget.html#button",
    "title": "Ipywidget",
    "section": "Button",
    "text": "Button\n\nbutton = widgets.Button(\n    description='Click me',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n    tooltip='Click me',\n    icon='check' # (FontAwesome names without the `fa-` prefix)\n)\nbutton\n\n\n\n\nThe icon attribute can be used to define an icon; see the fontawesome page for available icons. A callback function foo can be registered using button.on_click(foo). The function foo will be called when the button is clicked with the button instance as its single argument.",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#output",
    "href": "ipywidget.html#output",
    "title": "Ipywidget",
    "section": "Output",
    "text": "Output\nThe Output widget can capture and display stdout, stderr and rich output generated by IPython. For detailed documentation, see the output widget examples.",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#play-animation-widget",
    "href": "ipywidget.html#play-animation-widget",
    "title": "Ipywidget",
    "section": "Play (Animation) widget",
    "text": "Play (Animation) widget\nThe Play widget is useful to perform animations by iterating on a sequence of integers with a certain speed. The value of the slider below is linked to the player.\n\nplay = widgets.Play(\n    value=50,\n    min=0,\n    max=100,\n    step=1,\n    interval=500,\n    description=\"Press play\",\n    disabled=False\n)\nslider = widgets.IntSlider()\nwidgets.jslink((play, 'value'), (slider, 'value'))\nwidgets.HBox([play, slider])",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#tag-widgets",
    "href": "ipywidget.html#tag-widgets",
    "title": "Ipywidget",
    "section": "Tag widgets",
    "text": "Tag widgets\n\nTagsInput\nThe TagsInput widget is useful for selecting/creating a list of tags. You can drag and drop tags to reorder them, limit them to a set of allowed values, or even prevent making duplicate tags.\n\ntags = widgets.TagsInput(\n    value=['pizza', 'fries'],\n    allowed_tags=['pizza', 'fries', 'tomatoes', 'steak'],\n    allow_duplicates=False\n)\ntags\n\n\n\n\n\n\nColorsInput\nThe ColorsInput widget is useful for selecting/creating a list of colors. You can drag and drop colors to reorder them, limit them to a set of allowed values, or even prevent making duplicate colors.\n\ncolor_tags = widgets.ColorsInput(\n    value=['red', '#2f6d30'],\n    # allowed_tags=['red', 'blue', 'green'],\n    # allow_duplicates=False\n)\ncolor_tags\n\n\n\n\n\n\nFloat and Integer Input widgets\nThe FloatInputs and IntsInput widgets enable creating a list of float or integer numbers.\n\nfloatsinput = widgets.FloatsInput(\n    value=[1.3, 4.56, 78.90],\n    tag_style='info',\n    format = '.2f'\n)\nfloatsinput\n\n\n\n\n\nintsinput = widgets.IntsInput(\n    value=[1, 4, 3243],\n    min=0,\n    max=1000000,\n    format='$,d'\n)\nintsinput",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#date-picker",
    "href": "ipywidget.html#date-picker",
    "title": "Ipywidget",
    "section": "Date picker",
    "text": "Date picker\nFor a list of browsers that support the date picker widget, see the MDN article for the HTML date input field.\n\nwidgets.DatePicker(\n    description='Pick a Date',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#time-picker",
    "href": "ipywidget.html#time-picker",
    "title": "Ipywidget",
    "section": "Time picker",
    "text": "Time picker\nFor a list of browsers that support the time picker widget, see the MDN article for the HTML time input field.\n\nwidgets.TimePicker(\n    description='Pick a Time',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#datetime-picker",
    "href": "ipywidget.html#datetime-picker",
    "title": "Ipywidget",
    "section": "Datetime picker",
    "text": "Datetime picker\nFor a list of browsers that support the datetime picker widget, see the MDN article for the HTML datetime-local input field. For the browsers that do not support the datetime-local input, we try to fall back on displaying separate date and time inputs.\n\nTime zones\nThere are two points worth to note with regards to timezones for datetimes: - The browser always picks datetimes using its timezone. - The kernel always gets the datetimes in the default system timezone of the kernel (see https://docs.python.org/3/library/datetime.html#datetime.datetime.astimezone with None as the argument).\nThis means that if the kernel and browser have different timezones, the default string serialization of the timezones might differ, but they will still represent the same point in time.\n\nwidgets.DatetimePicker(\n    description='Pick a Time',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#naive-picker",
    "href": "ipywidget.html#naive-picker",
    "title": "Ipywidget",
    "section": "Naive picker",
    "text": "Naive picker\nIn some cases you might want to be able to pick naive datetime objects, i.e. timezone-unaware datetimes. To quote the Python 3 docs:\n\nNaive objects are easy to understand and to work with, at the cost of ignoring some aspects of reality.\n\nThis is useful if you need to compare the picked datetime to naive datetime objects, as Python will otherwise complain!\n\nwidgets.NaiveDatetimePicker(description='Pick a Time')",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#color-picker",
    "href": "ipywidget.html#color-picker",
    "title": "Ipywidget",
    "section": "Color picker",
    "text": "Color picker\n\nwidgets.ColorPicker(\n    concise=False,\n    description='Pick a color',\n    value='blue',\n    disabled=False\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#file-upload",
    "href": "ipywidget.html#file-upload",
    "title": "Ipywidget",
    "section": "File Upload",
    "text": "File Upload\nThe FileUpload allows to upload any type of file(s) into memory in the kernel.\n\nwidgets.FileUpload(\n    accept='',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n    multiple=False  # True to accept multiple files upload else False\n)\n\n\n\n\nThe upload widget exposes a value attribute that contains the files uploaded. The value attribute is a tuple with a dictionary for each uploaded file. For instance:\nuploader = widgets.FileUpload()\ndisplay(uploader)\n\n# upload something...\n\n# once a file is uploaded, use the `.value` attribute to retrieve the content:\nuploader.value\n#=&gt; (\n#=&gt;   {\n#=&gt;     'name': 'example.txt',\n#=&gt;     'type': 'text/plain',\n#=&gt;     'size': 36,\n#=&gt;     'last_modified': datetime.datetime(2020, 1, 9, 15, 58, 43, 321000, tzinfo=datetime.timezone.utc), \n#=&gt;     'content': &lt;memory at 0x10c1b37c8&gt;\n#=&gt;   },\n#=&gt; )\nEntries in the dictionary can be accessed either as items, as one would any dictionary, or as attributes:\nuploaded_file = uploader.value[0]\nuploaded_file[\"size\"]\n#=&gt; 36\nuploaded_file.size\n#=&gt; 36\nThe contents of the file uploaded are in the value of the content key. They are a memory view:\nuploaded_file.content\n#=&gt; &lt;memory at 0x10c1b37c8&gt;\nYou can extract the content to bytes:\nuploaded_file.content.tobytes()\n#=&gt; b'This is the content of example.txt.\\n'\nIf the file is a text file, you can get the contents as a string by decoding it:\nimport codecs\ncodecs.decode(uploaded_file.content, encoding=\"utf-8\")\n#=&gt; 'This is the content of example.txt.\\n'\nYou can save the uploaded file to the filesystem from the kernel:\nwith open(\"./saved-output.txt\", \"wb\") as fp:\n    fp.write(uploaded_file.content)\nTo convert the uploaded file into a Pandas dataframe, you can use a BytesIO object:\nimport io\nimport pandas as pd\npd.read_csv(io.BytesIO(uploaded_file.content))\nIf the uploaded file is an image, you can visualize it with an image widget:\nwidgets.Image(value=uploaded_file.content.tobytes())\n\nChanges in ipywidgets 8:\nThe FileUpload changed significantly in ipywidgets 8:\n\nThe .value traitlet is now a list of dictionaries, rather than a dictionary mapping the uploaded name to the content. To retrieve the original form, use {f[\"name\"]: f.content.tobytes() for f in uploader.value}.\nThe .data traitlet has been removed. To retrieve it, use [f.content.tobytes() for f in uploader.value].\nThe .metadata traitlet has been removed. To retrieve it, use [{k: v for k, v in f.items() if k != \"content\"} for f in w.value].\n\n\n\nWarning: When using the FileUpload Widget, uploaded file content might be saved in the notebook if widget state is saved.",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#controller",
    "href": "ipywidget.html#controller",
    "title": "Ipywidget",
    "section": "Controller",
    "text": "Controller\nThe Controller allows a game controller to be used as an input device.\n\nwidgets.Controller(\n    index=0,\n)",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "ipywidget.html#containerlayout-widgets",
    "href": "ipywidget.html#containerlayout-widgets",
    "title": "Ipywidget",
    "section": "Container/Layout widgets",
    "text": "Container/Layout widgets\nThese widgets are used to hold other widgets, called children. Each has a children property that may be set either when the widget is created or later.\n\nBox\n\nitems = [widgets.Label(str(i)) for i in range(4)]\nwidgets.Box(items)\n\n\n\n\n\n\nHBox\n\nitems = [widgets.Label(str(i)) for i in range(4)]\nwidgets.HBox(items)\n\n\n\n\n\n\nVBox\n\nitems = [widgets.Label(str(i)) for i in range(4)]\nleft_box = widgets.VBox([items[0], items[1]])\nright_box = widgets.VBox([items[2], items[3]])\nwidgets.HBox([left_box, right_box])\n\n\n\n\n\n\nGridBox\nThis box uses the HTML Grid specification to lay out its children in two dimensional grid. The example below lays out the 8 items inside in 3 columns and as many rows as needed to accommodate the items.\n\nitems = [widgets.Label(str(i)) for i in range(8)]\nwidgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(3, 100px)\"))\n\n\n\n\n\n\nAccordion\n\naccordion = widgets.Accordion(children=[widgets.IntSlider(), widgets.Text()], titles=('Slider', 'Text'))\naccordion\n\n\n\n\n\n\nTabs\nIn this example the children are set after the tab is created. Titles for the tabs are set in the same way they are for Accordion.\n\ntab_contents = ['P0', 'P1', 'P2', 'P3', 'P4']\nchildren = [widgets.Text(description=name) for name in tab_contents]\ntab = widgets.Tab()\ntab.children = children\ntab.titles = [str(i) for i in range(len(children))]\ntab\n\n\n\n\n\n\nStack\nThe Stack widget can have multiple children widgets as for Tab and Accordion, but only shows one at a time depending on the value of selected_index:\n\nbutton = widgets.Button(description='Click here')\nslider = widgets.IntSlider()\nstack = widgets.Stack([button, slider], selected_index=0)\nstack  # will show only the button\n\n\n\n\nThis can be used in combination with another selection-based widget to show different widgets depending on the selection:\n\ndropdown = widgets.Dropdown(options=['button', 'slider'])\nwidgets.jslink((dropdown, 'index'), (stack, 'selected_index'))\nwidgets.VBox([dropdown, stack])\n\n\n\n\n\n\nAccordion, Tab, and Stack use selected_index, not value\nUnlike the rest of the widgets discussed earlier, the container widgets Accordion and Tab update their selected_index attribute when the user changes which accordion or tab is selected. That means that you can both see what the user is doing and programmatically set what the user sees by setting the value of selected_index.\nSetting selected_index = None closes all of the accordions or deselects all tabs.\nIn the cells below try displaying or setting the selected_index of the tab and/or accordion.\n\ntab.selected_index = 3\n\n\naccordion.selected_index = None\n\n\n\nNesting tabs and accordions\nTabs and accordions can be nested as deeply as you want. If you have a few minutes, try nesting a few accordions or putting an accordion inside a tab or a tab inside an accordion.\nThe example below makes a couple of tabs with an accordion children in one of them\n\ntab_nest = widgets.Tab()\ntab_nest.children = [accordion, accordion]\ntab_nest.titles = ('An accordion', 'Copy of the accordion')\ntab_nest",
    "crumbs": [
      "Blog",
      "Ipywidget"
    ]
  },
  {
    "objectID": "Other/latexify.html",
    "href": "Other/latexify.html",
    "title": "Latexify examples",
    "section": "",
    "text": "See also the official documentation for more details.\nIf you have any questions, please ask it in the issue tracker.",
    "crumbs": [
      "Blog",
      "Other",
      "Latexify examples"
    ]
  },
  {
    "objectID": "Other/latexify.html#install-latexify",
    "href": "Other/latexify.html#install-latexify",
    "title": "Latexify examples",
    "section": "Install latexify",
    "text": "Install latexify",
    "crumbs": [
      "Blog",
      "Other",
      "Latexify examples"
    ]
  },
  {
    "objectID": "Other/latexify.html#import-latexify-into-your-code",
    "href": "Other/latexify.html#import-latexify-into-your-code",
    "title": "Latexify examples",
    "section": "Import latexify into your code",
    "text": "Import latexify into your code\n\nimport math  # Optional\nimport numpy as np  # Optional\nimport latexify\n\nlatexify.__version__\n\n'0.4.2'",
    "crumbs": [
      "Blog",
      "Other",
      "Latexify examples"
    ]
  },
  {
    "objectID": "Other/latexify.html#examples",
    "href": "Other/latexify.html#examples",
    "title": "Latexify examples",
    "section": "Examples",
    "text": "Examples\n\n@latexify.function\ndef solve(a, b, c):\n  return (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\n\nprint(solve(1, 4, 3))  # Invoking the function works as expected.\nprint(solve)  # Printing the function shows the underlying LaTeX source.\nsolve  # Displays the expression.\n\n# Writes the underlying LaTeX source into a file.\nwith open(\"compiled.tex\", \"w\") as fp:\n  print(solve, file=fp)\n\n-1.0\n\\mathrm{solve}(a, b, c) = \\frac{-b + \\sqrt{ b^{2} - 4 a c }}{2 a}\n\n\n\n# latexify.expression works similarly, but does not output the signature.\n@latexify.expression\ndef solve(a, b, c):\n  return (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\n\nsolve\n\n\\[ \\displaystyle \\frac{-b + \\sqrt{ b^{2} - 4 a c }}{2 a} \\]\n\n\n\n# latexify.get_latex obtains the underlying LaTeX expression directly.\ndef solve(a, b, c):\n  return (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\n\nlatexify.get_latex(solve)\n\n'\\\\mathrm{solve}(a, b, c) = \\\\frac{-b + \\\\sqrt{ b^{2} - 4 a c }}{2 a}'\n\n\n\n@latexify.function\ndef sinc(x):\n  if x == 0:\n    return 1\n  else:\n    return math.sin(x) / x\n\nsinc\n\n\\[ \\displaystyle \\mathrm{sinc}(x) = \\left\\{ \\begin{array}{ll} 1, & \\mathrm{if} \\ x = 0 \\\\ \\frac{\\sin x}{x}, & \\mathrm{otherwise} \\end{array} \\right. \\]\n\n\n\n# Elif or nested else-if are unrolled.\n@latexify.function\ndef fib(x):\n  if x == 0:\n    return 0\n  elif x == 1:\n    return 1\n  else:\n    return fib(x-1) + fib(x-2)\n\nfib\n\n\\[ \\displaystyle \\mathrm{fib}(x) = \\left\\{ \\begin{array}{ll} 0, & \\mathrm{if} \\ x = 0 \\\\ 1, & \\mathrm{if} \\ x = 1 \\\\ \\mathrm{fib} \\mathopen{}\\left( x - 1 \\mathclose{}\\right) + \\mathrm{fib} \\mathopen{}\\left( x - 2 \\mathclose{}\\right), & \\mathrm{otherwise} \\end{array} \\right. \\]\n\n\n\n# Some math symbols are converted automatically.\n@latexify.function(use_math_symbols=True)\ndef greek(alpha, beta, gamma, Omega):\n  return alpha * beta + math.gamma(gamma) + Omega\n\ngreek\n\n\\[ \\displaystyle \\mathrm{greek}(\\alpha, \\beta, \\gamma, \\Omega) = \\alpha \\beta + \\Gamma \\mathopen{}\\left( \\gamma \\mathclose{}\\right) + \\Omega \\]\n\n\n\n# Function names, arguments, variables can be replaced.\nidentifiers = {\n    \"my_function\": \"f\",\n    \"my_inner_function\": \"g\",\n    \"my_argument\": \"x\",\n}\n\n@latexify.function(identifiers=identifiers)\ndef my_function(my_argument):\n    return my_inner_function(my_argument)\n\nmy_function\n\n\\[ \\displaystyle f(x) = g \\mathopen{}\\left( x \\mathclose{}\\right) \\]\n\n\n\n# Assignments can be reduced into one expression.\n@latexify.function(reduce_assignments=True)\ndef f(a, b, c):\n    discriminant = b**2 - 4 * a * c\n    numerator = -b + math.sqrt(discriminant)\n    denominator = 2 * a\n    return numerator / denominator\n\nf\n\n\\[ \\displaystyle f(a, b, c) = \\frac{-b + \\sqrt{ b^{2} - 4 a c }}{2 a} \\]\n\n\n\n# Matrix support.\n@latexify.function(reduce_assignments=True, use_math_symbols=True)\ndef transform(x, y, a, b, theta, s, t):\n  cos_t = math.cos(theta)\n  sin_t = math.sin(theta)\n  scale = np.array([[a, 0, 0], [0, b, 0], [0, 0, 1]])\n  rotate = np.array([[cos_t, -sin_t, 0], [sin_t, cos_t, 0], [0, 0, 1]])\n  move = np.array([[1, 0, s], [0, 1, t], [0, 0, 1]])\n  return move @ rotate @ scale @ np.array([[x], [y], [1]])\n\ntransform\n\n\\[ \\displaystyle \\mathrm{transform}(x, y, a, b, \\theta, s, t) = \\begin{bmatrix} 1 & 0 & s \\\\ 0 & 1 & t \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\cos \\theta & -\\sin \\theta & 0 \\\\ \\sin \\theta & \\cos \\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} a & 0 & 0 \\\\ 0 & b & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \\]\n\n\n\n# latexify.algorithmic generates an algorithmic environment instead of an equation.\n@latexify.algorithmic\ndef fib(x):\n  if x == 0:\n    return 0\n  elif x == 1:\n    return 1\n  else:\n    return fib(x-1) + fib(x-2)\n\nfib\n\n$\n\\[\\begin{array}{l} \\mathbf{function} \\ \\mathrm{fib}(x) \\\\ \\hspace{1em} \\mathbf{if} \\ x = 0 \\\\ \\hspace{2em} \\mathbf{return} \\ 0 \\\\ \\hspace{1em} \\mathbf{else} \\\\ \\hspace{2em} \\mathbf{if} \\ x = 1 \\\\ \\hspace{3em} \\mathbf{return} \\ 1 \\\\ \\hspace{2em} \\mathbf{else} \\\\ \\hspace{3em} \\mathbf{return} \\ \\mathrm{fib} \\mathopen{}\\left( x - 1 \\mathclose{}\\right) + \\mathrm{fib} \\mathopen{}\\left( x - 2 \\mathclose{}\\right) \\\\ \\hspace{2em} \\mathbf{end \\ if} \\\\ \\hspace{1em} \\mathbf{end \\ if} \\\\ \\mathbf{end \\ function} \\end{array}\\]\n$\n\n\n\n# Another example: latexify.algorithmic supports usual control flows.\n@latexify.algorithmic\ndef collatz(x):\n  n = 0\n  while x &gt; 1:\n    n = n + 1\n    if x % 2 == 0:\n      x = x // 2\n    else:\n      x = 3 * x + 1\n  return n\n\ncollatz\n\n$\n\\[\\begin{array}{l} \\mathbf{function} \\ \\mathrm{collatz}(x) \\\\ \\hspace{1em} n \\gets 0 \\\\ \\hspace{1em} \\mathbf{while} \\ x &gt; 1 \\\\ \\hspace{2em} n \\gets n + 1 \\\\ \\hspace{2em} \\mathbf{if} \\ x \\mathbin{\\%} 2 = 0 \\\\ \\hspace{3em} x \\gets \\left\\lfloor\\frac{x}{2}\\right\\rfloor \\\\ \\hspace{2em} \\mathbf{else} \\\\ \\hspace{3em} x \\gets 3 x + 1 \\\\ \\hspace{2em} \\mathbf{end \\ if} \\\\ \\hspace{1em} \\mathbf{end \\ while} \\\\ \\hspace{1em} \\mathbf{return} \\ n \\\\ \\mathbf{end \\ function} \\end{array}\\]\n$",
    "crumbs": [
      "Blog",
      "Other",
      "Latexify examples"
    ]
  },
  {
    "objectID": "Other/pytube.html",
    "href": "Other/pytube.html",
    "title": "Pytube",
    "section": "",
    "text": "!pip list | grep pytube\n\npytube                        15.0.0\n\n\n\nfrom pytube import YouTube\nyt = YouTube('https://www.youtube.com/watch?v=dQw4w9WgXcQ')\n\n\nyt.title\n\n'Never Gonna Give You Up'\n\n\n\nyt.thumbnail_url\n\n'https://i.ytimg.com/vi/dQw4w9WgXcQ/hq720.jpg?sqp=-oaymwEXCNUGEOADIAQqCwjVARCqCBh4INgESFo&rs=AOn4CLBX-HcaMSEAucUr5J0qD5nEyiPAoQ'\n\n\n\nhigh_yt = yt.streams.get_highest_resolution()\n\n\nhigh_yt.download(output_path = 'Data')\n\n'/home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/MLtools/nbs/Data/Never Gonna Give You Up.mp4'\n\n\n\nfor streams in yt.streams:\n    print(streams)\n\n&lt;Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"6fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\"&gt;\n&lt;Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"25fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\"&gt;\n&lt;Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"25fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\"&gt;\n&lt;Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"25fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"25fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"25fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"25fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"25fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"25fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"25fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\"&gt;\n&lt;Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\"&gt;\n&lt;Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\"&gt;\n&lt;Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\"&gt;\n&lt;Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\"&gt;\n&lt;Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\"&gt;\n\n\n\nyt.streams\\\n.filter(progressive=True, file_extension='mp4')\\\n.order_by('resolution')\\\n.desc().first().download(output_path = 'Data')\n\n'/home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/MLtools/nbs/Data/Never Gonna Give You Up.mp4'\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Other",
      "Pytube"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python Libraries for ML",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Blog",
      "Python Libraries for ML"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html",
    "href": "Python/python_multiprocessing.html",
    "title": "Python Multiprocessing",
    "section": "",
    "text": "from multiprocessing import Pool\n\n\nPool??\n\n\nSignature: Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None)\nSource:   \n    def Pool(self, processes=None, initializer=None, initargs=(),\n             maxtasksperchild=None):\n        '''Returns a process pool object'''\n        from .pool import Pool\n        return Pool(processes, initializer, initargs, maxtasksperchild,\n                    context=self.get_context())\nFile:      ~/mambaforge/envs/cfast/lib/python3.11/multiprocessing/context.py\nType:      method\n\n\n\n\ndef f(x):\n    return x*x\n\nif __name__ == '__main__':\n    with Pool(5) as p:\n        print(p.map(f, [1, 2, 3]))\n\n[1, 4, 9]",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#pool",
    "href": "Python/python_multiprocessing.html#pool",
    "title": "Python Multiprocessing",
    "section": "",
    "text": "from multiprocessing import Pool\n\n\nPool??\n\n\nSignature: Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None)\nSource:   \n    def Pool(self, processes=None, initializer=None, initargs=(),\n             maxtasksperchild=None):\n        '''Returns a process pool object'''\n        from .pool import Pool\n        return Pool(processes, initializer, initargs, maxtasksperchild,\n                    context=self.get_context())\nFile:      ~/mambaforge/envs/cfast/lib/python3.11/multiprocessing/context.py\nType:      method\n\n\n\n\ndef f(x):\n    return x*x\n\nif __name__ == '__main__':\n    with Pool(5) as p:\n        print(p.map(f, [1, 2, 3]))\n\n[1, 4, 9]",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#process",
    "href": "Python/python_multiprocessing.html#process",
    "title": "Python Multiprocessing",
    "section": "Process",
    "text": "Process\n\nfrom multiprocessing import Process\nimport os\n\ndef info(title):\n    print(title)\n    print('module name:', __name__)\n    print('parent process:', os.getppid())\n    print('process id:', os.getpid())\n\ndef f(name):\n    info('function f')\n    print('hello', name)\n\nif __name__ == '__main__':\n    info('main line')\n    p = Process(target=f, args=('bob',))\n    p.start()\n    p.join()\n\nmain line\nmodule name: __main__\nparent process: 2121\nprocess id: 50591\nfunction f\nmodule name: __main__\nparent process: 50591\nprocess id: 50750\nhello bob",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#queues",
    "href": "Python/python_multiprocessing.html#queues",
    "title": "Python Multiprocessing",
    "section": "Queues",
    "text": "Queues\n\nfrom multiprocessing import Process, Queue\n\ndef f(q):\n    q.put([42, None, 'hello'])\n\nif __name__ == '__main__':\n    q = Queue()\n    p = Process(target=f, args=(q,))\n    p.start()\n    print(q.get())    # prints \"[42, None, 'hello']\"\n    p.join()\n\n[42, None, 'hello']",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#pipes",
    "href": "Python/python_multiprocessing.html#pipes",
    "title": "Python Multiprocessing",
    "section": "Pipes",
    "text": "Pipes\n\nfrom multiprocessing import Process, Pipe\n\ndef f(conn):\n    conn.send([42, None, 'hello'])\n    conn.close()\n\nif __name__ == '__main__':\n    parent_conn, child_conn = Pipe()\n    p = Process(target=f, args=(child_conn,))\n    p.start()\n    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n    p.join()\n\n[42, None, 'hello']",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#lock",
    "href": "Python/python_multiprocessing.html#lock",
    "title": "Python Multiprocessing",
    "section": "Lock",
    "text": "Lock\n\nfrom multiprocessing import Process, Lock\n\ndef f(l, i):\n    l.acquire()\n    try:\n        print('hello world', i)\n    finally:\n        l.release()\n\nif __name__ == '__main__':\n    lock = Lock()\n\n    for num in range(10):\n        Process(target=f, args=(lock, num)).start()\n\nhello world\n 0hello world 1\nhello world2 \n hello world3\nhello world 4\nhello world 5\nhello world 6\nhello world 7\nhello world 8\nhello world 9",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#shared-memory",
    "href": "Python/python_multiprocessing.html#shared-memory",
    "title": "Python Multiprocessing",
    "section": "Shared memory",
    "text": "Shared memory\n\nfrom multiprocessing import Process, Value, Array\n\ndef f(n, a):\n    n.value = 3.1415927\n    for i in range(len(a)):\n        a[i] = -a[i]\n\nif __name__ == '__main__':\n    num = Value('d', 0.0)\n    arr = Array('i', range(10))\n\n    p = Process(target=f, args=(num, arr))\n    p.start()\n    p.join()\n\n    print(num.value)\n    print(arr[:])\n\n3.1415927\n[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_multiprocessing.html#server-process",
    "href": "Python/python_multiprocessing.html#server-process",
    "title": "Python Multiprocessing",
    "section": "Server process",
    "text": "Server process\n\nfrom multiprocessing import Process, Manager\n\ndef f(d, l):\n    d[1] = '1'\n    d['2'] = 2\n    d[0.25] = None\n    l.reverse()\n\nif __name__ == '__main__':\n    with Manager() as manager:\n        d = manager.dict()\n        l = manager.list(range(10))\n\n        p = Process(target=f, args=(d, l))\n        p.start()\n        p.join()\n\n        print(d)\n        print(l)\n\n{1: '1', '2': 2, 0.25: None}\n[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]",
    "crumbs": [
      "Blog",
      "Python",
      "Python Multiprocessing"
    ]
  },
  {
    "objectID": "Python/python_logging.html",
    "href": "Python/python_logging.html",
    "title": "Python Logging",
    "section": "",
    "text": "import logging\n\n\nlogging.basicConfig(filename='my_logs.log',\n                    format='%(asctime)s %(levelname)s [Line:%(lineno)d] [file: %(filename)s]'\\\n                    '[func: %(funcName)s] [process: %(process)d, %(processName)s]'\\\n                    '[thread: %(thread)d, %(threadName)s] %(message)s ',\n                    filemode='w',\n                    datefmt='%d-%m-%Y %H:%M:%S',\n                    level=logging.DEBUG)\n\n\nlogging.debug('DEBUG')\nlogging.info('INFO')\nlogging.warning('WARNING')\nlogging.error('ERROR')\nlogging.critical('CRITICAL')\n\n\na = 2\n\n\nb = 55\n\n\nprint(\"asdfasf\")\n\nasdfasf\n\n\n\nx:int = 10 + 10\n\n\nlogging.info(f\"The answer is {x}!\")\n\n\nlogging.info(f\"The answer is {x + a}!\")\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Python",
      "Python Logging"
    ]
  },
  {
    "objectID": "1_monkey_patch.html",
    "href": "1_monkey_patch.html",
    "title": "Monkey Patch",
    "section": "",
    "text": "Monkey patching is the practice of dynamically changing a class, method, or module at runtime, usually to alter or extend behavior without modifying the original source code.\n\n✅ Often used in:\n\nTesting/mocking\nTemporary bug fixes\nDynamic feature injection",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#what-is-monkey-patching",
    "href": "1_monkey_patch.html#what-is-monkey-patching",
    "title": "Monkey Patch",
    "section": "",
    "text": "Monkey patching is the practice of dynamically changing a class, method, or module at runtime, usually to alter or extend behavior without modifying the original source code.\n\n✅ Often used in:\n\nTesting/mocking\nTemporary bug fixes\nDynamic feature injection",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#monkey-patching-use-cases",
    "href": "1_monkey_patch.html#monkey-patching-use-cases",
    "title": "Monkey Patch",
    "section": "🧪 2. Monkey Patching Use Cases",
    "text": "🧪 2. Monkey Patching Use Cases\n\n\n\n\n\n\n\nUse Case\nExample\n\n\n\n\nTesting\nReplace API calls or database functions with mocks\n\n\nHotfixes\nPatch a bug in a third-party library\n\n\nInstrumentation\nInject logging, metrics, or tracing code dynamically\n\n\nCompatibility\nOverride methods for legacy or platform-specific behavior",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#basic-monkey-patch-example",
    "href": "1_monkey_patch.html#basic-monkey-patch-example",
    "title": "Monkey Patch",
    "section": "🧩 3. Basic Monkey Patch Example",
    "text": "🧩 3. Basic Monkey Patch Example\n\nPatching a method:\nclass Math:\n    def add(self, x, y):\n        return x + y\n\n# Patch the method\ndef fake_add(self, x, y):\n    return 42\n\nMath.add = fake_add\n\nm = Math()\nprint(m.add(1, 2))  # ➜ 42",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#monkey-patching-in-pytest-using-monkeypatch-fixture",
    "href": "1_monkey_patch.html#monkey-patching-in-pytest-using-monkeypatch-fixture",
    "title": "Monkey Patch",
    "section": "🧪 4. Monkey Patching in pytest (Using monkeypatch Fixture)",
    "text": "🧪 4. Monkey Patching in pytest (Using monkeypatch Fixture)\npytest provides a built-in fixture named monkeypatch to safely patch objects.\n\nExample:\n# app.py\ndef get_ip():\n    import requests\n    return requests.get(\"https://ipapi.co/ip/\").text\n# test_app.py\ndef test_get_ip(monkeypatch):\n    def mock_get(url):\n        class MockResponse:\n            text = \"123.123.123.123\"\n        return MockResponse()\n\n    monkeypatch.setattr(\"requests.get\", mock_get)\n    from app import get_ip\n    assert get_ip() == \"123.123.123.123\"",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#monkeypatch-methods",
    "href": "1_monkey_patch.html#monkeypatch-methods",
    "title": "Monkey Patch",
    "section": "🧰 5. monkeypatch Methods",
    "text": "🧰 5. monkeypatch Methods\n\n\n\n\n\n\n\nMethod\nPurpose\n\n\n\n\nsetattr(obj_or_path, name, value)\nSet an attribute on an object or module\n\n\ndelattr(obj_or_path, name)\nDelete an attribute\n\n\nsetitem(mapping, key, value)\nPatch a dictionary or map\n\n\ndelitem(mapping, key)\nRemove a key from a dictionary\n\n\nsyspath_prepend(path)\nTemporarily prepend a path to sys.path\n\n\nchdir(path)\nTemporarily change current directory\n\n\nsetenv(name, value)\nPatch environment variable\n\n\ndelenv(name)\nRemove environment variable",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#example-patching-a-class-method",
    "href": "1_monkey_patch.html#example-patching-a-class-method",
    "title": "Monkey Patch",
    "section": "🔍 6. Example: Patching a Class Method",
    "text": "🔍 6. Example: Patching a Class Method\nimport os\n\ndef test_env(monkeypatch):\n    monkeypatch.setenv(\"ENV\", \"test\")\n    assert os.getenv(\"ENV\") == \"test\"",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#risks-of-monkey-patching",
    "href": "1_monkey_patch.html#risks-of-monkey-patching",
    "title": "Monkey Patch",
    "section": "⚠️ 7. Risks of Monkey Patching",
    "text": "⚠️ 7. Risks of Monkey Patching\n\n\n\n\n\n\n\nRisk\nDescription\n\n\n\n\n🔄 Global side effects\nPatches affect all usage of the object across the app\n\n\n😱 Hard to trace\nDynamic behavior can confuse maintainers or IDEs\n\n\n❌ Breaks updates\nFuture library updates may invalidate the patch\n\n\n🧪 Unintended leakage in tests\nIf not undone/reset between tests, state leaks may occur",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#best-practices",
    "href": "1_monkey_patch.html#best-practices",
    "title": "Monkey Patch",
    "section": "✅ 8. Best Practices",
    "text": "✅ 8. Best Practices\n\n\n\n\n\n\n\nTip\nDescription\n\n\n\n\n✔️ Use pytest.monkeypatch\nIt’s scoped to the test and auto-resets afterward\n\n\n🧪 Patch only what you need\nAvoid excessive or deep patches\n\n\n🛑 Don’t monkeypatch in production\nUnless absolutely necessary and temporary\n\n\n🧼 Cleanup manually if not using monkeypatch\nUse try/finally or context managers\n\n\n📚 Document all patches\nEspecially in test or third-party contexts",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#comparison-monkeypatch-vs-unittest.mock.patch",
    "href": "1_monkey_patch.html#comparison-monkeypatch-vs-unittest.mock.patch",
    "title": "Monkey Patch",
    "section": "🧪 9. Comparison: monkeypatch vs unittest.mock.patch",
    "text": "🧪 9. Comparison: monkeypatch vs unittest.mock.patch\n\n\n\n\n\n\n\n\nFeature\npytest.monkeypatch\nunittest.mock.patch\n\n\n\n\nScope\nFunction-scoped fixture\nContext manager / decorator\n\n\nResets?\n✅ Auto-reset\n✅ Auto-reset if used correctly\n\n\nVerbosity\nMinimal\nMore boilerplate\n\n\nStyle\nFunctional\nObject-oriented\n\n\n\n\nExample with mock.patch:\nfrom unittest.mock import patch\n\n@patch(\"requests.get\")\ndef test_get_ip(mock_get):\n    mock_get.return_value.text = \"123.123.123.123\"\n    assert get_ip() == \"123.123.123.123\"",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#common-monkey-patch-targets",
    "href": "1_monkey_patch.html#common-monkey-patch-targets",
    "title": "Monkey Patch",
    "section": "📦 10. Common Monkey Patch Targets",
    "text": "📦 10. Common Monkey Patch Targets\n\n\n\nTarget\nPurpose\n\n\n\n\nos.getenv, os.environ\nPatch environment-dependent behavior\n\n\nrequests.get / post\nReplace API calls\n\n\ndatetime.now\nFreeze or control time\n\n\nClass methods\nReplace expensive or slow logic\n\n\nThird-party libraries\nFix bugs or inject logic",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#bonus-patch-datetime.now",
    "href": "1_monkey_patch.html#bonus-patch-datetime.now",
    "title": "Monkey Patch",
    "section": "🧪 Bonus: Patch datetime.now()",
    "text": "🧪 Bonus: Patch datetime.now()\nimport datetime\n\nclass FakeDatetime(datetime.datetime):\n    @classmethod\n    def now(cls):\n        return cls(2020, 1, 1)\n\ndef test_time(monkeypatch):\n    monkeypatch.setattr(datetime, \"datetime\", FakeDatetime)\n    assert datetime.datetime.now() == datetime.datetime(2020, 1, 1)",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  },
  {
    "objectID": "1_monkey_patch.html#final-thoughts",
    "href": "1_monkey_patch.html#final-thoughts",
    "title": "Monkey Patch",
    "section": "📌 Final Thoughts",
    "text": "📌 Final Thoughts\n\n✅ Monkey patching is powerful for testing, mocking, and runtime modifications\n❗️Use carefully and only when needed\nPrefer pytest.monkeypatch in test code\nAvoid in production unless under control (e.g., well-documented, temporary hotfix)",
    "crumbs": [
      "Blog",
      "Monkey Patch"
    ]
  }
]